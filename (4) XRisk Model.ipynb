{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1\n",
      "Loaded 2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import squigglepy as sq\n",
    "from squigglepy import bayes\n",
    "from squigglepy.numbers import K, M, B, T\n",
    "from copy import deepcopy\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "print('Loaded 1')\n",
    "\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "# Global variables - probably don't want to change these but you could.\n",
    "RUNS = K # 100*K                                      # Number of runs to do (default 100*K)\n",
    "CURRENT_YEAR = 2023                               # What year to start the run on? (default: 2023)\n",
    "MAX_YEAR = 2123                                   # What year to end the run on? (default: 2123)\n",
    "\n",
    "\n",
    "years = range(CURRENT_YEAR, MAX_YEAR)\n",
    "print('Loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAI Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TAI scenarios module\n"
     ]
    }
   ],
   "source": [
    "# Conditoinal on making TAI, will it be agentic?\n",
    "p_make_agent_tai = 0.9\n",
    "\n",
    "# Conditional on making agentic TAI, will it be aligned by default?\n",
    "p_tai_aligned_by_default = 0.2\n",
    "\n",
    "# Conditional on making agentic TAI that is not aligned by default, will we solve the alignment problem?\n",
    "# Varies by year, whether this is the first attempt, and whether there is a great power war\n",
    "def p_alignment_solved(war, year, first_attempt=True, verbose=False):\n",
    "    if first_attempt:\n",
    "        p = min(0.1 + 1.3 * (year/45), 0.75)\n",
    "    else:\n",
    "        p = min(0.1 + 1.9 * (year/45), 0.85)\n",
    "    if war:\n",
    "        p = p * 0.7\n",
    "    if verbose == 2:\n",
    "        print('* alignment diagnostic - war: {} year: {} first attempt: {} -> p {})'.format(war, year, first_attempt, p))\n",
    "    return p\n",
    "# TODO: Convert to logistic curves\n",
    "\n",
    "# Conditional on solving the alignment problem, what is the chance we also solve the subtle misalignment problem?\n",
    "p_subtle_alignment_solved = 0.85\n",
    "\n",
    "# Conditional on alignment by default, what is the chance we also solve the subtle misalignment problem?\n",
    "p_subtle_alignment_solved_if_aligned_by_default = 0.4\n",
    "\n",
    "# Conditional on having agentic TAI, will it be intentionally misused to create a singleton?\n",
    "def p_tai_intentional_misuse(war):\n",
    "    return 0.3 if war else 0.05\n",
    "\n",
    "# If TAI is fully misaligned what is the chance we can successfully detect and avert this?\n",
    "p_full_tai_misalignment_averted = 0.15\n",
    "\n",
    "# If TAI is fully misaligned but successfully averted, what is the probability there will be a catasrophe (10%+ death)?\n",
    "p_tai_misalignment_averting_is_catastrophic = 0.4\n",
    "\n",
    "# If TAI is fully misaligned and we successfully avert it, what is the chance we give up on TAI?\n",
    "p_full_tai_misalignment_averted_means_abandoned_tai = 0.7\n",
    "\n",
    "# If TAI is fully misaligned, what is the chance it results in extinction versus a singleton?\n",
    "p_tai_xrisk_is_extinction = 0.4\n",
    "\n",
    "# If there is a fully misaligned TAI singleton, what is the chance it results in a non-extinction catastrophe (10%+ death)?\n",
    "p_tai_singleton_is_catastrophic = 0.8\n",
    "\n",
    "\n",
    "exec(open('modules/tai_risk.py').read())\n",
    "print('Loaded TAI scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuclear Scenarios Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded nuclear scenarios module\n"
     ]
    }
   ],
   "source": [
    "def p_russia_uses_nuke(peace, year):\n",
    "    peace = 10 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year == 2023:\n",
    "        return 0.03\n",
    "    else:\n",
    "        return 0.001 / peace\n",
    "\n",
    "    \n",
    "p_nk_uses_nuke = 0.001\n",
    "\n",
    "\n",
    "def p_china_invades_taiwan(peace, year):\n",
    "    peace = 10 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year == 2022:\n",
    "        return 0\n",
    "    elif year == 2023:\n",
    "        return 0.01\n",
    "    elif year == 2024 or year == 2025:\n",
    "        return 0.047   # makes cumulative probability by EOY 2025 = 0.1\n",
    "                        # solve 0.01 + (1-0.01)*X + (1-0.01)(1-X)*X = 0.1, 0>X<1\n",
    "    elif year < 2030:\n",
    "        return 0.078 # makes cumulative probability by EOY 2029 = 0.4\n",
    "                     # solve 0.1 + (1-0.1)*X + (1-0.1)(1-X)*X + (1-0.1)(1-X)^2*X + (1-0.1)(1-X)^3*X + (1-0.1)(1-X)^4*X = 0.4\n",
    "    elif year < 2035:\n",
    "        return 0.097 # makes cumulative probability by EOY 2034 = 0.6\n",
    "                     # 0.4 + (1-0.5)*X + (1-0.5)(1-X)*X + (1-0.5)(1-X)^2*X + (1-0.5)(1-X)^3*X + (1-0.5)(1-X)^4*X = 0.6\n",
    "    else:\n",
    "        return 0.005 / peace\n",
    "\n",
    "\n",
    "def p_china_uses_nuke(peace, year):\n",
    "    return p_china_invades_taiwan(peace, year) * 0.01\n",
    "\n",
    "    \n",
    "def p_other_uses_nuke(peace):\n",
    "    peace = 10 if peace else 1\n",
    "    return 0.0002 / peace\n",
    "\n",
    "\n",
    "# What is the chance in a given year there will be a \"nuclear accident\"?\n",
    "def p_nuclear_accident(war, year):\n",
    "    p = 0.05 if war else 0.02\n",
    "    p = p * (0.998 ** year)\n",
    "    return p\n",
    "\n",
    "\n",
    "# Conditional on a nuclear accident, what is the chance it escalates into an \"exchange\"?\n",
    "def p_nuclear_accident_becomes_exchange(war):\n",
    "    return 0.2 if war else 0.05\n",
    "\n",
    "\n",
    "# Conditional on a nuclear exchange, what is the chance it escalates into a catastrophe (10%+ dead)?\n",
    "def p_catastrophe_from_nuclear_exchange(war):\n",
    "    p_exchange_becomes_all_out_war = 0.6 if war else 0.3\n",
    "    p_nuclear_winter_happens = 0.3\n",
    "    alternative_foods_or_other_save = 0.05\n",
    "    return (p_exchange_becomes_all_out_war *\n",
    "            (p_nuclear_winter_happens + (1 - p_nuclear_winter_happens) * 0.1) *\n",
    "            (1 - alternative_foods_or_other_save))\n",
    "    \n",
    "    \n",
    "# Conditional on a nuclear exchange catastrophe, what is the chance it becomes an xrisk?\n",
    "p_xrisk_from_nuclear_catastrophe = 0.05 # https://forum.effectivealtruism.org/posts/GsjmufaebreiaivF7/what-is-the-likelihood-that-civilizational-collapse-would\n",
    "\n",
    "\n",
    "# Conditional on a great power war, what is the chance it goes intentionally nuclear in any given year?\n",
    "def p_nuclear_exchange_given_war(first_year_of_war):\n",
    "    return 0.1 if first_year_of_war else 0.02\n",
    "\n",
    "\n",
    "exec(open('modules/nuclear.py').read())\n",
    "print('Loaded nuclear scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Power War Scenarios Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded great power war scenarios module\n"
     ]
    }
   ],
   "source": [
    "def p_great_power_war_us_russia_without_nuke_first(peace, year):\n",
    "    peace = 20 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year == 2022 or year == 2023:\n",
    "        return (0.02 / 2) / peace\n",
    "    else:\n",
    "        return 0.003 / peace\n",
    "\n",
    "    \n",
    "def p_great_power_war_us_china(peace, year):\n",
    "    peace = 20 if peace else 1\n",
    "    p_invade_taiwan = p_china_invades_taiwan(peace, year)\n",
    "    p_us_responds = 0.6\n",
    "    return p_invade_taiwan * p_us_responds\n",
    "\n",
    "    \n",
    "def p_great_power_war_other(peace, year):\n",
    "    peace = 5 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year > 2040:\n",
    "        return 0.005 / peace\n",
    "    else:\n",
    "        return 0.001 / peace\n",
    "\n",
    "\n",
    "# Conditional on a great power war starting, how long will it last?\n",
    "war_length = sq.lognorm(2, 50) # 90% CI\n",
    "\n",
    "# After a war ends, how long will there be a peace?\n",
    "peace_length = sq.lognorm(10, 100)\n",
    "\n",
    "\n",
    "exec(open('modules/great_power_war.py').read())\n",
    "print('Loaded great power war scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bio scenarios module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bio scenarios module\n"
     ]
    }
   ],
   "source": [
    "# Conditional on a great power war, what is the annual chance it intentionally results in a bioweapon?\n",
    "p_biowar_given_war = 1/800\n",
    "\n",
    "# What is the annual chance of a non-state actor creating an intentional biorisk that causes 1%+ death?\n",
    "p_nonstate_bio = 1/1200\n",
    "\n",
    "# What is the chance that if 1%+ die from natural bio, 10%+ will die from natural bio?\n",
    "p_natural_bio_is_catastrophe = 1 / (10 ** 0.5) # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "\n",
    "# What is the chance that if 1%+ die from engineered bio, 10%+ will die from engineered bio?\n",
    "p_engineered_bio_is_catastrophe = 1 / (10 ** 0.5) # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "\n",
    "p_covid_spanish_flu_like_becomes_1pct_death = 1 / (10 ** 0.5) # https://www.economist.com/graphic-detail/coronavirus-excess-deaths-estimates suggests COVID killed 0.2%... https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028 suggests 1% is 2x less likely than 0.2%\n",
    "p_covid_lab_leak = 0.3\n",
    "p_extinction_given_90_pct_death = 0.03 # per Luisa https://forum.effectivealtruism.org/posts/GsjmufaebreiaivF7/what-is-the-likelihood-that-civilizational-collapse-would\n",
    "p_accidental_catastrophe_causes_90_pct_death = (1 / (10 ** 0.5)) ** 2 # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "p_intentional_catastrophe_causes_90_pct_death = (1 / (10 ** 0.5)) ** 2 # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "\n",
    "# If a lab leak occurs, how likely is it that the leaked pandemic will be engineered vs. natural?\n",
    "ratio_engineered_vs_natural_lab_leak = 0.8\n",
    "\n",
    "# What is the chance of an natural biorisk/pandemic causing 1%+ population death?\n",
    "def p_natural_bio(year):\n",
    "    base_rate_from_covid_and_spanish_flu = 1/250\n",
    "    increase_from_globalization = 1.1\n",
    "    decreate_in_rate_per_year_from_improvements = 0.99 ** year\n",
    "    return ((base_rate_from_covid_and_spanish_flu * 0.5 +\n",
    "             base_rate_from_covid_and_spanish_flu * (1 - p_covid_lab_leak) * 0.5) *\n",
    "            increase_from_globalization *\n",
    "            p_covid_spanish_flu_like_becomes_1pct_death *\n",
    "            decreate_in_rate_per_year_from_improvements)\n",
    "    \n",
    "    \n",
    "# What is the chance of an accidental biorisk (e.g., lab leak) causing 1%+ population death?\n",
    "def p_accidental_bio(war):\n",
    "    base_rate_from_covid = 0.01 * p_covid_lab_leak\n",
    "    increase_factor_due_to_increasing_labs = 1.3\n",
    "    increase_factor_due_to_great_power_war = 2\n",
    "    p = (base_rate_from_covid *\n",
    "         p_covid_spanish_flu_like_becomes_1pct_death *\n",
    "         increase_factor_due_to_increasing_labs)\n",
    "    return p * increase_factor_due_to_great_power_war if war else p\n",
    "    \n",
    "\n",
    "# Conditional on a accidental biorisk (1% death), what is the chance it becomes a xrisk?\n",
    "def p_xrisk_from_accidental_bio_given_catastrophe(year):\n",
    "    return p_accidental_catastrophe_causes_90_pct_death * p_extinction_given_90_pct_death\n",
    "\n",
    "\n",
    "# Conditional on a bioweapon, what is the chance it becomes a xrisk?\n",
    "def p_xrisk_from_engineered_bio_given_catastrophe(year):\n",
    "    return p_intentional_catastrophe_causes_90_pct_death * p_extinction_given_90_pct_death\n",
    "\n",
    "\n",
    "exec(open('modules/bio.py').read())\n",
    "print('Loaded bio scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nanotech scenarios module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded nano scenarios module\n"
     ]
    }
   ],
   "source": [
    "# What is the chance in a given year that nanotech will be developed?\n",
    "def p_nanotech_possible(year):\n",
    "    return 0.0001 / (0.956 ** year) # TODO: This goes over 1\n",
    "\n",
    "\n",
    "# Conditional on developing nanotech, what is the chance nanotech results in an xrisk?\n",
    "p_nanotech_is_xrisk = 0.1 * 0.05\n",
    "\n",
    "\n",
    "exec(open('modules/nano.py').read())\n",
    "print('Loaded nano scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervolcano scenarios module (all other natural risks <0.01%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded supervolcano module\n"
     ]
    }
   ],
   "source": [
    "p_supervolcano_catastrophe = 1 / (500*K)  # https://www.openphilanthropy.org/research/large-volcanic-eruptions/ VEI >= 9 (geometric mean of 30K and 30M)\n",
    "\n",
    "p_supervolcano_extinction_given_catastrophe = 0.05\n",
    "\n",
    "\n",
    "exec(open('modules/supervolcano.py').read())\n",
    "print('Loaded supervolcano module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown unknown scenarios module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded unknown unknown scenarios module\n"
     ]
    }
   ],
   "source": [
    "# What is the chance in any given year that an unknown unknown xrisk occurs?\n",
    "def p_unknown_unknown_xrisk(year):\n",
    "    return (1 / (100*K)) / (0.99 ** year) # TODO: This goes over 1\n",
    "    \n",
    "exec(open('modules/unknown_unknown.py').read())\n",
    "print('Loaded unknown unknown scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double dip catastrophe module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded double dip catastrophe module\n"
     ]
    }
   ],
   "source": [
    "p_extinction_from_double_catastrophe = 0.1\n",
    "extinction_from_double_catastrophe_range = 10\n",
    "\n",
    "exec(open('modules/double_dip_catastrophe.py').read())\n",
    "print('Loaded double dip catastrophe module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Timeline variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TAI timelines module\n",
      "-\n",
      "Loading from cache file (`caches/tai_years.sqcache`)...\n",
      "...Loaded\n",
      "Caching in-memory...\n",
      "...Cached!\n",
      "...Reducing\n",
      "...Reduced!\n",
      "...All done!\n",
      "-\n",
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "exec(open('modules/tai_timelines.py').read())\n",
    "print('Loaded TAI timelines module')\n",
    "\n",
    "print('-')\n",
    "tai_years = bayes.bayesnet(load_cache_file='caches/tai_years', verbose=True)\n",
    "\n",
    "# TODO: War spending\n",
    "# TODO: TAI China delay\n",
    "# TODO: TAI Catastrophe delay\n",
    "\n",
    "print('-')\n",
    "print('Loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "exec(open('modules/define_event.py').read())\n",
    "print('Model loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "## RUN 1 ##\n",
      "############\n",
      "2086: Russia uses a nuke first strike (outside of great power war)!\n",
      "2086: WAR!!! (US vs. Russia)\n",
      "2089: ...catastrophe from nukes (war)\n",
      "2091: War ends :)\n",
      "...Total loop complete in 193.12ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 2 ##\n",
      "############\n",
      "2084: Russia uses a nuke first strike (outside of great power war)!\n",
      "2084: WAR!!! (US vs. Russia)\n",
      "--- /!\\ TAI CREATED in 2089\n",
      "2090: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 124.02ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 3 ##\n",
      "############\n",
      "2045: WAR!!! (Other)\n",
      "2052: War ends :)\n",
      "--- /!\\ TAI CREATED in 2053\n",
      "2054: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 173.49ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 4 ##\n",
      "############\n",
      "2031: WAR!!! (US vs. China)\n",
      "--- /!\\ TAI CREATED in 2034\n",
      "2035: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 117.79ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 5 ##\n",
      "############\n",
      "2034: WAR!!! (US vs. China)\n",
      "--- /!\\ TAI CREATED in 2044\n",
      "2045: ...Tool TAI made\n",
      "2060: War ends :)\n",
      "2111: A country other than Russia/China/NK uses a nuke first strike (outside of great power war)!\n",
      "...Total loop complete in 177.13ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 6 ##\n",
      "############\n",
      "2027: WAR!!! (US vs. China)\n",
      "2046: War ends :)\n",
      "--- /!\\ TAI CREATED in 2059\n",
      "2060: ...XRISK from fully unaligned TAI (singleton) :(\n",
      "...Singleton is catastrophic\n",
      "...Total loop complete in 175.45ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 7 ##\n",
      "############\n",
      "...Total loop complete in 175.81ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 8 ##\n",
      "############\n",
      "2023: Russia uses a nuke first strike (outside of great power war)!\n",
      "2024: WAR!!! (US vs. Russia)\n",
      "2024: ...catastrophe from pathogen (war)\n",
      "2028: War ends :)\n",
      "...Total loop complete in 124.17ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 9 ##\n",
      "############\n",
      "2095: WAR!!! (US vs. Russia)\n",
      "2104: War ends :)\n",
      "...Total loop complete in 174.91ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 10 ##\n",
      "############\n",
      "...Total loop complete in 177.55ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 11 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2054\n",
      "2055: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 113.92ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 12 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2036\n",
      "2037: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 168.23ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 13 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2038\n",
      "2039: ...XRISK from subtly unaligned TAI :(\n",
      "...Total loop complete in 169.01ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 14 ##\n",
      "############\n",
      "2041: Russia uses a nuke first strike (outside of great power war)!\n",
      "2042: WAR!!! (US vs. Russia)\n",
      "--- /!\\ TAI CREATED in 2047\n",
      "2048: ...XRISK from intentional misuse of TAI (singleton) :(\n",
      "...Singleton is catastrophic\n",
      "...Total loop complete in 118.23ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 15 ##\n",
      "############\n",
      "...Total loop complete in 174.84ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 16 ##\n",
      "############\n",
      "2031: WAR!!! (US vs. China)\n",
      "2044: War ends :)\n",
      "--- /!\\ TAI CREATED in 2099\n",
      "2100: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 175.95ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 17 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2030\n",
      "2031: ...XRISK from intentional misuse of TAI (singleton) :(\n",
      "...Singleton is catastrophic\n",
      "...Total loop complete in 115.7ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 18 ##\n",
      "############\n",
      "2070: WAR!!! (US vs. Russia)\n",
      "2082: War ends :)\n",
      "--- /!\\ TAI CREATED in 2097\n",
      "2098: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 171.72ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 19 ##\n",
      "############\n",
      "2026: WAR!!! (US vs. China)\n",
      "2030: War ends :)\n",
      "2031: WAR!!! (US vs. China)\n",
      "2036: War ends :)\n",
      "--- /!\\ TAI CREATED in 2086\n",
      "2087: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 178.43ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 20 ##\n",
      "############\n",
      "2029: WAR!!! (US vs. China)\n",
      "2046: War ends :)\n",
      "2075: WAR!!! (Other)\n",
      "2077: War ends :)\n",
      "...Total loop complete in 124.56ms\n",
      "...Boring future\n",
      "-\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print('############')\n",
    "    print('## RUN {} ##'.format(i + 1))\n",
    "    print('############')\n",
    "    define_event(verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading cache...\n",
      "Generating Bayes net with 5 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████████████████████████▎                                                                                                                            | 240/1000 [00:08<00:28, 26.87it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collectors = bayes.bayesnet(define_event,\n",
    "                            find=lambda e: e['collectors'],\n",
    "                            load_cache_file='caches/future_assessment_model_cache',\n",
    "                            dump_cache_file='caches/future_assessment_model_cache',\n",
    "                            reload_cache=True, # False\n",
    "                            raw=True,\n",
    "                            verbose=True,\n",
    "                            cores=5,\n",
    "                            n=RUNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('4E. When TAI?')\n",
    "print('-')\n",
    "\n",
    "yrs = bayes.bayesnet(define_event,\n",
    "                     find=lambda e: e['final_state']['tai_year'],\n",
    "                     raw=True,\n",
    "                     n=RUNS)\n",
    "yrs = [MAX_YEAR + 1 if y is None else y for y in yrs]\n",
    "print_tai_arrival_stats(yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_p = np.array([p_alignment_solved(war=False, year=y - CURRENT_YEAR, first_attempt=True) for y in years])\n",
    "alignment_p2 = np.array([p_alignment_solved(war=False, year=y - CURRENT_YEAR, first_attempt=False) for y in years])\n",
    "alignment_pwar = np.array([p_alignment_solved(war=True, year=y - CURRENT_YEAR, first_attempt=True) for y in years])\n",
    "alignment_p2war = np.array([p_alignment_solved(war=True, year=y - CURRENT_YEAR, first_attempt=False) for y in years])\n",
    "plt.plot(years, alignment_p, label='first attempt, no war')\n",
    "plt.plot(years, alignment_p2, label='2+ attempt, no war')\n",
    "plt.plot(years, alignment_pwar, label='first attempt, war')\n",
    "plt.plot(years, alignment_p2war, label='2+ attempt, war')\n",
    "plt.legend()\n",
    "plt.ylabel('chance of solving alignment if TAI in year')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in list(years[:17]) + list(years[17::10]):\n",
    "    str_ = 'Year: {} - chance of solving TAI alignment with war {}% (2nd attempt {}%) -- or no war {}% (2nd attempt {}%)'\n",
    "    print(str_.format(y,\n",
    "                      round(alignment_pwar[y - CURRENT_YEAR] * 100, 0),\n",
    "                      round(alignment_p2war[y - CURRENT_YEAR] * 100, 0),\n",
    "                      round(alignment_p[y - CURRENT_YEAR] * 100, 0),\n",
    "                      round(alignment_p2[y - CURRENT_YEAR] * 100, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('AI X-Risk BY EOY year')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: e['collectors'][y_c]['category'] == category,\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    extinction = find(y_c, 'xrisk_full_unaligned_tai_extinction')\n",
    "    singleton = find(y_c, 'xrisk_full_unaligned_tai_singleton')\n",
    "    subtle_misalignment = find(y_c, 'xrisk_subtly_unaligned_tai')\n",
    "    misuse = find(y_c, 'xrisk_tai_misuse')\n",
    "    out = '{} - {}% (Extinction: {}%, Bad TAI singleton: {}%, Subtly misaligned singleton: {}%, Misuse singleton: {}%)'\n",
    "    print(out.format(y_c,\n",
    "                     round((extinction + singleton + subtle_misalignment + misuse) * 100, 1),\n",
    "                     round(extinction * 100, 1),\n",
    "                     round(singleton * 100, 1),\n",
    "                     round(subtle_misalignment * 100, 1),\n",
    "                     round(misuse * 100, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Chance of successfully aligning TAI by EOY year')\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: e['collectors'][y_c]['category'] == 'aligned_tai',\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cumulative Total X-Risk (including non-extinction x-risks and \"good but not great\" x-risks)')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: ('xrisk' in e['collectors'][y_c]['category']) and (category in e['collectors'][y_c]['category']),\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2023, 2024, 2030, 2031, 2035, 2040, 2045, 2050, 2060, 2070, 2100]:\n",
    "    ai = find(y_c, 'tai')\n",
    "    nukes = find(y_c, 'nukes')\n",
    "    unknown = find(y_c, 'unknown')\n",
    "    nano = find(y_c, 'nanotech')\n",
    "    natural = find(y_c, 'supervolcano')\n",
    "    bio = find(y_c, 'bio')\n",
    "\n",
    "    out = '{} - {}% (AI: {}%, Nukes: {}%, Bio: {}%, Nano: {}%, Natural: {}%, Other: {}%)'\n",
    "    print(out.format(y_c,\n",
    "                     round((ai + nukes + bio + nano + unknown) * 100, 2),\n",
    "                     round(ai * 100, 2),\n",
    "                     round(nukes * 100, 3),\n",
    "                     round(bio * 100, 3),\n",
    "                     round(nano * 100, 3),\n",
    "                     round(natural * 100, 3),\n",
    "                     round(unknown * 100, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cumulative Total Extinction Risk')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: e['collectors'][y_c]['category'] == category,\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2030, 2050, 2100]:\n",
    "    ai = find(y_c, 'xrisk_full_unaligned_tai_extinction')\n",
    "    nukes_war = find(y_c, 'xrisk_nukes_war')\n",
    "    nukes_accident = find(y_c, 'xrisk_nukes_accident')\n",
    "    unknown = find(y_c, 'xrisk_unknown_unknown')\n",
    "    bio_war = find(y_c, 'xrisk_bio_war')\n",
    "    bio_accident = find(y_c, 'xrisk_bio_accident')\n",
    "    bio_nonstate = find(y_c, 'xrisk_bio_nonstate')\n",
    "    nanotech = find(y_c, 'xrisk_nanotech')\n",
    "    supervolcano = find(y_c, 'xrisk_supervolcano')\n",
    "    \n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: e['collectors'][y_c]['category'] in extinctions,\n",
    "                       n=RUNS)\n",
    "    \n",
    "    out = '{} - {}% (AI: {}%, Nukes: {}% (War: {}% Accident: {}%), Bio: {}% (War: {}%, Accident: {}%, Nonstate: {}%), Nano: {}%, Natural: {}%, Other: {}%)'\n",
    "    print(out.format(y_c,\n",
    "                     round(r * 100, 2),\n",
    "                     round(ai * 100, 2),\n",
    "                     round((nukes_war + nukes_accident) * 100, 3),\n",
    "                     round(nukes_war * 100, 3),\n",
    "                     round(nukes_accident * 100, 3),\n",
    "                     round((bio_war + bio_accident + bio_nonstate) * 100, 3),\n",
    "                     round(bio_war * 100, 3),\n",
    "                     round(bio_accident * 100, 3),\n",
    "                     round(bio_nonstate * 100, 3),\n",
    "                     round(nanotech * 100, 3),\n",
    "                     round(supervolcano * 100, 3),\n",
    "                     round(unknown * 100, 3)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cumulative Total *Actively Bad* Future X-Risk (including non-extinction risks but excluding subtle AI misalignment)')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: ('xrisk' in e['collectors'][y_c]['category']) and (category in e['collectors'][y_c]['category']),\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2023, 2024, 2030, 2031, 2035, 2040, 2045, 2050, 2060, 2070, 2100]:\n",
    "    ai = find(y_c, 'tai')\n",
    "    ai_subtle_misalignment = find(y_c, 'xrisk_subtly_unaligned_tai')\n",
    "    nukes = find(y_c, 'nukes')\n",
    "    unknown = find(y_c, 'unknown')\n",
    "    nano = find(y_c, 'nanotech')\n",
    "    natural = find(y_c, 'supervolcano')\n",
    "    bio = find(y_c, 'bio')\n",
    "\n",
    "    out = '{} - {}% (AI: {}%, Nukes: {}%, Bio: {}%, Nano: {}%, Natural: {}%, Other: {}%)'\n",
    "    print(out.format(y_c,\n",
    "                     round((ai - ai_subtle_misalignment + nukes + bio + nano + unknown) * 100, 2),\n",
    "                     round((ai - ai_subtle_misalignment) * 100, 2),\n",
    "                     round(nukes * 100, 3),\n",
    "                     round(bio * 100, 3),\n",
    "                     round(nano * 100, 3),\n",
    "                     round(natural * 100, 3),\n",
    "                     round(unknown * 100, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cumulative Total Catastrophe Risk (defined as 10%+ death)')\n",
    "\n",
    "for y_c in [2030, 2050, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: e['collectors'][y_c]['catastrophe'] != [],\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total X-Risk IN THAT SPECIFIC YEAR (non-cumulative) (including non-extinction x-risks)')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: ('xrisk' in e['collectors'][y_c]['category']) and (category in e['collectors'][y_c]['category']),\n",
    "                          n=RUNS)\n",
    "\n",
    "ai = np.diff(np.array([find(y, 'tai') for y in tqdm(range(CURRENT_YEAR, MAX_YEAR))]))\n",
    "nukes = np.diff(np.array([find(y, 'nukes') for y in tqdm(range(CURRENT_YEAR, MAX_YEAR))]))\n",
    "unknown = np.diff(np.array([find(y, 'unknown') for y in tqdm(range(CURRENT_YEAR, MAX_YEAR))]))\n",
    "nano = np.diff(np.array([find(y, 'nanotech') for y in tqdm(range(CURRENT_YEAR, MAX_YEAR))]))\n",
    "natural = np.diff(np.array([find(y, 'supervolcano') for y in tqdm(range(CURRENT_YEAR, MAX_YEAR))]))\n",
    "bio = np.diff(np.array([find(y, 'bio') for y in tqdm(range(CURRENT_YEAR, MAX_YEAR))]))\n",
    "\n",
    "for y_c in range(MAX_YEAR - CURRENT_YEAR - 1):\n",
    "    out = '{} - {}% (AI: {}%, Nukes: {}%, Bio: {}%, Nano: {}%, Natural: {}%, Other: {}%)'\n",
    "    print(out.format(y_c + CURRENT_YEAR,\n",
    "                     round((ai[y_c] + nukes[y_c] + bio[y_c] + nano[y_c] + unknown[y_c]) * 100, 8),\n",
    "                     round(ai[y_c] * 100, 8),\n",
    "                     round(nukes[y_c] * 100, 8),\n",
    "                     round(bio[y_c] * 100, 8),\n",
    "                     round(nano[y_c] * 100, 8),\n",
    "                     round(natural[y_c] * 100, 8),\n",
    "                     round(unknown[y_c] * 100, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrisk_df = pd.DataFrame({'year': range(CURRENT_YEAR, MAX_YEAR - 1),\n",
    "                         'ai': ai,\n",
    "                         'nukes': nukes,\n",
    "                         'unknown': unknown,\n",
    "                         'nano': nano,\n",
    "                         'natural': natural,\n",
    "                         'bio': bio})\n",
    "xrisk_df['total'] = xrisk_df['ai'] + xrisk_df['nukes'] + xrisk_df['unknown'] + xrisk_df['nano'] + xrisk_df['natural'] + xrisk_df['bio']\n",
    "xrisk_df.to_csv('caches/xrisk_df.csv', index=False)\n",
    "xrisk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total X-Risk OR catastrophe by EOY year')\n",
    "\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: 'xrisk' in e['collectors'][y_c]['category'] or e['collectors'][y_c]['catastrophe'] != [],\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total X-Risk AND catastrophe by EOY year')\n",
    "\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: 'xrisk' in e['collectors'][y_c]['category'] and e['collectors'][y_c]['catastrophe'] != [],\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://forum.effectivealtruism.org/posts/nYgw4FNpHf9bmJGEi/forecasting-thread-how-does-ai-risk-level-vary-based-on\n",
    "\n",
    "def generate_conditional(y_low, y_high):\n",
    "    def fn(e):\n",
    "        if e['final_state']['tai_year'] is None:\n",
    "            return False\n",
    "        elif e['final_state']['tai_year'] < y_low:\n",
    "            return False\n",
    "        elif e['final_state']['tai_year'] > y_high:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    return fn\n",
    "    \n",
    "\n",
    "def find(y_low, y_high, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: e['collectors'][MAX_YEAR - 1 if y_high >= MAX_YEAR else y_high]['category'] == category,\n",
    "                          conditional_on=generate_conditional(y_low, y_high),\n",
    "                          n=RUNS)\n",
    "\n",
    "\n",
    "for y_c in [[2022, 2024], [2024, 2029], [2029, 2039], [2039, 2059], [2059, MAX_YEAR - 1], [2022, 2070]]:\n",
    "    print('AI X-Risk conditional on AGI beween beginning of {} and end of {}'.format(y_c[0] + 1, y_c[1]))\n",
    "    extinction = find(y_c[0], y_c[1], 'xrisk_full_unaligned_tai_extinction')\n",
    "    singleton = find(y_c[0], y_c[1], 'xrisk_full_unaligned_tai_singleton')\n",
    "    subtle_misalignment = find(y_c[0], y_c[1], 'xrisk_subtly_unaligned_tai')\n",
    "    misuse = find(y_c[0], y_c[1], 'xrisk_tai_misuse')\n",
    "    out = '{}% (Extinction: {}%, Bad TAI singleton: {}%, Subtly misaligned singleton: {}%, Misuse singleton: {}%)'\n",
    "    print(out.format(round((extinction + singleton + subtle_misalignment + misuse) * 100, 1),\n",
    "                     round(extinction * 100, 1),\n",
    "                     round(singleton * 100, 1),\n",
    "                     round(subtle_misalignment * 100, 1),\n",
    "                     round(misuse * 100, 1)))\n",
    "    print('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Have we seen the following wars by EOY year?')\n",
    "\n",
    "def print_wars(wars):\n",
    "    bs = [[w['belligerents'] if w != [] else [] for w in ws] for ws in wars]\n",
    "    bs = Counter([' '.join(sorted(b)) for b in bs])    \n",
    "    bs = dict([(k, round(v / RUNS * 100, 3)) for k, v in bs.items()])\n",
    "    bs = sorted(bs.items(), key=lambda x: x[1], reverse=True)\n",
    "    for war in ['US/China', 'US/Russia', 'Other']:\n",
    "        print('{}: {}%'.format(war, round(sum([b[1] if war in b[0] else 0 for b in bs]), 1)))\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    print_wars([c[y_c]['wars'] for c in collectors])\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Offensive nuclear weapon use (1+ fatality) by EOY year?')\n",
    "\n",
    "def p_nuke_used_by(y_c):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: e['collectors'][y_c]['nuclear_weapon_used'],\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('{}: {}%'.format(y_c, round(p_nuke_used_by(y_c) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Detail on war states')\n",
    "\n",
    "def print_wars(wars):\n",
    "    bs = [[w['belligerents'] if w != [] else [] for w in ws] for ws in wars]\n",
    "    bs = Counter([' '.join(sorted(b)) for b in bs])    \n",
    "    bs = dict([(k, round(v / RUNS * 100, 3)) for k, v in bs.items()])\n",
    "    bs = sorted(bs.items(), key=lambda x: x[1], reverse=True)\n",
    "    return bs\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_wars([c[y_c]['wars'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Detail on # of Wars At Year')\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## # of wars as of {} ##'.format(y_c))  \n",
    "    pprint(sq.get_percentiles([len(c[y_c]['wars']) for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Detail on War Length States At Year')\n",
    "\n",
    "def print_wars(y, wars):\n",
    "    bs = [[(w['end_year'] - w['start_year'] if w['end_year'] < y else y - w['start_year']) if w != [] else 0 for w in ws] for ws in wars]\n",
    "    bs = [round(sum(b) / (y - CURRENT_YEAR) * 100, 1) for b in bs]\n",
    "    return bs\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## Percent of time in war as of {} ##'.format(y_c))  \n",
    "    pprint(sq.get_percentiles(print_wars(y_c, [c[y_c]['wars'] for c in collectors])))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_states(states):\n",
    "    c = Counter(states)\n",
    "    c = dict([(k, round(v / RUNS * 100, 3)) for k, v in c.items()])\n",
    "    for k in c.keys():\n",
    "        if k not in STATES:\n",
    "            raise ValueError('State {} not in `STATES`'.format(k))\n",
    "    for state in STATES:\n",
    "        if not c.get(state):\n",
    "            c[state] = 0.0\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    return c\n",
    "\n",
    "\n",
    "print('Detail on World State At Year')\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c)) \n",
    "    pprint(print_states([c[y_c]['category'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Detail on Catastrophe States At Year')\n",
    "\n",
    "def print_catastrophe(catastrophes):\n",
    "    c = Counter([' '.join(sorted(c)) for c in catastrophes])\n",
    "    c = dict([(k, round(v / RUNS * 100, 2)) for k, v in c.items()])\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    c = [c_ for c_ in c if c_[1] >= 0.1]\n",
    "    return c\n",
    "\n",
    "for y_c in [2023, 2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_catastrophe([c[y_c]['catastrophe'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Detail on # of Catastrophes At Year')\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## # of catastrophes as of {} ##'.format(y_c))  \n",
    "    pprint(sq.get_percentiles([len(c[y_c]['catastrophe']) for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Detail on *First* Catastrophe State At Year')\n",
    "\n",
    "def print_catastrophe_first(catastrophes):\n",
    "    c = Counter([c[0] if len(c) > 0 else '' for c in catastrophes])\n",
    "    c = dict([(k, round(v / RUNS * 100, 2)) for k, v in c.items()])\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    c = [c_ for c_ in c if c_[1] >= 0.1]\n",
    "    return c\n",
    "\n",
    "for y_c in [2023, 2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_catastrophe_first([c[y_c]['catastrophe'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Detail on Double Catastrophe X-Risks')\n",
    "\n",
    "def print_double_catastrophes(catastrophes):\n",
    "    c = Counter(['' if c is None else c for c in catastrophes])\n",
    "    c = dict([(k, round(v / RUNS * 100, 3)) for k, v in c.items()])\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    # c = [c_ for c_ in c if c_[1] >= 0.1]\n",
    "    return c\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_double_catastrophes([c[y_c]['double_catastrophe_xrisk'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
