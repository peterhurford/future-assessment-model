{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1\n",
      "Loaded 2\n",
      "Loaded TAI timelines module\n",
      "Loaded anchors module\n",
      "Loaded Metaculus lib v0.3\n",
      "Loaded Metaculus module\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import squigglepy as sq\n",
    "from squigglepy import bayes\n",
    "from squigglepy.numbers import K, M, B, T\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime as dt\n",
    "print('Loaded 1')\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded 2')\n",
    "\n",
    "exec(open('modules/tai_timelines.py').read())\n",
    "print('Loaded TAI timelines module')\n",
    "\n",
    "exec(open('modules/anchors.py').read())\n",
    "print('Loaded anchors module')\n",
    "\n",
    "exec(open('/Users/peterhurford/dev/forecastflow/library.py').read()) # TODO: Package?\n",
    "print('Loaded Metaculus module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Timelines Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Default ##\n",
      "Default: 2044\n"
     ]
    }
   ],
   "source": [
    "CURRENT_YEAR = 2023                               # What year to start the run on? (default: 2023)\n",
    "MAX_YEAR = 2123                                   # What year to end the run on? (default: 2123)\n",
    "years = list(range(CURRENT_YEAR, MAX_YEAR))\n",
    "\n",
    "def print_year(y):\n",
    "    y = y['tai_year']\n",
    "    return '>{}'.format(MAX_YEAR) if y > MAX_YEAR else str(int(y))\n",
    "\n",
    "\n",
    "defaults = {'initial_gdp_': 23*T,\n",
    "            'tai_flop_size_': 32,\n",
    "            'algo_doubling_rate_': algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=31),\n",
    "            'possible_algo_reduction_': possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                   max_reduction=5,\n",
    "                                                                   tai_flop_size=31),\n",
    "            'initial_flop_per_dollar_': 10 ** 18.3,\n",
    "            'flop_halving_rate_': 2.5,\n",
    "            'max_flop_per_dollar_': 10 ** 24,\n",
    "            'initial_pay_': 10 ** 8.2,\n",
    "            'gdp_growth_': 1.02,\n",
    "            'max_gdp_frac_': 0.005,\n",
    "            'willingness_ramp_': 1,\n",
    "            'spend_doubling_time_': 3,\n",
    "            'spend_doubling_time_2025_': 1,\n",
    "            'nonscaling_delay_': {'delay': {'prob': 1, 'length': 4}},\n",
    "            'willingness_spend_horizon_': 1,\n",
    "            'print_diagnostic': False,\n",
    "            'variables': {'CURRENT_YEAR': CURRENT_YEAR, 'MAX_YEAR': MAX_YEAR}}\n",
    "\n",
    "print('## Default ##')\n",
    "result = run_tai_model_round(**defaults)\n",
    "print('{}: {}'.format('Default', print_year(result)))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## TAI FLOP Size ##\n",
      "FLOP Size for TAI 26 log FLOP -> 2027\n",
      "FLOP Size for TAI 27 log FLOP -> 2028\n",
      "FLOP Size for TAI 28 log FLOP -> 2031\n",
      "FLOP Size for TAI 29 log FLOP -> 2034\n",
      "FLOP Size for TAI 30 log FLOP -> 2038\n",
      "FLOP Size for TAI 31 log FLOP -> 2041\n",
      "FLOP Size for TAI 32 log FLOP -> 2043\n",
      "FLOP Size for TAI 33 log FLOP -> 2047\n",
      "FLOP Size for TAI 34 log FLOP -> 2051\n",
      "FLOP Size for TAI 35 log FLOP -> 2051\n",
      "FLOP Size for TAI 36 log FLOP -> 2056\n",
      "FLOP Size for TAI 37 log FLOP -> 2061\n",
      "FLOP Size for TAI 38 log FLOP -> 2062\n",
      "FLOP Size for TAI 39 log FLOP -> 2068\n",
      "FLOP Size for TAI 40 log FLOP -> 2082\n",
      "FLOP Size for TAI 41 log FLOP -> >2123\n",
      "FLOP Size for TAI 42 log FLOP -> >2123\n"
     ]
    }
   ],
   "source": [
    "print('## TAI FLOP Size ##')\n",
    "for t in range(26, 43):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['tai_flop_size_'] = t\n",
    "    varset['algo_doubling_rate_'] = algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=t)\n",
    "    varset['possible_algo_reduction_'] = possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                    max_reduction=5,\n",
    "                                                                    tai_flop_size=t)\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('FLOP Size for TAI {} log FLOP -> {}'.format(t, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GDP Growth ##\n",
      "GDP Growth Rate 1.0% -> 2044\n",
      "GDP Growth Rate 1.01% -> 2044\n",
      "GDP Growth Rate 1.02% -> 2044\n",
      "GDP Growth Rate 1.03% -> 2044\n",
      "GDP Growth Rate 1.04% -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## GDP Growth ##')\n",
    "for g in range(0, 5):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['gdp_growth_'] = 1 + (g / 100)\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('GDP Growth Rate {}% -> {}'.format(1 + g / 100, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Max GDP Frac ##\n",
      "Max GDP Frac 2e-06 (1 in ~500,000) -> 2055\n",
      "Max GDP Frac 4e-06 (1 in ~250,000) -> 2053\n",
      "Max GDP Frac 1e-05 (1 in ~100,000) -> 2051\n",
      "Max GDP Frac 2e-05 (1 in ~50,000) -> 2049\n",
      "Max GDP Frac 0.0001 (1 in ~10,000) -> 2046\n",
      "Max GDP Frac 0.0005 (1 in ~2,000) -> 2044\n",
      "Max GDP Frac 0.0005 (1 in ~2,000) -> 2044\n",
      "Max GDP Frac 0.000667 (1 in ~1,500) -> 2044\n",
      "Max GDP Frac 0.001 (1 in ~1,000) -> 2044\n",
      "Max GDP Frac 0.002 (1 in ~500) -> 2044\n",
      "Max GDP Frac 0.003 (1 in ~333) -> 2044\n",
      "Max GDP Frac 0.004 (1 in ~250) -> 2044\n",
      "Max GDP Frac 0.005 (1 in ~200) -> 2044\n",
      "Max GDP Frac 0.01 (1 in ~100) -> 2044\n",
      "Max GDP Frac 0.02 (1 in ~50) -> 2044\n",
      "Max GDP Frac 0.03 (1 in ~33) -> 2044\n",
      "Max GDP Frac 0.04 (1 in ~25) -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## Max GDP Frac ##')\n",
    "for g in [1/(500*K), 1/(250*K), 1/(100*K), 1/(50*K), 1/(10*K), 5/(10*K),\n",
    "          1/2000, 1/1500, 1/1000, 2/1000, 3/1000, 4/1000, 5/1000, 1/100,\n",
    "          2/100, 3/100, 4/100]:\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['max_gdp_frac_'] = g\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Max GDP Frac {} (1 in ~{:,}) -> {}'.format(round(g, 6), int(round(1 / g)), print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Spend Doubling Time ##\n",
      "Spend Doubling Time 1.0yrs -> 2040\n",
      "Spend Doubling Time 1.2yrs -> 2039\n",
      "Spend Doubling Time 1.4yrs -> 2040\n",
      "Spend Doubling Time 1.6yrs -> 2041\n",
      "Spend Doubling Time 1.8yrs -> 2041\n",
      "Spend Doubling Time 2.0yrs -> 2042\n",
      "Spend Doubling Time 2.2yrs -> 2042\n",
      "Spend Doubling Time 2.4yrs -> 2043\n",
      "Spend Doubling Time 2.6yrs -> 2043\n",
      "Spend Doubling Time 2.8yrs -> 2044\n",
      "Spend Doubling Time 3.0yrs -> 2044\n",
      "Spend Doubling Time 3.2yrs -> 2044\n",
      "Spend Doubling Time 3.4yrs -> 2045\n",
      "Spend Doubling Time 3.6yrs -> 2045\n",
      "Spend Doubling Time 3.8yrs -> 2045\n",
      "Spend Doubling Time 4.0yrs -> 2045\n",
      "Spend Doubling Time 4.2yrs -> 2046\n",
      "Spend Doubling Time 4.4yrs -> 2046\n",
      "Spend Doubling Time 4.6yrs -> 2046\n",
      "Spend Doubling Time 4.8yrs -> 2046\n",
      "Spend Doubling Time 5.0yrs -> 2046\n",
      "Spend Doubling Time 5.2yrs -> 2046\n",
      "Spend Doubling Time 5.4yrs -> 2047\n",
      "Spend Doubling Time 5.6yrs -> 2047\n",
      "Spend Doubling Time 5.8yrs -> 2047\n",
      "Spend Doubling Time 6.0yrs -> 2047\n"
     ]
    }
   ],
   "source": [
    "print('## Spend Doubling Time ##')\n",
    "for d in range(0, 51, 2):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['spend_doubling_time_'] = 1 + (d / 10)\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Spend Doubling Time {}yrs -> {}'.format(1 + d / 10, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Spend Doubling Time for 2023-2025 ##\n",
      "Spend Doubling Time (2023-2025) 0.5yrs -> 2042\n",
      "Spend Doubling Time (2023-2025) 0.6yrs -> 2043\n",
      "Spend Doubling Time (2023-2025) 0.7yrs -> 2043\n",
      "Spend Doubling Time (2023-2025) 0.8yrs -> 2043\n",
      "Spend Doubling Time (2023-2025) 0.9yrs -> 2044\n",
      "Spend Doubling Time (2023-2025) 1.0yrs -> 2044\n",
      "Spend Doubling Time (2023-2025) 1.1yrs -> 2044\n",
      "Spend Doubling Time (2023-2025) 1.2yrs -> 2044\n",
      "Spend Doubling Time (2023-2025) 1.3yrs -> 2044\n",
      "Spend Doubling Time (2023-2025) 1.4yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 1.5yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 1.6yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 1.7yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 1.8yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 1.9yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.0yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.1yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.2yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.3yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.4yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.5yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.6yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.7yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.8yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 2.9yrs -> 2045\n",
      "Spend Doubling Time (2023-2025) 3.0yrs -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Spend Doubling Time for 2023-2025 ##')\n",
    "for d in range(5, 31, 1):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['spend_doubling_time_2025_'] = d / 10\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Spend Doubling Time (2023-2025) {}yrs -> {}'.format(d / 10, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Initial FLOP per dollar ##\n",
      "Initial log FLOP per dollar 17 -> 2049\n",
      "Initial log FLOP per dollar 17.5 -> 2047\n",
      "Initial log FLOP per dollar 18 -> 2045\n",
      "Initial log FLOP per dollar 18.3 -> 2044\n",
      "Initial log FLOP per dollar 18.5 -> 2043\n",
      "Initial log FLOP per dollar 19 -> 2042\n"
     ]
    }
   ],
   "source": [
    "print('## Initial FLOP per dollar ##')\n",
    "for d in [17, 17.5, 18, 18.3, 18.5, 19]:\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['initial_flop_per_dollar_'] = 10 ** d\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Initial log FLOP per dollar {} -> {}'.format(d, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Initial pay ##\n",
      "Initial pay in log 2022$USD 7.0 (~$10 million) -> 2048\n",
      "Initial pay in log 2022$USD 7.2 (~$16 million) -> 2047\n",
      "Initial pay in log 2022$USD 7.4 (~$25 million) -> 2047\n",
      "Initial pay in log 2022$USD 7.6 (~$40 million) -> 2046\n",
      "Initial pay in log 2022$USD 7.8 (~$63 million) -> 2045\n",
      "Initial pay in log 2022$USD 8.0 (~$100 million) -> 2045\n",
      "Initial pay in log 2022$USD 8.2 (~$158 million) -> 2044\n",
      "Initial pay in log 2022$USD 8.4 (~$251 million) -> 2043\n",
      "Initial pay in log 2022$USD 8.6 (~$398 million) -> 2043\n",
      "Initial pay in log 2022$USD 8.8 (~$631 million) -> 2042\n",
      "Initial pay in log 2022$USD 9.0 (~$1 billion) -> 2041\n",
      "Initial pay in log 2022$USD 9.2 (~$2 billion) -> 2041\n",
      "Initial pay in log 2022$USD 9.4 (~$3 billion) -> 2040\n",
      "Initial pay in log 2022$USD 9.6 (~$4 billion) -> 2040\n",
      "Initial pay in log 2022$USD 9.8 (~$6 billion) -> 2039\n",
      "Initial pay in log 2022$USD 10.0 (~$10 billion) -> 2039\n"
     ]
    }
   ],
   "source": [
    "print('## Initial pay ##')\n",
    "for p in range(70, 101, 2):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['initial_pay_'] = 10 ** (p / 10)\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Initial pay in log 2022$USD {} (~${}) -> {}'.format(p / 10, numerize(10 ** (p / 10)), print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## FLOP halving rate ##\n",
      "FLOP halving rate 0.5 -> 2034\n",
      "FLOP halving rate 0.6 -> 2035\n",
      "FLOP halving rate 0.7 -> 2036\n",
      "FLOP halving rate 0.8 -> 2036\n",
      "FLOP halving rate 0.9 -> 2037\n",
      "FLOP halving rate 1.0 -> 2038\n",
      "FLOP halving rate 1.1 -> 2038\n",
      "FLOP halving rate 1.2 -> 2039\n",
      "FLOP halving rate 1.3 -> 2039\n",
      "FLOP halving rate 1.4 -> 2040\n",
      "FLOP halving rate 1.5 -> 2040\n",
      "FLOP halving rate 1.6 -> 2041\n",
      "FLOP halving rate 1.7 -> 2041\n",
      "FLOP halving rate 1.8 -> 2042\n",
      "FLOP halving rate 1.9 -> 2042\n",
      "FLOP halving rate 2.0 -> 2042\n",
      "FLOP halving rate 2.1 -> 2043\n",
      "FLOP halving rate 2.2 -> 2043\n",
      "FLOP halving rate 2.3 -> 2043\n",
      "FLOP halving rate 2.4 -> 2044\n",
      "FLOP halving rate 2.5 -> 2044\n",
      "FLOP halving rate 2.6 -> 2044\n",
      "FLOP halving rate 2.7 -> 2044\n",
      "FLOP halving rate 2.8 -> 2045\n",
      "FLOP halving rate 2.9 -> 2045\n",
      "FLOP halving rate 3.0 -> 2045\n",
      "FLOP halving rate 3.1 -> 2045\n",
      "FLOP halving rate 3.2 -> 2046\n",
      "FLOP halving rate 3.3 -> 2046\n",
      "FLOP halving rate 3.4 -> 2046\n",
      "FLOP halving rate 3.5 -> 2046\n",
      "FLOP halving rate 3.6 -> 2046\n",
      "FLOP halving rate 3.7 -> 2047\n",
      "FLOP halving rate 3.8 -> 2047\n",
      "FLOP halving rate 3.9 -> 2047\n",
      "FLOP halving rate 4.0 -> 2047\n"
     ]
    }
   ],
   "source": [
    "print('## FLOP halving rate ##')\n",
    "for f in range(5, 41):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['flop_halving_rate_'] = f / 10\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('FLOP halving rate {} -> {}'.format(f / 10, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Max FLOP per dollar ##\n",
      "Max log FLOP per 2022USD$1 = 20 -> 2046\n",
      "Max log FLOP per 2022USD$1 = 21 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 22 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 23 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 24 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 25 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 26 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 27 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 28 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 29 -> 2044\n",
      "Max log FLOP per 2022USD$1 = 30 -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## Max FLOP per dollar ##')\n",
    "for f in range(20, 31):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['max_flop_per_dollar_'] = 10 ** f\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Max log FLOP per 2022USD$1 = {} -> {}'.format(f, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Algo Doubling Rate Minimum ##\n",
      "Algo doubling rate minimum 1 -> 2043\n",
      "Algo doubling rate minimum 1.3 -> 2043\n",
      "Algo doubling rate minimum 1.5 -> 2043\n",
      "Algo doubling rate minimum 2 -> 2043\n",
      "Algo doubling rate minimum 2.5 -> 2043\n",
      "Algo doubling rate minimum 3 -> 2044\n",
      "Algo doubling rate minimum 3.5 -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Algo Doubling Rate Minimum ##')\n",
    "for m in [1, 1.3, 1.5, 2, 2.5, 3, 3.5]:\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['algo_doubling_rate_'] = algo_halving_fn(min_speed=m, max_speed=3.5, tai_flop_size=defaults['tai_flop_size_'])\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Algo doubling rate minimum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Algo Doubling Rate Maximum ##\n",
      "Algo doubling rate maximum 2 -> 2042\n",
      "Algo doubling rate maximum 2.5 -> 2042\n",
      "Algo doubling rate maximum 3 -> 2042\n",
      "Algo doubling rate maximum 3.5 -> 2043\n",
      "Algo doubling rate maximum 4 -> 2044\n",
      "Algo doubling rate maximum 4.5 -> 2045\n",
      "Algo doubling rate maximum 5 -> 2045\n",
      "Algo doubling rate maximum 6 -> 2046\n"
     ]
    }
   ],
   "source": [
    "print('## Algo Doubling Rate Maximum ##')\n",
    "for m in [2, 2.5, 3, 3.5, 4, 4.5, 5, 6]:\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['algo_doubling_rate_'] = algo_halving_fn(min_speed=2, max_speed=m, tai_flop_size=defaults['tai_flop_size_'])\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Algo doubling rate maximum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Possible Algo Reduction minimum ##\n",
      "Possible algo reduction minimum 0 -> 2051\n",
      "Possible algo reduction minimum 1 -> 2046\n",
      "Possible algo reduction minimum 2 -> 2044\n",
      "Possible algo reduction minimum 3 -> 2043\n",
      "Possible algo reduction minimum 4 -> 2043\n",
      "Possible algo reduction minimum 5 -> 2043\n"
     ]
    }
   ],
   "source": [
    "print('## Possible Algo Reduction minimum ##')\n",
    "for m in [0, 1, 2, 3, 4, 5]:\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['possible_algo_reduction_'] = possible_algo_reduction_fn(min_reduction=m,\n",
    "                                                                    max_reduction=5,\n",
    "                                                                    tai_flop_size=defaults['tai_flop_size_'])\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Possible algo reduction minimum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Possible Algo Reduction maximum ##\n",
      "Possible algo reduction maximum 2 -> 2044\n",
      "Possible algo reduction maximum 3 -> 2044\n",
      "Possible algo reduction maximum 4 -> 2044\n",
      "Possible algo reduction maximum 5 -> 2044\n",
      "Possible algo reduction maximum 6 -> 2044\n",
      "Possible algo reduction maximum 7 -> 2044\n",
      "Possible algo reduction maximum 8 -> 2044\n",
      "Possible algo reduction maximum 9 -> 2044\n",
      "Possible algo reduction maximum 10 -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## Possible Algo Reduction maximum ##')\n",
    "for m in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['possible_algo_reduction_'] = possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                    max_reduction=m,\n",
    "                                                                    tai_flop_size=defaults['tai_flop_size_'])\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Possible algo reduction maximum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Willingness ramp ##\n",
      "Willingness ramp 10.0x -> 2041\n",
      "Willingness ramp 5.0x -> 2042\n",
      "Willingness ramp 3.3x -> 2042\n",
      "Willingness ramp 2.5x -> 2043\n",
      "Willingness ramp 2.0x -> 2043\n",
      "Willingness ramp 1.7x -> 2043\n",
      "Willingness ramp 1.4x -> 2043\n",
      "Willingness ramp 1.2x -> 2044\n",
      "Willingness ramp 1.1x -> 2044\n",
      "Willingness ramp 1.0x -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## Willingness ramp ##')\n",
    "for r in range(1, 11):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['willingness_ramp_'] = r / 10\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Willingness ramp {}x -> {}'.format(round(10 / r, 1), print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Willingness spend horizon ##\n",
      "Willingness spend horizon 1yrs -> 2044\n",
      "Willingness spend horizon 2yrs -> 2044\n",
      "Willingness spend horizon 3yrs -> 2044\n",
      "Willingness spend horizon 4yrs -> 2044\n",
      "Willingness spend horizon 5yrs -> 2044\n",
      "Willingness spend horizon 6yrs -> 2044\n",
      "Willingness spend horizon 7yrs -> 2044\n",
      "Willingness spend horizon 8yrs -> 2044\n",
      "Willingness spend horizon 9yrs -> 2044\n",
      "Willingness spend horizon 10yrs -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## Willingness spend horizon ##')\n",
    "for h in range(1, 11):\n",
    "    varset = deepcopy(defaults)\n",
    "    varset['willingness_spend_horizon_'] = h\n",
    "    result = run_tai_model_round(**varset)\n",
    "    print('Willingness spend horizon {}yrs -> {}'.format(h, print_year(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11558 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates?\n",
      "6517 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (Feb-2023)\n",
      "Resolved as 688639.124123147\n",
      "-\n",
      "6559 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (Jan-2026)\n",
      "Me -\n",
      "* Min: 3640\n",
      "* <Min: 0\n",
      "* Q1: 3568581.524\n",
      "* Mid: 14150587.477\n",
      "* Q3: 56111686.0\n",
      "* >Max: 0.027000000000000024\n",
      "* Max: 1000000000\n",
      "Metaculus -\n",
      "* Min: 3640\n",
      "* <Min: 0.0\n",
      "* Q1: 618087.295\n",
      "* Mid: 5889135.777\n",
      "* Q3: 49506740.334\n",
      "* >Max: 0.11153000000000002\n",
      "* Max: 1000000000\n",
      "-\n",
      "6192 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (Jan-2031)\n",
      "Me -\n",
      "* Min: 1800\n",
      "* <Min: 0\n",
      "* Q1: 4242640.687\n",
      "* Mid: 20049751.859\n",
      "* Q3: 37316259.269\n",
      "* >Max: 0.014000000000000012\n",
      "* Max: 10000000000\n",
      "Metaculus -\n",
      "* Min: 1800\n",
      "* <Min: 0.0\n",
      "* Q1: 3109866.189\n",
      "* Mid: 31948526.063\n",
      "* Q3: 383360379.303\n",
      "* >Max: 0.08740999999999999\n",
      "* Max: 10000000000\n",
      "-\n",
      "6148 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (Jan-2022)\n",
      "Resolved as 320532.1027084993\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "get_question(11558)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "## 2022 ##\n",
      "25th: 24.5 max log FLOPs / ~40911 petaFLOP/s-days)\n",
      "mean: 25.7 max log FLOPs / ~619751 petaFLOP/s-days)\n",
      "75th: 26.8 max log FLOPs / ~7265380 petaFLOP/s-days)\n",
      "-\n",
      "## 2025 ##\n",
      "25th: 25.9 max log FLOPs / ~924379 petaFLOP/s-days)\n",
      "mean: 26.5 max log FLOPs / ~4021998 petaFLOP/s-days)\n",
      "75th: 27.4 max log FLOPs / ~28976286 petaFLOP/s-days)\n",
      "-\n",
      "## 2030 ##\n",
      "25th: 28.1 max log FLOPs / ~159863445 petaFLOP/s-days)\n",
      "mean: 27.9 max log FLOPs / ~90261450 petaFLOP/s-days)\n",
      "75th: 28.4 max log FLOPs / ~288816073 petaFLOP/s-days)\n"
     ]
    }
   ],
   "source": [
    "# https://www.metaculus.com/questions/11558/maximum-compute-used-in-ai-training/\n",
    "# TODO: Fetch from Metaculus, look side by side\n",
    "# TODO: Be able to predict back\n",
    "for y in [2022, 2025, 2030]:\n",
    "    print('-')\n",
    "    print('## {} ##'.format(y))\n",
    "    for i in range(3):\n",
    "        flop_at_max_ = flop_at_max(initial_gdp=defaults['initial_gdp_'],\n",
    "                                   gdp_growth=[1.02, 1.025, 1.03][i],\n",
    "                                   initial_pay=[10*M, 100*M, 1*B][i],\n",
    "                                   spend_doubling_time=[1, 2, 3][i],\n",
    "                                   max_gdp_frac=[1/1000, 4/1000, 1/100][i],\n",
    "                                   initial_flop_per_dollar=10 ** 18,\n",
    "                                   max_flop_per_dollar=10 ** 24,\n",
    "                                   flop_halving_rate=[2, 2.5, 3][i],\n",
    "                                   year=(y - CURRENT_YEAR))\n",
    "\n",
    "        print('{}: {} max log FLOPs / ~{} petaFLOP/s-days)'.format(['25th', 'mean', '75th'][i],\n",
    "                                                                   np.round(np.log10(flop_at_max_), 1),\n",
    "                                                                   log_flop_to_petaflop_sdays(np.log10(flop_at_max_))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain 11 -> 25.4 log FLOP\n",
      "Brain 12 -> 26.2 log FLOP\n",
      "Brain 13 -> 27.1 log FLOP\n",
      "Brain 14 -> 27.8 log FLOP\n",
      "Brain 15 -> 29.8 log FLOP\n",
      "Brain 16 -> 31.8 log FLOP\n",
      "Brain 17 -> 33.8 log FLOP\n",
      "Brain 18 -> 35.8 log FLOP\n",
      "Brain 19 -> 37.8 log FLOP\n",
      "Brain 20 -> 39.8 log FLOP\n"
     ]
    }
   ],
   "source": [
    "for b in range(11, 21):\n",
    "    anchor = tai_log_flop_needs(brain=b,\n",
    "                                efficiency=0,\n",
    "                                transformative_vs_human=0,\n",
    "                                horizon_length=0,\n",
    "                                scaling_exponent=1,\n",
    "                                flops_per_param_per_sec=1,\n",
    "                                bayes_update=peter_bayes_update_against_low_flop) @ 2\n",
    "    print('Brain {} -> {} log FLOP'.format(b, round(anchor[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency -2 -> 28.2 log FLOP\n",
      "Efficiency -1 -> 27.8 log FLOP\n",
      "Efficiency 0 -> 29.8 log FLOP\n",
      "Efficiency 1 -> 31.8 log FLOP\n",
      "Efficiency 2 -> 33.8 log FLOP\n",
      "Efficiency 3 -> 35.8 log FLOP\n",
      "Efficiency 4 -> 37.8 log FLOP\n",
      "Efficiency 5 -> 39.8 log FLOP\n"
     ]
    }
   ],
   "source": [
    "for e in range(-2, 6):\n",
    "    anchor = tai_log_flop_needs(brain=15,\n",
    "                                efficiency=e,\n",
    "                                transformative_vs_human=0,\n",
    "                                horizon_length=0,\n",
    "                                scaling_exponent=1,\n",
    "                                flops_per_param_per_sec=1,\n",
    "                                bayes_update=peter_bayes_update_against_low_flop) @ 2\n",
    "    print('Efficiency {} -> {} log FLOP'.format(e, round(anchor[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformative vs. human -3 -> 26.8 log FLOP\n",
      "Transformative vs. human -2 -> 27.8 log FLOP\n",
      "Transformative vs. human -1 -> 28.8 log FLOP\n",
      "Transformative vs. human 0 -> 29.8 log FLOP\n",
      "Transformative vs. human 1 -> 30.8 log FLOP\n",
      "Transformative vs. human 2 -> 31.8 log FLOP\n",
      "Transformative vs. human 3 -> 32.8 log FLOP\n"
     ]
    }
   ],
   "source": [
    "for t in range(-3, 4):\n",
    "    anchor = tai_log_flop_needs(brain=15,\n",
    "                                efficiency=0,\n",
    "                                transformative_vs_human=t,\n",
    "                                horizon_length=0,\n",
    "                                scaling_exponent=1,\n",
    "                                flops_per_param_per_sec=1,\n",
    "                                bayes_update=peter_bayes_update_against_low_flop) @ 2\n",
    "    print('Transformative vs. human {} -> {} log FLOP'.format(t, round(anchor[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horizon length 0 -> 29.8 log FLOP\n",
      "Horizon length 1 -> 30.8 log FLOP\n",
      "Horizon length 2 -> 31.8 log FLOP\n",
      "Horizon length 3 -> 32.8 log FLOP\n",
      "Horizon length 4 -> 33.8 log FLOP\n",
      "Horizon length 5 -> 34.8 log FLOP\n",
      "Horizon length 6 -> 35.8 log FLOP\n",
      "Horizon length 7 -> 36.8 log FLOP\n",
      "Horizon length 8 -> 37.8 log FLOP\n",
      "Horizon length 9 -> 38.8 log FLOP\n"
     ]
    }
   ],
   "source": [
    "for h in range(0, 10):\n",
    "    anchor = tai_log_flop_needs(brain=15,\n",
    "                                efficiency=0,\n",
    "                                transformative_vs_human=0,\n",
    "                                horizon_length=h,\n",
    "                                scaling_exponent=1,\n",
    "                                flops_per_param_per_sec=1,\n",
    "                                bayes_update=peter_bayes_update_against_low_flop) @ 2\n",
    "    print('Horizon length {} -> {} log FLOP'.format(h, round(anchor[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling exponent 0.5 -> 28.4 log FLOP\n",
      "Scaling exponent 0.6 -> 28.7 log FLOP\n",
      "Scaling exponent 0.7 -> 29.0 log FLOP\n",
      "Scaling exponent 0.8 -> 29.2 log FLOP\n",
      "Scaling exponent 0.9 -> 29.5 log FLOP\n",
      "Scaling exponent 1.0 -> 29.8 log FLOP\n",
      "Scaling exponent 1.1 -> 30.1 log FLOP\n",
      "Scaling exponent 1.2 -> 30.4 log FLOP\n",
      "Scaling exponent 1.3 -> 30.6 log FLOP\n",
      "Scaling exponent 1.4 -> 30.9 log FLOP\n",
      "Scaling exponent 1.5 -> 31.2 log FLOP\n"
     ]
    }
   ],
   "source": [
    "for s in range(5, 16):\n",
    "    anchor = tai_log_flop_needs(brain=15,\n",
    "                                efficiency=0,\n",
    "                                transformative_vs_human=0,\n",
    "                                horizon_length=0,\n",
    "                                scaling_exponent=s / 10,\n",
    "                                flops_per_param_per_sec=1,\n",
    "                                bayes_update=peter_bayes_update_against_low_flop) @ 2\n",
    "    print('Scaling exponent {} -> {} log FLOP'.format(s / 10, round(anchor[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS per param per sec 1.0 -> 25.3 log FLOP\n",
      "FLOPS per param per sec 1.1 -> 24.4 log FLOP\n",
      "FLOPS per param per sec 1.2 -> 23.9 log FLOP\n",
      "FLOPS per param per sec 1.3 -> 23.8 log FLOP\n",
      "FLOPS per param per sec 1.4 -> 25.1 log FLOP\n",
      "FLOPS per param per sec 1.5 -> 24.6 log FLOP\n",
      "FLOPS per param per sec 1.6 -> 23.0 log FLOP\n",
      "FLOPS per param per sec 1.7 -> 24 log FLOP\n",
      "FLOPS per param per sec 1.8 -> 23 log FLOP\n",
      "FLOPS per param per sec 1.9 -> 25 log FLOP\n",
      "FLOPS per param per sec 2.0 -> 23 log FLOP\n"
     ]
    }
   ],
   "source": [
    "for fppps in range(10, 21):\n",
    "    anchor = tai_log_flop_needs(brain=15,\n",
    "                                efficiency=0,\n",
    "                                transformative_vs_human=0,\n",
    "                                horizon_length=0,\n",
    "                                scaling_exponent=1,\n",
    "                                flops_per_param_per_sec=fppps,\n",
    "                                bayes_update=peter_bayes_update_against_low_flop) @ 2\n",
    "    print('FLOPS per param per sec {} -> {} log FLOP'.format(fppps / 10, round(anchor[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes FN none -> 19.8 log FLOP\n",
      "Bayes FN Peter -> 25.5 log FLOP\n",
      "Bayes FN Cotra -> 25.2 log FLOP\n"
     ]
    }
   ],
   "source": [
    "for bayes_fn in [[None, 'none'],\n",
    "                 [peter_bayes_update_against_low_flop, 'Peter'],\n",
    "                 [cotra_bayes_update_against_low_flop, 'Cotra']]:\n",
    "    anchor = tai_log_flop_needs(brain=10,\n",
    "                                efficiency=0,\n",
    "                                transformative_vs_human=0,\n",
    "                                horizon_length=0,\n",
    "                                scaling_exponent=1,\n",
    "                                flops_per_param_per_sec=1,\n",
    "                                bayes_update=bayes_fn[0])\n",
    "    if bayes_fn[0] is not None:\n",
    "        anchor = (anchor @ 2)[0]\n",
    "    print('Bayes FN {} -> {} log FLOP'.format(bayes_fn[1], round(anchor, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File last ran: 2023-07-09 16:28:52.549945\n"
     ]
    }
   ],
   "source": [
    "print('File last ran: {}'.format(dt.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
