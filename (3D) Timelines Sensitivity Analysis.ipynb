{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1\n",
      "Loaded 2\n",
      "Loaded TAI timelines module\n",
      "Loaded Metaculus lib v0.2\n",
      "Loaded Metaculus module\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import squigglepy as sq\n",
    "from squigglepy import bayes\n",
    "from squigglepy.numbers import K, M, B, T\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "print('Loaded 1')\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded 2')\n",
    "\n",
    "exec(open('modules/tai_timelines.py').read())\n",
    "print('Loaded TAI timelines module')\n",
    "\n",
    "exec(open('/Users/peterhurford/dev/forecastflow/library.py').read()) # TODO: Package?\n",
    "print('Loaded Metaculus module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Timelines Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Default ##\n",
      "Default: 2045\n"
     ]
    }
   ],
   "source": [
    "CURRENT_YEAR = 2023                               # What year to start the run on? (default: 2023)\n",
    "MAX_YEAR = 2123                                   # What year to end the run on? (default: 2123)\n",
    "years = list(range(CURRENT_YEAR, MAX_YEAR))\n",
    "\n",
    "def print_year(y):\n",
    "    return '>{}'.format(MAX_YEAR) if y > MAX_YEAR else str(int(y))\n",
    "\n",
    "\n",
    "print('## Default ##')\n",
    "result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                             tai_flop_size_=34,\n",
    "                             nonscaling_delay_=0,\n",
    "                             algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                             possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                 max_reduction=5,\n",
    "                                                                                 tai_flop_size=34),\n",
    "                             initial_flop_per_dollar_=10 ** 18.3,\n",
    "                             flop_halving_rate_=2.5,\n",
    "                             max_flop_per_dollar_=10 ** 24,\n",
    "                             initial_pay_=10 ** 9,\n",
    "                             gdp_growth_=1.03,\n",
    "                             max_gdp_frac_=0.01,\n",
    "                             willingness_ramp_=1,\n",
    "                             spend_doubling_time_=2.5,\n",
    "                             p_nonscaling_delay=None,\n",
    "                             willingness_spend_horizon_=1,\n",
    "                             print_diagnostic=False)\n",
    "print('{}: {}'.format('Default', print_year(result)))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## TAI FLOP Size ##\n",
      "FLOP Size for TAI 26 log FLOP -> 2023\n",
      "FLOP Size for TAI 27 log FLOP -> 2023\n",
      "FLOP Size for TAI 28 log FLOP -> 2026\n",
      "FLOP Size for TAI 29 log FLOP -> 2029\n",
      "FLOP Size for TAI 30 log FLOP -> 2032\n",
      "FLOP Size for TAI 31 log FLOP -> 2035\n",
      "FLOP Size for TAI 32 log FLOP -> 2037\n",
      "FLOP Size for TAI 33 log FLOP -> 2040\n",
      "FLOP Size for TAI 34 log FLOP -> 2045\n",
      "FLOP Size for TAI 35 log FLOP -> 2045\n",
      "FLOP Size for TAI 36 log FLOP -> 2050\n",
      "FLOP Size for TAI 37 log FLOP -> 2056\n",
      "FLOP Size for TAI 38 log FLOP -> 2057\n",
      "FLOP Size for TAI 39 log FLOP -> 2064\n",
      "FLOP Size for TAI 40 log FLOP -> 2078\n",
      "FLOP Size for TAI 41 log FLOP -> >2123\n",
      "FLOP Size for TAI 42 log FLOP -> >2123\n"
     ]
    }
   ],
   "source": [
    "print('## TAI FLOP Size ##')\n",
    "for t in range(26, 43):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=t,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=t),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=t),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('FLOP Size for TAI {} log FLOP -> {}'.format(t, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GDP Growth ##\n",
      "GDP Growth Rate 1.0% -> 2045\n",
      "GDP Growth Rate 1.01% -> 2045\n",
      "GDP Growth Rate 1.02% -> 2045\n",
      "GDP Growth Rate 1.03% -> 2045\n",
      "GDP Growth Rate 1.04% -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## GDP Growth ##')\n",
    "for g in range(0, 5):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1 + (g / 100),\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('GDP Growth Rate {}% -> {}'.format(1 + g / 100, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Max GDP Frac ##\n",
      "Max GDP Frac 2e-06 (1 in ~500,000) -> 2071\n",
      "Max GDP Frac 4e-06 (1 in ~250,000) -> 2068\n",
      "Max GDP Frac 1e-05 (1 in ~100,000) -> 2064\n",
      "Max GDP Frac 2e-05 (1 in ~50,000) -> 2062\n",
      "Max GDP Frac 0.0001 (1 in ~10,000) -> 2056\n",
      "Max GDP Frac 0.0005 (1 in ~2,000) -> 2051\n",
      "Max GDP Frac 0.0005 (1 in ~2,000) -> 2051\n",
      "Max GDP Frac 0.000667 (1 in ~1,500) -> 2050\n",
      "Max GDP Frac 0.001 (1 in ~1,000) -> 2049\n",
      "Max GDP Frac 0.002 (1 in ~500) -> 2047\n",
      "Max GDP Frac 0.003 (1 in ~333) -> 2046\n",
      "Max GDP Frac 0.004 (1 in ~250) -> 2046\n",
      "Max GDP Frac 0.005 (1 in ~200) -> 2045\n",
      "Max GDP Frac 0.01 (1 in ~100) -> 2045\n",
      "Max GDP Frac 0.02 (1 in ~50) -> 2044\n",
      "Max GDP Frac 0.03 (1 in ~33) -> 2044\n",
      "Max GDP Frac 0.04 (1 in ~25) -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## Max GDP Frac ##')\n",
    "for g in [1/(500*K), 1/(250*K), 1/(100*K), 1/(50*K), 1/(10*K), 5/(10*K),\n",
    "          1/2000, 1/1500, 1/1000, 2/1000, 3/1000, 4/1000, 5/1000, 1/100,\n",
    "          2/100, 3/100, 4/100]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=g,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Max GDP Frac {} (1 in ~{:,}) -> {}'.format(round(g, 6), int(round(1 / g)), print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Spend Doubling Time ##\n",
      "Spend Doubling Time 1.0yrs -> 2042\n",
      "Spend Doubling Time 1.2yrs -> 2042\n",
      "Spend Doubling Time 1.4yrs -> 2043\n",
      "Spend Doubling Time 1.6yrs -> 2043\n",
      "Spend Doubling Time 1.8yrs -> 2043\n",
      "Spend Doubling Time 2.0yrs -> 2043\n",
      "Spend Doubling Time 2.2yrs -> 2044\n",
      "Spend Doubling Time 2.4yrs -> 2044\n",
      "Spend Doubling Time 2.6yrs -> 2045\n",
      "Spend Doubling Time 2.8yrs -> 2045\n",
      "Spend Doubling Time 3.0yrs -> 2046\n",
      "Spend Doubling Time 3.2yrs -> 2046\n",
      "Spend Doubling Time 3.4yrs -> 2047\n",
      "Spend Doubling Time 3.6yrs -> 2047\n",
      "Spend Doubling Time 3.8yrs -> 2048\n",
      "Spend Doubling Time 4.0yrs -> 2048\n",
      "Spend Doubling Time 4.2yrs -> 2048\n",
      "Spend Doubling Time 4.4yrs -> 2049\n",
      "Spend Doubling Time 4.6yrs -> 2049\n",
      "Spend Doubling Time 4.8yrs -> 2050\n",
      "Spend Doubling Time 5.0yrs -> 2050\n",
      "Spend Doubling Time 5.2yrs -> 2050\n",
      "Spend Doubling Time 5.4yrs -> 2050\n",
      "Spend Doubling Time 5.6yrs -> 2051\n",
      "Spend Doubling Time 5.8yrs -> 2051\n",
      "Spend Doubling Time 6.0yrs -> 2051\n"
     ]
    }
   ],
   "source": [
    "print('## Spend Doubling Time ##')\n",
    "for d in range(0, 51, 2):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=1 + (d / 10),\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Spend Doubling Time {}yrs -> {}'.format(1 + d / 10, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Initial FLOP per dollar ##\n",
      "Initial log FLOP per dollar 17 -> 2052\n",
      "Initial log FLOP per dollar 17.5 -> 2049\n",
      "Initial log FLOP per dollar 18 -> 2046\n",
      "Initial log FLOP per dollar 18.3 -> 2045\n",
      "Initial log FLOP per dollar 18.5 -> 2044\n",
      "Initial log FLOP per dollar 19 -> 2042\n"
     ]
    }
   ],
   "source": [
    "print('## Initial FLOP per dollar ##')\n",
    "for d in [17, 17.5, 18, 18.3, 18.5, 19]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** d,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Initial log FLOP per dollar {} -> {}'.format(d, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Initial pay ##\n",
      "Initial pay in log 2022$USD 7.0 (~$10 million) -> 2051\n",
      "Initial pay in log 2022$USD 7.2 (~$16 million) -> 2051\n",
      "Initial pay in log 2022$USD 7.4 (~$25 million) -> 2050\n",
      "Initial pay in log 2022$USD 7.6 (~$40 million) -> 2049\n",
      "Initial pay in log 2022$USD 7.8 (~$63 million) -> 2048\n",
      "Initial pay in log 2022$USD 8.0 (~$100 million) -> 2048\n",
      "Initial pay in log 2022$USD 8.2 (~$158 million) -> 2047\n",
      "Initial pay in log 2022$USD 8.4 (~$251 million) -> 2046\n",
      "Initial pay in log 2022$USD 8.6 (~$398 million) -> 2046\n",
      "Initial pay in log 2022$USD 8.8 (~$631 million) -> 2045\n",
      "Initial pay in log 2022$USD 9.0 (~$1 billion) -> 2045\n",
      "Initial pay in log 2022$USD 9.2 (~$2 billion) -> 2044\n",
      "Initial pay in log 2022$USD 9.4 (~$3 billion) -> 2044\n",
      "Initial pay in log 2022$USD 9.6 (~$4 billion) -> 2043\n",
      "Initial pay in log 2022$USD 9.8 (~$6 billion) -> 2043\n",
      "Initial pay in log 2022$USD 10.0 (~$10 billion) -> 2043\n"
     ]
    }
   ],
   "source": [
    "print('## Initial pay ##')\n",
    "for p in range(70, 101, 2):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** (p / 10),\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Initial pay in log 2022$USD {} (~${}) -> {}'.format(p / 10, numerize(10 ** (p / 10)), print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## FLOP halving rate ##\n",
      "FLOP halving rate 0.5 -> 2032\n",
      "FLOP halving rate 0.6 -> 2033\n",
      "FLOP halving rate 0.7 -> 2034\n",
      "FLOP halving rate 0.8 -> 2035\n",
      "FLOP halving rate 0.9 -> 2035\n",
      "FLOP halving rate 1.0 -> 2036\n",
      "FLOP halving rate 1.1 -> 2037\n",
      "FLOP halving rate 1.2 -> 2038\n",
      "FLOP halving rate 1.3 -> 2038\n",
      "FLOP halving rate 1.4 -> 2039\n",
      "FLOP halving rate 1.5 -> 2039\n",
      "FLOP halving rate 1.6 -> 2040\n",
      "FLOP halving rate 1.7 -> 2041\n",
      "FLOP halving rate 1.8 -> 2041\n",
      "FLOP halving rate 1.9 -> 2042\n",
      "FLOP halving rate 2.0 -> 2042\n",
      "FLOP halving rate 2.1 -> 2043\n",
      "FLOP halving rate 2.2 -> 2043\n",
      "FLOP halving rate 2.3 -> 2044\n",
      "FLOP halving rate 2.4 -> 2044\n",
      "FLOP halving rate 2.5 -> 2045\n",
      "FLOP halving rate 2.6 -> 2045\n",
      "FLOP halving rate 2.7 -> 2045\n",
      "FLOP halving rate 2.8 -> 2046\n",
      "FLOP halving rate 2.9 -> 2046\n",
      "FLOP halving rate 3.0 -> 2047\n",
      "FLOP halving rate 3.1 -> 2047\n",
      "FLOP halving rate 3.2 -> 2048\n",
      "FLOP halving rate 3.3 -> 2048\n",
      "FLOP halving rate 3.4 -> 2049\n",
      "FLOP halving rate 3.5 -> 2049\n",
      "FLOP halving rate 3.6 -> 2049\n",
      "FLOP halving rate 3.7 -> 2050\n",
      "FLOP halving rate 3.8 -> 2050\n",
      "FLOP halving rate 3.9 -> 2051\n",
      "FLOP halving rate 4.0 -> 2051\n"
     ]
    }
   ],
   "source": [
    "print('## FLOP halving rate ##')\n",
    "for f in range(5, 41):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=f / 10,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('FLOP halving rate {} -> {}'.format(f / 10, print_year(result)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Max FLOP per dollar ##\n",
      "Max log FLOP per 2022USD$1 20 -> 2045\n",
      "Max log FLOP per 2022USD$1 21 -> 2045\n",
      "Max log FLOP per 2022USD$1 22 -> 2045\n",
      "Max log FLOP per 2022USD$1 23 -> 2045\n",
      "Max log FLOP per 2022USD$1 24 -> 2045\n",
      "Max log FLOP per 2022USD$1 25 -> 2045\n",
      "Max log FLOP per 2022USD$1 26 -> 2045\n",
      "Max log FLOP per 2022USD$1 27 -> 2045\n",
      "Max log FLOP per 2022USD$1 28 -> 2045\n",
      "Max log FLOP per 2022USD$1 29 -> 2045\n",
      "Max log FLOP per 2022USD$1 30 -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Max FLOP per dollar ##')\n",
    "for f in range(20, 31):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Max log FLOP per 2022USD$1 {} -> {}'.format(f, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Algo Doubling Rate Minimum ##\n",
      "Algo doubling rate minimum 1 -> 2045\n",
      "Algo doubling rate minimum 1.3 -> 2045\n",
      "Algo doubling rate minimum 1.5 -> 2045\n",
      "Algo doubling rate minimum 2 -> 2045\n",
      "Algo doubling rate minimum 2.5 -> 2045\n",
      "Algo doubling rate minimum 3 -> 2045\n",
      "Algo doubling rate minimum 3.5 -> 2046\n"
     ]
    }
   ],
   "source": [
    "print('## Algo Doubling Rate Minimum ##')\n",
    "for m in [1, 1.3, 1.5, 2, 2.5, 3, 3.5]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=m, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Algo doubling rate minimum {} -> {}'.format(m, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Algo Doubling Rate Maximum ##\n",
      "Algo doubling rate maximum 2 -> 2044\n",
      "Algo doubling rate maximum 2.5 -> 2044\n",
      "Algo doubling rate maximum 3 -> 2044\n",
      "Algo doubling rate maximum 3.5 -> 2045\n",
      "Algo doubling rate maximum 4 -> 2045\n",
      "Algo doubling rate maximum 4.5 -> 2046\n",
      "Algo doubling rate maximum 5 -> 2046\n",
      "Algo doubling rate maximum 6 -> 2048\n"
     ]
    }
   ],
   "source": [
    "print('## Algo Doubling Rate Maximum ##')\n",
    "for m in [2, 2.5, 3, 3.5, 4, 4.5, 5, 6]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=m, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Algo doubling rate maximum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Possible Algo Reduction minimum ##\n",
      "Possible algo reduction minimum 0 -> 2056\n",
      "Possible algo reduction minimum 1 -> 2050\n",
      "Possible algo reduction minimum 2 -> 2045\n",
      "Possible algo reduction minimum 3 -> 2043\n",
      "Possible algo reduction minimum 4 -> 2043\n",
      "Possible algo reduction minimum 5 -> 2043\n"
     ]
    }
   ],
   "source": [
    "print('## Possible Algo Reduction minimum ##')\n",
    "for m in [0, 1, 2, 3, 4, 5]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=m,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Possible algo reduction minimum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Possible Algo Reduction maximum ##\n",
      "Possible algo reduction maximum 2 -> 2045\n",
      "Possible algo reduction maximum 3 -> 2045\n",
      "Possible algo reduction maximum 4 -> 2045\n",
      "Possible algo reduction maximum 5 -> 2045\n",
      "Possible algo reduction maximum 6 -> 2045\n",
      "Possible algo reduction maximum 7 -> 2045\n",
      "Possible algo reduction maximum 8 -> 2045\n",
      "Possible algo reduction maximum 9 -> 2045\n",
      "Possible algo reduction maximum 10 -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Possible Algo Reduction maximum ##')\n",
    "for m in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=m,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Possible algo reduction maximum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Willingness ramp ##\n",
      "Willingness ramp 10.0x -> 2040\n",
      "Willingness ramp 5.0x -> 2042\n",
      "Willingness ramp 3.3x -> 2042\n",
      "Willingness ramp 2.5x -> 2043\n",
      "Willingness ramp 2.0x -> 2043\n",
      "Willingness ramp 1.7x -> 2044\n",
      "Willingness ramp 1.4x -> 2044\n",
      "Willingness ramp 1.2x -> 2044\n",
      "Willingness ramp 1.1x -> 2044\n",
      "Willingness ramp 1.0x -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Willingness ramp ##')\n",
    "for r in range(1, 11):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=m,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=r / 10,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Willingness ramp {}x -> {}'.format(round(10 / r, 1), print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Willingness spend horizon ##\n",
      "Willingness spend horizon 1yrs -> 2045\n",
      "Willingness spend horizon 2yrs -> 2045\n",
      "Willingness spend horizon 3yrs -> 2045\n",
      "Willingness spend horizon 4yrs -> 2045\n",
      "Willingness spend horizon 5yrs -> 2045\n",
      "Willingness spend horizon 6yrs -> 2045\n",
      "Willingness spend horizon 7yrs -> 2045\n",
      "Willingness spend horizon 8yrs -> 2045\n",
      "Willingness spend horizon 9yrs -> 2045\n",
      "Willingness spend horizon 10yrs -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Willingness spend horizon ##')\n",
    "for h in range(1, 11):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=m,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=h,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Willingness spend horizon {}yrs -> {}'.format(h, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay 90% -> 10%, delay fixed to 5yrs, change `nonscaling_issue_bottom_year` ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [02:44<00:00, 20.56s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5091.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2025: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4918.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2030: 2053 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5748.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2035: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5036.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2040: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5277.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2045: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 6984.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2050: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5865.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2055: 2076 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5599.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2060: 2053 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay 90% -> 10%, delay fixed to 5yrs, change `nonscaling_issue_bottom_year` ##')\n",
    "years = [2025, 2030, 2035, 2040, 2045, 2050, 2055, 2060]\n",
    "p_nonscaling_delays = {y: derive_nonscaling_delay_curve(0.9, 0.1, y, verbose=False) for y in tqdm(years)}\n",
    "for y in years:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=5,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delays[y],\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in tqdm(range(10000))]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Nonscaling delay bottom year {}: {} (90% CI {} - {})'.format(y,\n",
    "                                                                        print_year(np.mean(results)),\n",
    "                                                                        print_year(pctiles[5]),\n",
    "                                                                        print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay 90% -> 10%, bottom year fixed to 2040, vary delay ##\n",
      "|   iter    |  target   |   push    |   shift   |   slope   |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-0.08293 \u001b[0m | \u001b[95m2.282    \u001b[0m | \u001b[95m8.526    \u001b[0m | \u001b[95m7.903    \u001b[0m |\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m-0.05308 \u001b[0m | \u001b[95m0.09665  \u001b[0m | \u001b[95m9.39     \u001b[0m | \u001b[95m1.412    \u001b[0m |\n",
      "| \u001b[95m50       \u001b[0m | \u001b[95m-0.03093 \u001b[0m | \u001b[95m1.284    \u001b[0m | \u001b[95m9.925    \u001b[0m | \u001b[95m0.467    \u001b[0m |\n",
      "=============================================================\n",
      "Curve params found\n",
      "{'push': 1.284290752713264,\n",
      " 'shift': 9.92515473141246,\n",
      " 'slope': 0.46704353428576517}\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 6891.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 1yrs: 2045 (90% CI 2045 - 2050)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 6073.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 2yrs: 2046 (90% CI 2045 - 2055)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5242.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 3yrs: 2046 (90% CI 2045 - 2060)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5232.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 4yrs: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5977.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 5yrs: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 7907.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 7yrs: 2053 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 8157.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 10yrs: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 6561.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 20yrs: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 6573.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay 40yrs: 2053 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay 90% -> 10%, bottom year fixed to 2040, vary delay ##')\n",
    "p_nonscaling_delay = derive_nonscaling_delay_curve(0.9, 0.1, 2040)\n",
    "for d in [1, 2, 3, 4, 5, 7, 10, 20, 40]:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=d,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delay,\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in tqdm(range(10000))]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Nonscaling delay {}yrs: {} (90% CI {} - {})'.format(d,\n",
    "                                                               print_year(np.mean(results)),\n",
    "                                                               print_year(pctiles[5]),\n",
    "                                                               print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay X% -> 10%, bottom year fixed to 2040, delay fixed to 4yrs, vary `initial_chance_of_nonscaling_issue` ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mData point [0.01 0.01 0.01] is not unique. 1 duplicates registered. Continuing ...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [05:46<00:00, 31.54s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4826.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 10%: 2053 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5596.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 20%: 2053 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5954.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 30%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 6054.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 40%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5206.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 50%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4032.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 60%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4743.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 70%: 2053 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5709.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 80%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5417.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 90%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5237.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 95%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:02<00:00, 4997.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 99%: 2052 (90% CI 2045 - >2123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay X% -> 10%, bottom year fixed to 2040, delay fixed to 4yrs, vary `initial_chance_of_nonscaling_issue` ##')\n",
    "\n",
    "ps = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "p_nonscaling_delays = {p: derive_nonscaling_delay_curve(p, 0.1, 2040, verbose=False) for p in tqdm(ps)}\n",
    "for p in ps:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=4,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delays[p],\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in tqdm(range(10000))]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Initial chance of nonscaling issue {}%: {} (90% CI {} - {})'.format(int(round(p * 100)),\n",
    "                                                                               print_year(np.mean(results)),\n",
    "                                                                               print_year(pctiles[5]),\n",
    "                                                                               print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay 90% -> X%, bottom year fixed to 2040, delay fixed to 4yrs, vary `final_chance_of_nonscaling_issue` ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████████████████████████████████████████████████                                                                                    | 6/12 [03:56<04:12, 42.07s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:306\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 306\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:27\u001b[0m, in \u001b[0;36mQueue.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueue is empty, no more objects to retrieve.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mStopIteration\u001b[0m: Queue is empty, no more objects to retrieve.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## Nonscaling delay 90\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m -> X\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m, bottom year fixed to 2040, delay fixed to 4yrs, vary `final_chance_of_nonscaling_issue` ##\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m ps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m p_nonscaling_delays \u001b[38;5;241m=\u001b[39m {p: derive_nonscaling_delay_curve(\u001b[38;5;241m0.9\u001b[39m, p, \u001b[38;5;241m2040\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m tqdm(ps)}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m ps:\n\u001b[1;32m      5\u001b[0m     results \u001b[38;5;241m=\u001b[39m [run_tai_model_round(initial_gdp_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m\u001b[38;5;241m*\u001b[39mT,\n\u001b[1;32m      6\u001b[0m                                    tai_flop_size_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                    nonscaling_delay_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                                    willingness_spend_horizon_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m                                    print_diagnostic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m))]\n",
      "Cell \u001b[0;32mIn [20], line 3\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## Nonscaling delay 90\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m -> X\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m, bottom year fixed to 2040, delay fixed to 4yrs, vary `final_chance_of_nonscaling_issue` ##\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m ps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.7\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m0.9\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m p_nonscaling_delays \u001b[38;5;241m=\u001b[39m {p: \u001b[43mderive_nonscaling_delay_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2040\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m tqdm(ps)}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m ps:\n\u001b[1;32m      5\u001b[0m     results \u001b[38;5;241m=\u001b[39m [run_tai_model_round(initial_gdp_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m23\u001b[39m\u001b[38;5;241m*\u001b[39mT,\n\u001b[1;32m      6\u001b[0m                                    tai_flop_size_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m34\u001b[39m,\n\u001b[1;32m      7\u001b[0m                                    nonscaling_delay_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                                    willingness_spend_horizon_\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     22\u001b[0m                                    print_diagnostic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m))]\n",
      "File \u001b[0;32m<string>:96\u001b[0m, in \u001b[0;36mderive_nonscaling_delay_curve\u001b[0;34m(minimum, maximum, bottom_year, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:309\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     util\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[0;32m--> 309\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mutil\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:220\u001b[0m, in \u001b[0;36mBayesianOptimization.suggest\u001b[0;34m(self, utility_function)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    219\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_constrained:\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraint\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mparams,\n\u001b[1;32m    223\u001b[0m                             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39m_constraint_values)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:273\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[1;32m    271\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    272\u001b[0m     (\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m ]\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:609\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 609\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    617\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_minimize.py:699\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    697\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 699\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    702\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    703\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    354\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:263\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 263\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:538\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    535\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# Alg. 2.1, page 19, line 2 -> L = cholesky(K + sigma^2 I)\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m K[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag_indices_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     L \u001b[38;5;241m=\u001b[39m cholesky(K, lower\u001b[38;5;241m=\u001b[39mGPR_CHOLESKY_LOWER, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdiag_indices_from\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/numpy/lib/index_tricks.py:1011\u001b[0m, in \u001b[0;36mdiag_indices_from\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput array must be at least 2-d\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# For more than d=2, the strided formula is only valid for arrays with\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# all dimensions equal, so we check first.\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m alltrue(\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   1012\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll dimensions of input must be of equal length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m diag_indices(arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], arr\u001b[38;5;241m.\u001b[39mndim)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/numpy/lib/function_base.py:1446\u001b[0m, in \u001b[0;36mdiff\u001b[0;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[1;32m   1443\u001b[0m slice2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(slice2)\n\u001b[1;32m   1445\u001b[0m op \u001b[38;5;241m=\u001b[39m not_equal \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m subtract\n\u001b[0;32m-> 1446\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1447\u001b[0m     a \u001b[38;5;241m=\u001b[39m op(a[slice1], a[slice2])\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay 90% -> X%, bottom year fixed to 2040, delay fixed to 4yrs, vary `final_chance_of_nonscaling_issue` ##')\n",
    "ps = [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "p_nonscaling_delays = {p: derive_nonscaling_delay_curve(0.9, p, 2040, verbose=False) for p in tqdm(ps)}\n",
    "for p in ps:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=4,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delays[p],\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in tqdm(range(10000))]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Final chance of nonscaling issue {}%: {} (90% CI {} - {})'.format(int(round(p * 100)),\n",
    "                                                                             print_year(np.mean(results)),\n",
    "                                                                             print_year(pctiles[5]),\n",
    "                                                                             print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_question(11558)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.metaculus.com/questions/11558/maximum-compute-used-in-ai-training/\n",
    "# TODO: Fetch from Metaculus, look side by side\n",
    "# TODO: Be able to predict back\n",
    "for y in [2022, 2025, 2030]:\n",
    "    print('-')\n",
    "    print('## {} ##'.format(y))\n",
    "    for i in range(3):\n",
    "        flop_at_max_ = flop_at_max(initial_gdp=variables['initial_gdp'],\n",
    "                                   gdp_growth=[1.02, 1.025, 1.03][i],\n",
    "                                   initial_pay=[10*M, 100*M, 1*B][i],\n",
    "                                   spend_doubling_time=[1, 2, 3][i],\n",
    "                                   max_gdp_frac=[1/1000, 4/1000, 1/100][i],\n",
    "                                   initial_flop_per_dollar=10 ** 18,\n",
    "                                   max_flop_per_dollar=10 ** 24,\n",
    "                                   flop_halving_rate=[2, 2.5, 3][i],\n",
    "                                   year=(y - CURRENT_YEAR))\n",
    "\n",
    "        print('{}: {} max log FLOPs / ~{} petaFLOP/s-days)'.format(['25th', 'mean', '75th'][i],\n",
    "                                                                   np.round(np.log10(flop_at_max_), 1),\n",
    "                                                                   log_flop_to_petaflop_sdays(np.log10(flop_at_max_))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
