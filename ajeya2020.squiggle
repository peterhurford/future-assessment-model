// Based on Ajeya Cotra's 2020 "When compute required to train a transformative model may be attainable".
// - https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines
// 
// Adapted by: Jesse Hoogland

// Best guess 
// - https://docs.google.com/spreadsheets/d/1TjNQyVHvHlC-sZbcA7CRKcCp0NxV6MkkqBvL408xrJw/edit#gid=505210495

start_year = 2025
end_year = 2100

minx(n, max) = SampleSet.map(n, { |x| if x > max then max else x })
maxx(n, min) = SampleSet.map(n, { |x| if x < min then min else x })
bound(x, min, max) = maxx(minx(x, max), min)

bayes_update_against_low_end_flop(anchor) = anchor |> truncateLeft(24)

anchor(brain, efficiency, transformative_vs_human, horizon_length,
       scaling_exponent, params, ref_params, ref_params_samples) = {
           
    anchor = brain + efficiency + transformative_vs_human +
             horizon_length + ref_params_samples -
             scaling_exponent * ref_params +
             scaling_exponent * params
             
    anchor |> bayes_update_against_low_end_flop
}

nn_anchor(h) = {
    brain = 11 to 19.5
    efficiency = 1
    transformative_vs_human = -2 to 2
    scaling_exponent = 0.5 to 1.1
    flops_per_param_per_sec = 1 to 2
    params = brain + efficiency - flops_per_param_per_sec
    ref_params = 11.2
    ref_params_samples = 12
    
    anchor(brain, efficiency, transformative_vs_human, h, scaling_exponent,
           params, ref_params, ref_params_samples)
}

gpt_nn = nn_anchor(0)
short_nn = nn_anchor(0 to 3)
medium_nn = nn_anchor(3 to 6)
long_nn = nn_anchor(6 to 9)

lifetime_anchor = anchor(11 to 19.5,
                         mixture(2 to 5, 5 to 9, [0.5,0.5]),
                         -2 to 2,
                         9,
                         0,
                         (11 to 19.5) + mixture(2 to 5, 5 to 9, [0.5,0.5]) - (1 to 2),
                         0,
                         0)

average_ancestor_brain_flops = 3 to 6
log_n_individuals = 20 to 22
evo_time_log_sec = 16
evolution_anchor = anchor(average_ancestor_brain_flops,
                          -6 to 5, // TODO: This seems not quite right
                          -2 to 2,
                          log_n_individuals + evo_time_log_sec,
                          0,
                          average_ancestor_brain_flops + (-2 to 2) - (1 to 2),
                          0,
                          0)

genome_anchor = anchor(11 to 19.5,
                       0 to 2,
                       -2 to 2,
                       7 to 9,
                       0.5 to 1.1,
                       8.3 to 9.44,
                       11.2,
                       12)

no_path_anchor = 60 to 70

mixed_PDF = mixture(
    evolution_anchor,
    lifetime_anchor,
    short_nn,
    medium_nn,
    long_nn,
    genome_anchor,
    no_path_anchor,
    [
        .105,
        .055,
        .205,
        .305,
        .155,
        .105,
        .075
    ]
)

flop_per_$(y) = {
    curr_FLOP_per_$ = 4e17
    compute_$_halving_time = 2.5 // 1.5 to 3.5
    max_FLOP_per_$ = 1e24 // 22 to 26
    t = y - start_year
    curr_FLOP_per_$ * (exp((log(2) / compute_$_halving_time) * t)) / (1 + curr_FLOP_per_$ / max_FLOP_per_$ * exp(log(2) / compute_$_halving_time * t))  
}

frontier_country_GDP(y) = {
    // Our reference measurement comes from 2020, not 2025.
    t = y - 2020
    frontier_country_GDP_2020 = 2.13e13
    growth_rate = .03 // per year  // .02 to .05
    frontier_country_GDP_2020 * (1 + growth_rate)^(t)
}

spend(y) = {
    initial_pay = 1e9 // in 2020 USD  1e8 to 1e10
    spend_doubling_time = 2.5  // 1 to 3
    gdp = frontier_country_GDP(y)
    max_gdp_frac = .01 // of frontier GDP in 2020 USD  // .005 to .02
    t = y - start_year
    x = (log(2) / spend_doubling_time) * t
    10 ^ (log10(initial_pay) + log10(exp(x)) - log10(1 + initial_pay / (gdp * max_gdp_frac) * exp(x)))
}

flop(y) = {
    flop_per_$(y) * spend(y)
}

logflop_at_y(y) = log10(flop(y))

algo_progress_reduction_at_y(y, f) = {
    max_algo_reduction = bound(2 + (f - 32) / 4, 2, 5)
    algo_halving_time = bound(3.5 - (f - 29) / 4, 2, 3.5)
    t = y - start_year
    r = (exp((log(2) / algo_halving_time) * t)) / (1 + 1 / max_algo_reduction * exp(log(2) / algo_halving_time * t))
    SampleSet.map(r, { |x| if x > 5 then 5 else x })
}

flop_to_make_tai_at_y(y) = { mixed_PDF - algo_progress_reduction_at_y(y, mixed_PDF) }

mixed(y) = cdf(flop_to_make_tai_at_y(y), logflop_at_y(y))

{
    'FLOP to TAI at Y': flop_to_make_tai_at_y(2030),
    'Available FLOP at Y': logflop_at_y(2030),
    'Log FLOP per $ at Y': log10(flop_per_$(2030)),
    'Log Spend at Y': log10(spend(2030)),
    'Initial FLOP': mixed_PDF,
    '2030': mixed(2030),
    '2036': mixed(2036),
    '2040': mixed(2040),
    '2050': mixed(2050),
    '2100': mixed(2100)
}

