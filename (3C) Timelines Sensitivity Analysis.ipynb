{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1\n",
      "Loaded 2\n",
      "Loaded TAI timelines module\n",
      "Loaded Metaculus lib v0.2\n",
      "Loaded Metaculus module\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import squigglepy as sq\n",
    "from squigglepy import bayes\n",
    "from squigglepy.numbers import K, M, B, T\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "print('Loaded 1')\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded 2')\n",
    "\n",
    "exec(open('modules/tai_timelines.py').read())\n",
    "print('Loaded TAI timelines module')\n",
    "\n",
    "exec(open('/Users/peterhurford/dev/forecastflow/library.py').read()) # TODO: Package?\n",
    "print('Loaded Metaculus module')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Timelines Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Default ##\n",
      "Default: 2045\n"
     ]
    }
   ],
   "source": [
    "CURRENT_YEAR = 2023                               # What year to start the run on? (default: 2023)\n",
    "MAX_YEAR = 2123                                   # What year to end the run on? (default: 2123)\n",
    "years = list(range(CURRENT_YEAR, MAX_YEAR))\n",
    "\n",
    "def print_year(y):\n",
    "    return '>{}'.format(MAX_YEAR) if y > MAX_YEAR else str(int(y))\n",
    "\n",
    "\n",
    "print('## Default ##')\n",
    "result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                             tai_flop_size_=34,\n",
    "                             nonscaling_delay_=0,\n",
    "                             algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                             possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                 max_reduction=5,\n",
    "                                                                                 tai_flop_size=34),\n",
    "                             initial_flop_per_dollar_=10 ** 18.3,\n",
    "                             flop_halving_rate_=2.5,\n",
    "                             max_flop_per_dollar_=10 ** 24,\n",
    "                             initial_pay_=10 ** 9,\n",
    "                             gdp_growth_=1.03,\n",
    "                             max_gdp_frac_=0.01,\n",
    "                             willingness_ramp_=1,\n",
    "                             spend_doubling_time_=2.5,\n",
    "                             p_nonscaling_delay=None,\n",
    "                             willingness_spend_horizon_=1,\n",
    "                             print_diagnostic=False)\n",
    "print('{}: {}'.format('Default', print_year(result)))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## TAI FLOP Size ##\n",
      "FLOP Size for TAI 26 log FLOP -> 2023\n",
      "FLOP Size for TAI 27 log FLOP -> 2023\n",
      "FLOP Size for TAI 28 log FLOP -> 2026\n",
      "FLOP Size for TAI 29 log FLOP -> 2029\n",
      "FLOP Size for TAI 30 log FLOP -> 2032\n",
      "FLOP Size for TAI 31 log FLOP -> 2035\n",
      "FLOP Size for TAI 32 log FLOP -> 2037\n",
      "FLOP Size for TAI 33 log FLOP -> 2040\n",
      "FLOP Size for TAI 34 log FLOP -> 2045\n",
      "FLOP Size for TAI 35 log FLOP -> 2045\n",
      "FLOP Size for TAI 36 log FLOP -> 2050\n",
      "FLOP Size for TAI 37 log FLOP -> 2056\n",
      "FLOP Size for TAI 38 log FLOP -> 2057\n",
      "FLOP Size for TAI 39 log FLOP -> 2064\n",
      "FLOP Size for TAI 40 log FLOP -> 2078\n",
      "FLOP Size for TAI 41 log FLOP -> >2123\n",
      "FLOP Size for TAI 42 log FLOP -> >2123\n"
     ]
    }
   ],
   "source": [
    "print('## TAI FLOP Size ##')\n",
    "for t in range(26, 43):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=t,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=t),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=t),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('FLOP Size for TAI {} log FLOP -> {}'.format(t, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## GDP Growth ##\n",
      "GDP Growth Rate 1.0% -> 2045\n",
      "GDP Growth Rate 1.01% -> 2045\n",
      "GDP Growth Rate 1.02% -> 2045\n",
      "GDP Growth Rate 1.03% -> 2045\n",
      "GDP Growth Rate 1.04% -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## GDP Growth ##')\n",
    "for g in range(0, 5):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1 + (g / 100),\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('GDP Growth Rate {}% -> {}'.format(1 + g / 100, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Max GDP Frac ##\n",
      "Max GDP Frac 2e-06 (1 in ~500,000) -> 2071\n",
      "Max GDP Frac 4e-06 (1 in ~250,000) -> 2068\n",
      "Max GDP Frac 1e-05 (1 in ~100,000) -> 2064\n",
      "Max GDP Frac 2e-05 (1 in ~50,000) -> 2062\n",
      "Max GDP Frac 0.0001 (1 in ~10,000) -> 2056\n",
      "Max GDP Frac 0.0005 (1 in ~2,000) -> 2051\n",
      "Max GDP Frac 0.0005 (1 in ~2,000) -> 2051\n",
      "Max GDP Frac 0.000667 (1 in ~1,500) -> 2050\n",
      "Max GDP Frac 0.001 (1 in ~1,000) -> 2049\n",
      "Max GDP Frac 0.002 (1 in ~500) -> 2047\n",
      "Max GDP Frac 0.003 (1 in ~333) -> 2046\n",
      "Max GDP Frac 0.004 (1 in ~250) -> 2046\n",
      "Max GDP Frac 0.005 (1 in ~200) -> 2045\n",
      "Max GDP Frac 0.01 (1 in ~100) -> 2045\n",
      "Max GDP Frac 0.02 (1 in ~50) -> 2044\n",
      "Max GDP Frac 0.03 (1 in ~33) -> 2044\n",
      "Max GDP Frac 0.04 (1 in ~25) -> 2044\n"
     ]
    }
   ],
   "source": [
    "print('## Max GDP Frac ##')\n",
    "for g in [1/(500*K), 1/(250*K), 1/(100*K), 1/(50*K), 1/(10*K), 5/(10*K),\n",
    "          1/2000, 1/1500, 1/1000, 2/1000, 3/1000, 4/1000, 5/1000, 1/100,\n",
    "          2/100, 3/100, 4/100]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=g,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Max GDP Frac {} (1 in ~{:,}) -> {}'.format(round(g, 6), int(round(1 / g)), print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Spend Doubling Time ##\n",
      "Spend Doubling Time 1.0yrs -> 2042\n",
      "Spend Doubling Time 1.2yrs -> 2042\n",
      "Spend Doubling Time 1.4yrs -> 2043\n",
      "Spend Doubling Time 1.6yrs -> 2043\n",
      "Spend Doubling Time 1.8yrs -> 2043\n",
      "Spend Doubling Time 2.0yrs -> 2043\n",
      "Spend Doubling Time 2.2yrs -> 2044\n",
      "Spend Doubling Time 2.4yrs -> 2044\n",
      "Spend Doubling Time 2.6yrs -> 2045\n",
      "Spend Doubling Time 2.8yrs -> 2045\n",
      "Spend Doubling Time 3.0yrs -> 2046\n",
      "Spend Doubling Time 3.2yrs -> 2046\n",
      "Spend Doubling Time 3.4yrs -> 2047\n",
      "Spend Doubling Time 3.6yrs -> 2047\n",
      "Spend Doubling Time 3.8yrs -> 2048\n",
      "Spend Doubling Time 4.0yrs -> 2048\n",
      "Spend Doubling Time 4.2yrs -> 2048\n",
      "Spend Doubling Time 4.4yrs -> 2049\n",
      "Spend Doubling Time 4.6yrs -> 2049\n",
      "Spend Doubling Time 4.8yrs -> 2050\n",
      "Spend Doubling Time 5.0yrs -> 2050\n",
      "Spend Doubling Time 5.2yrs -> 2050\n",
      "Spend Doubling Time 5.4yrs -> 2050\n",
      "Spend Doubling Time 5.6yrs -> 2051\n",
      "Spend Doubling Time 5.8yrs -> 2051\n",
      "Spend Doubling Time 6.0yrs -> 2051\n"
     ]
    }
   ],
   "source": [
    "print('## Spend Doubling Time ##')\n",
    "for d in range(0, 51, 2):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=1 + (d / 10),\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Spend Doubling Time {}yrs -> {}'.format(1 + d / 10, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Initial FLOP per dollar ##\n",
      "Initial log FLOP per dollar 17 -> 2052\n",
      "Initial log FLOP per dollar 17.5 -> 2049\n",
      "Initial log FLOP per dollar 18 -> 2046\n",
      "Initial log FLOP per dollar 18.3 -> 2045\n",
      "Initial log FLOP per dollar 18.5 -> 2044\n",
      "Initial log FLOP per dollar 19 -> 2042\n"
     ]
    }
   ],
   "source": [
    "print('## Initial FLOP per dollar ##')\n",
    "for d in [17, 17.5, 18, 18.3, 18.5, 19]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** d,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Initial log FLOP per dollar {} -> {}'.format(d, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Initial pay ##\n",
      "Initial pay in log 2022$USD 7.0 (~$10 million) -> 2051\n",
      "Initial pay in log 2022$USD 7.2 (~$16 million) -> 2051\n",
      "Initial pay in log 2022$USD 7.4 (~$25 million) -> 2050\n",
      "Initial pay in log 2022$USD 7.6 (~$40 million) -> 2049\n",
      "Initial pay in log 2022$USD 7.8 (~$63 million) -> 2048\n",
      "Initial pay in log 2022$USD 8.0 (~$100 million) -> 2048\n",
      "Initial pay in log 2022$USD 8.2 (~$158 million) -> 2047\n",
      "Initial pay in log 2022$USD 8.4 (~$251 million) -> 2046\n",
      "Initial pay in log 2022$USD 8.6 (~$398 million) -> 2046\n",
      "Initial pay in log 2022$USD 8.8 (~$631 million) -> 2045\n",
      "Initial pay in log 2022$USD 9.0 (~$1 billion) -> 2045\n",
      "Initial pay in log 2022$USD 9.2 (~$2 billion) -> 2044\n",
      "Initial pay in log 2022$USD 9.4 (~$3 billion) -> 2044\n",
      "Initial pay in log 2022$USD 9.6 (~$4 billion) -> 2043\n",
      "Initial pay in log 2022$USD 9.8 (~$6 billion) -> 2043\n",
      "Initial pay in log 2022$USD 10.0 (~$10 billion) -> 2043\n"
     ]
    }
   ],
   "source": [
    "print('## Initial pay ##')\n",
    "for p in range(70, 101, 2):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** (p / 10),\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Initial pay in log 2022$USD {} (~${}) -> {}'.format(p / 10, numerize(10 ** (p / 10)), print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## FLOP halving rate ##\n",
      "FLOP halving rate 0.5 -> 2032\n",
      "FLOP halving rate 0.6 -> 2033\n",
      "FLOP halving rate 0.7 -> 2034\n",
      "FLOP halving rate 0.8 -> 2035\n",
      "FLOP halving rate 0.9 -> 2035\n",
      "FLOP halving rate 1.0 -> 2036\n",
      "FLOP halving rate 1.1 -> 2037\n",
      "FLOP halving rate 1.2 -> 2038\n",
      "FLOP halving rate 1.3 -> 2038\n",
      "FLOP halving rate 1.4 -> 2039\n",
      "FLOP halving rate 1.5 -> 2039\n",
      "FLOP halving rate 1.6 -> 2040\n",
      "FLOP halving rate 1.7 -> 2041\n",
      "FLOP halving rate 1.8 -> 2041\n",
      "FLOP halving rate 1.9 -> 2042\n",
      "FLOP halving rate 2.0 -> 2042\n",
      "FLOP halving rate 2.1 -> 2043\n",
      "FLOP halving rate 2.2 -> 2043\n",
      "FLOP halving rate 2.3 -> 2044\n",
      "FLOP halving rate 2.4 -> 2044\n",
      "FLOP halving rate 2.5 -> 2045\n",
      "FLOP halving rate 2.6 -> 2045\n",
      "FLOP halving rate 2.7 -> 2045\n",
      "FLOP halving rate 2.8 -> 2046\n",
      "FLOP halving rate 2.9 -> 2046\n",
      "FLOP halving rate 3.0 -> 2047\n",
      "FLOP halving rate 3.1 -> 2047\n",
      "FLOP halving rate 3.2 -> 2048\n",
      "FLOP halving rate 3.3 -> 2048\n",
      "FLOP halving rate 3.4 -> 2049\n",
      "FLOP halving rate 3.5 -> 2049\n",
      "FLOP halving rate 3.6 -> 2049\n",
      "FLOP halving rate 3.7 -> 2050\n",
      "FLOP halving rate 3.8 -> 2050\n",
      "FLOP halving rate 3.9 -> 2051\n",
      "FLOP halving rate 4.0 -> 2051\n"
     ]
    }
   ],
   "source": [
    "print('## FLOP halving rate ##')\n",
    "for f in range(5, 41):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=f / 10,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('FLOP halving rate {} -> {}'.format(f / 10, print_year(result)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Max FLOP per dollar ##\n",
      "Max log FLOP per 2022USD$1 20 -> 2045\n",
      "Max log FLOP per 2022USD$1 21 -> 2045\n",
      "Max log FLOP per 2022USD$1 22 -> 2045\n",
      "Max log FLOP per 2022USD$1 23 -> 2045\n",
      "Max log FLOP per 2022USD$1 24 -> 2045\n",
      "Max log FLOP per 2022USD$1 25 -> 2045\n",
      "Max log FLOP per 2022USD$1 26 -> 2045\n",
      "Max log FLOP per 2022USD$1 27 -> 2045\n",
      "Max log FLOP per 2022USD$1 28 -> 2045\n",
      "Max log FLOP per 2022USD$1 29 -> 2045\n",
      "Max log FLOP per 2022USD$1 30 -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Max FLOP per dollar ##')\n",
    "for f in range(20, 31):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Max log FLOP per 2022USD$1 {} -> {}'.format(f, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Algo Doubling Rate Minimum ##\n",
      "Algo doubling rate minimum 1 -> 2045\n",
      "Algo doubling rate minimum 1.3 -> 2045\n",
      "Algo doubling rate minimum 1.5 -> 2045\n",
      "Algo doubling rate minimum 2 -> 2045\n",
      "Algo doubling rate minimum 2.5 -> 2045\n",
      "Algo doubling rate minimum 3 -> 2045\n",
      "Algo doubling rate minimum 3.5 -> 2046\n"
     ]
    }
   ],
   "source": [
    "print('## Algo Doubling Rate Minimum ##')\n",
    "for m in [1, 1.3, 1.5, 2, 2.5, 3, 3.5]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=m, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Algo doubling rate minimum {} -> {}'.format(m, print_year(result)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Algo Doubling Rate Maximum ##\n",
      "Algo doubling rate maximum 2 -> 2044\n",
      "Algo doubling rate maximum 2.5 -> 2044\n",
      "Algo doubling rate maximum 3 -> 2044\n",
      "Algo doubling rate maximum 3.5 -> 2045\n",
      "Algo doubling rate maximum 4 -> 2045\n",
      "Algo doubling rate maximum 4.5 -> 2046\n",
      "Algo doubling rate maximum 5 -> 2046\n",
      "Algo doubling rate maximum 6 -> 2048\n"
     ]
    }
   ],
   "source": [
    "print('## Algo Doubling Rate Maximum ##')\n",
    "for m in [2, 2.5, 3, 3.5, 4, 4.5, 5, 6]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=m, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Algo doubling rate maximum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Possible Algo Reduction minimum ##\n",
      "Possible algo reduction minimum 0 -> 2056\n",
      "Possible algo reduction minimum 1 -> 2050\n",
      "Possible algo reduction minimum 2 -> 2045\n",
      "Possible algo reduction minimum 3 -> 2043\n",
      "Possible algo reduction minimum 4 -> 2043\n",
      "Possible algo reduction minimum 5 -> 2043\n"
     ]
    }
   ],
   "source": [
    "print('## Possible Algo Reduction minimum ##')\n",
    "for m in [0, 1, 2, 3, 4, 5]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=m,\n",
    "                                                                                     max_reduction=5,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Possible algo reduction minimum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Possible Algo Reduction maximum ##\n",
      "Possible algo reduction maximum 2 -> 2045\n",
      "Possible algo reduction maximum 3 -> 2045\n",
      "Possible algo reduction maximum 4 -> 2045\n",
      "Possible algo reduction maximum 5 -> 2045\n",
      "Possible algo reduction maximum 6 -> 2045\n",
      "Possible algo reduction maximum 7 -> 2045\n",
      "Possible algo reduction maximum 8 -> 2045\n",
      "Possible algo reduction maximum 9 -> 2045\n",
      "Possible algo reduction maximum 10 -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Possible Algo Reduction maximum ##')\n",
    "for m in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=m,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Possible algo reduction maximum {} -> {}'.format(m, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Willingness ramp ##\n",
      "Willingness ramp 10.0x -> 2040\n",
      "Willingness ramp 5.0x -> 2042\n",
      "Willingness ramp 3.3x -> 2042\n",
      "Willingness ramp 2.5x -> 2043\n",
      "Willingness ramp 2.0x -> 2043\n",
      "Willingness ramp 1.7x -> 2044\n",
      "Willingness ramp 1.4x -> 2044\n",
      "Willingness ramp 1.2x -> 2044\n",
      "Willingness ramp 1.1x -> 2044\n",
      "Willingness ramp 1.0x -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Willingness ramp ##')\n",
    "for r in range(1, 11):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=m,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=r / 10,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=1,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Willingness ramp {}x -> {}'.format(round(10 / r, 1), print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Willingness spend horizon ##\n",
      "Willingness spend horizon 1yrs -> 2045\n",
      "Willingness spend horizon 2yrs -> 2045\n",
      "Willingness spend horizon 3yrs -> 2045\n",
      "Willingness spend horizon 4yrs -> 2045\n",
      "Willingness spend horizon 5yrs -> 2045\n",
      "Willingness spend horizon 6yrs -> 2045\n",
      "Willingness spend horizon 7yrs -> 2045\n",
      "Willingness spend horizon 8yrs -> 2045\n",
      "Willingness spend horizon 9yrs -> 2045\n",
      "Willingness spend horizon 10yrs -> 2045\n"
     ]
    }
   ],
   "source": [
    "print('## Willingness spend horizon ##')\n",
    "for h in range(1, 11):\n",
    "    result = run_tai_model_round(initial_gdp_=23*T,\n",
    "                                 tai_flop_size_=34,\n",
    "                                 nonscaling_delay_=0,\n",
    "                                 algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                 possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                     max_reduction=m,\n",
    "                                                                                     tai_flop_size=34),\n",
    "                                 initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                 flop_halving_rate_=2.5,\n",
    "                                 max_flop_per_dollar_=10 ** 24,\n",
    "                                 initial_pay_=10 ** 9,\n",
    "                                 gdp_growth_=1.03,\n",
    "                                 max_gdp_frac_=0.01,\n",
    "                                 willingness_ramp_=1,\n",
    "                                 spend_doubling_time_=2.5,\n",
    "                                 p_nonscaling_delay=None,\n",
    "                                 willingness_spend_horizon_=h,\n",
    "                                 print_diagnostic=False)\n",
    "    print('Willingness spend horizon {}yrs -> {}'.format(h, print_year(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay 90% -> 10%, delay fixed to 5yrs, change `nonscaling_issue_bottom_year` ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 8/8 [02:01<00:00, 15.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonscaling delay bottom year 2025: 2052 (90% CI 2045 - >2123)\n",
      "Nonscaling delay bottom year 2030: 2051 (90% CI 2045 - >2123)\n",
      "Nonscaling delay bottom year 2035: 2052 (90% CI 2045 - >2123)\n",
      "Nonscaling delay bottom year 2040: 2053 (90% CI 2045 - >2123)\n",
      "Nonscaling delay bottom year 2045: 2053 (90% CI 2045 - >2123)\n",
      "Nonscaling delay bottom year 2050: 2053 (90% CI 2045 - >2123)\n",
      "Nonscaling delay bottom year 2055: 2069 (90% CI 2045 - >2123)\n",
      "Nonscaling delay bottom year 2060: 2058 (90% CI 2045 - >2123)\n"
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay 90% -> 10%, delay fixed to 5yrs, change `nonscaling_issue_bottom_year` ##')\n",
    "years = [2025, 2030, 2035, 2040, 2045, 2050, 2055, 2060]\n",
    "p_nonscaling_delays = {y: derive_nonscaling_delay_curve(0.9, 0.1, y, verbose=False) for y in tqdm(years)}\n",
    "for y in years:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=5,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delays[y],\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in range(1000)]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Nonscaling delay bottom year {}: {} (90% CI {} - {})'.format(y,\n",
    "                                                                        print_year(np.mean(results)),\n",
    "                                                                        print_year(pctiles[5]),\n",
    "                                                                        print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay 90% -> 10%, bottom year fixed to 2040, vary delay ##\n",
      "|   iter    |  target   |   push    |   shift   |   slope   |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-0.0658  \u001b[0m | \u001b[95m1.025    \u001b[0m | \u001b[95m3.284    \u001b[0m | \u001b[95m2.771    \u001b[0m |\n",
      "| \u001b[95m17       \u001b[0m | \u001b[95m-0.05982 \u001b[0m | \u001b[95m1.362    \u001b[0m | \u001b[95m9.796    \u001b[0m | \u001b[95m6.835    \u001b[0m |\n",
      "| \u001b[95m31       \u001b[0m | \u001b[95m-0.05833 \u001b[0m | \u001b[95m0.8656   \u001b[0m | \u001b[95m4.077    \u001b[0m | \u001b[95m2.647    \u001b[0m |\n",
      "| \u001b[95m42       \u001b[0m | \u001b[95m-0.05333 \u001b[0m | \u001b[95m0.01     \u001b[0m | \u001b[95m10.0     \u001b[0m | \u001b[95m10.0     \u001b[0m |\n",
      "| \u001b[95m46       \u001b[0m | \u001b[95m-0.05333 \u001b[0m | \u001b[95m0.01     \u001b[0m | \u001b[95m3.694    \u001b[0m | \u001b[95m3.45     \u001b[0m |\n",
      "=============================================================\n",
      "Curve params found\n",
      "{'push': 0.01, 'shift': 3.694337648106121, 'slope': 3.4495479801525035}\n",
      "-\n",
      "Nonscaling delay 1yrs: 2045 (90% CI 2045 - 2050)\n",
      "Nonscaling delay 2yrs: 2046 (90% CI 2045 - 2055)\n",
      "Nonscaling delay 3yrs: 2046 (90% CI 2045 - 2060)\n",
      "Nonscaling delay 4yrs: 2052 (90% CI 2045 - >2123)\n",
      "Nonscaling delay 5yrs: 2052 (90% CI 2045 - >2123)\n",
      "Nonscaling delay 7yrs: 2053 (90% CI 2045 - >2123)\n",
      "Nonscaling delay 10yrs: 2052 (90% CI 2045 - >2123)\n",
      "Nonscaling delay 20yrs: 2052 (90% CI 2045 - >2123)\n",
      "Nonscaling delay 40yrs: 2053 (90% CI 2045 - >2123)\n"
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay 90% -> 10%, bottom year fixed to 2040, vary delay ##')\n",
    "p_nonscaling_delay = derive_nonscaling_delay_curve(0.9, 0.1, 2040)\n",
    "for d in [1, 2, 3, 4, 5, 7, 10, 20, 40]:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=d,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delay,\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in range(1000)]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Nonscaling delay {}yrs: {} (90% CI {} - {})'.format(d,\n",
    "                                                               print_year(np.mean(results)),\n",
    "                                                               print_year(pctiles[5]),\n",
    "                                                               print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay X% -> 10%, bottom year fixed to 2040, delay fixed to 4yrs, vary `initial_chance_of_nonscaling_issue` ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 11/11 [03:03<00:00, 16.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chance of nonscaling issue 10%: 2052 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 20%: 2053 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 30%: 2053 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 40%: 2052 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 50%: 2052 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 60%: 2053 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 70%: 2051 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 80%: 2053 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 90%: 2052 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 95%: 2052 (90% CI 2045 - >2123)\n",
      "Initial chance of nonscaling issue 99%: 2052 (90% CI 2045 - >2123)\n"
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay X% -> 10%, bottom year fixed to 2040, delay fixed to 4yrs, vary `initial_chance_of_nonscaling_issue` ##')\n",
    "\n",
    "ps = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99]\n",
    "p_nonscaling_delays = {p: derive_nonscaling_delay_curve(p, 0.1, 2040, verbose=False) for p in tqdm(ps)}\n",
    "for p in ps:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=4,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delays[p],\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in range(1000)]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Initial chance of nonscaling issue {}%: {} (90% CI {} - {})'.format(int(round(p * 100)),\n",
    "                                                                               print_year(np.mean(results)),\n",
    "                                                                               print_year(pctiles[5]),\n",
    "                                                                               print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Nonscaling delay 90% -> X%, bottom year fixed to 2040, delay fixed to 4yrs, vary `final_chance_of_nonscaling_issue` ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 12/12 [03:24<00:00, 17.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final chance of nonscaling issue 0%: 2045 (90% CI 2045 - 2045)\n",
      "Final chance of nonscaling issue 1%: 2045 (90% CI 2045 - 2045)\n",
      "Final chance of nonscaling issue 5%: 2049 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 10%: 2053 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 20%: 2061 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 30%: 2068 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 40%: 2075 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 50%: 2083 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 60%: 2091 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 70%: 2100 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 80%: 2108 (90% CI 2045 - >2123)\n",
      "Final chance of nonscaling issue 90%: 2116 (90% CI 2045 - >2123)\n"
     ]
    }
   ],
   "source": [
    "print('## Nonscaling delay 90% -> X%, bottom year fixed to 2040, delay fixed to 4yrs, vary `final_chance_of_nonscaling_issue` ##')\n",
    "ps = [0, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "p_nonscaling_delays = {p: derive_nonscaling_delay_curve(0.9, p, 2040, verbose=False) for p in tqdm(ps)}\n",
    "for p in ps:\n",
    "    results = [run_tai_model_round(initial_gdp_=23*T,\n",
    "                                   tai_flop_size_=34,\n",
    "                                   nonscaling_delay_=4,\n",
    "                                   algo_doubling_rate_=algo_halving_fn(min_speed=2, max_speed=3.5, tai_flop_size=34),\n",
    "                                   possible_algo_reduction_=possible_algo_reduction_fn(min_reduction=2,\n",
    "                                                                                       max_reduction=5,\n",
    "                                                                                       tai_flop_size=34),\n",
    "                                   initial_flop_per_dollar_=10 ** 18.3,\n",
    "                                   flop_halving_rate_=2.5,\n",
    "                                   max_flop_per_dollar_=10 ** 24,\n",
    "                                   initial_pay_=10 ** 9,\n",
    "                                   gdp_growth_=1.03,\n",
    "                                   max_gdp_frac_=0.01,\n",
    "                                   willingness_ramp_=1,\n",
    "                                   spend_doubling_time_=2.5,\n",
    "                                   p_nonscaling_delay=p_nonscaling_delays[p],\n",
    "                                   willingness_spend_horizon_=1,\n",
    "                                   print_diagnostic=False) for _ in range(1000)]\n",
    "    pctiles = sq.get_percentiles(results)\n",
    "    print('Final chance of nonscaling issue {}%: {} (90% CI {} - {})'.format(int(round(p * 100)),\n",
    "                                                                             print_year(np.mean(results)),\n",
    "                                                                             print_year(pctiles[5]),\n",
    "                                                                             print_year(pctiles[95])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metaculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11558 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates?\n",
      "6192 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (January 1, 2031)\n",
      "Me -\n",
      "* Min: 1800\n",
      "* <Min: 0\n",
      "* Q1: 482363.462\n",
      "* Mid: 4955454.895\n",
      "* Q3: 14696518.042\n",
      "* >Max: 0.02200000000000002\n",
      "* Max: 10000000000\n",
      "Metaculus -\n",
      "* Min: 1800\n",
      "* <Min: 0.0\n",
      "* Q1: 3109866.189\n",
      "* Mid: 31948526.063\n",
      "* Q3: 281004112.704\n",
      "* >Max: 0.07401999999999997\n",
      "* Max: 10000000000\n",
      "-\n",
      "6517 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (February 14, 2023)\n",
      "Metaculus -\n",
      "* Min: 3640\n",
      "* <Min: 0.0\n",
      "* Q1: 17623.15\n",
      "* Mid: 51507.61\n",
      "* Q3: 150542.549\n",
      "* >Max: 0.029410000000000047\n",
      "* Max: 2000000\n",
      "-\n",
      "6148 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (January 14, 2022)\n",
      "Resolved as 320532.1027084993\n",
      "-\n",
      "6559 What will be the maximum compute (in petaFLOPS-days) ever used in training an AI experiment by the following dates? (January 1, 2026)\n",
      "Me -\n",
      "* Min: 3640\n",
      "* <Min: 0\n",
      "* Q1: 330449.338\n",
      "* Mid: 899946.671\n",
      "* Q3: 1310339.199\n",
      "* >Max: 0.010000000000000009\n",
      "* Max: 1000000000\n",
      "Metaculus -\n",
      "* Min: 3640\n",
      "* <Min: 0.0\n",
      "* Q1: 618087.295\n",
      "* Mid: 5195921.5\n",
      "* Q3: 49506740.334\n",
      "* >Max: 0.12192999999999998\n",
      "* Max: 1000000000\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "get_question(11558)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "## 2022 ##\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'variables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ##\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     flop_at_max_ \u001b[38;5;241m=\u001b[39m flop_at_max(initial_gdp\u001b[38;5;241m=\u001b[39m\u001b[43mvariables\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitial_gdp\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      9\u001b[0m                                gdp_growth\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1.02\u001b[39m, \u001b[38;5;241m1.025\u001b[39m, \u001b[38;5;241m1.03\u001b[39m][i],\n\u001b[1;32m     10\u001b[0m                                initial_pay\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39mM, \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mM, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39mB][i],\n\u001b[1;32m     11\u001b[0m                                spend_doubling_time\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m][i],\n\u001b[1;32m     12\u001b[0m                                max_gdp_frac\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m4\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m][i],\n\u001b[1;32m     13\u001b[0m                                initial_flop_per_dollar\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m18\u001b[39m,\n\u001b[1;32m     14\u001b[0m                                max_flop_per_dollar\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m24\u001b[39m,\n\u001b[1;32m     15\u001b[0m                                flop_halving_rate\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m3\u001b[39m][i],\n\u001b[1;32m     16\u001b[0m                                year\u001b[38;5;241m=\u001b[39m(y \u001b[38;5;241m-\u001b[39m CURRENT_YEAR))\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m max log FLOPs / ~\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m petaFLOP/s-days)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25th\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m75th\u001b[39m\u001b[38;5;124m'\u001b[39m][i],\n\u001b[1;32m     19\u001b[0m                                                                np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39mlog10(flop_at_max_), \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     20\u001b[0m                                                                log_flop_to_petaflop_sdays(np\u001b[38;5;241m.\u001b[39mlog10(flop_at_max_))))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'variables' is not defined"
     ]
    }
   ],
   "source": [
    "# https://www.metaculus.com/questions/11558/maximum-compute-used-in-ai-training/\n",
    "# TODO: Fetch from Metaculus, look side by side\n",
    "# TODO: Be able to predict back\n",
    "for y in [2022, 2025, 2030]:\n",
    "    print('-')\n",
    "    print('## {} ##'.format(y))\n",
    "    for i in range(3):\n",
    "        flop_at_max_ = flop_at_max(initial_gdp=variables['initial_gdp'],\n",
    "                                   gdp_growth=[1.02, 1.025, 1.03][i],\n",
    "                                   initial_pay=[10*M, 100*M, 1*B][i],\n",
    "                                   spend_doubling_time=[1, 2, 3][i],\n",
    "                                   max_gdp_frac=[1/1000, 4/1000, 1/100][i],\n",
    "                                   initial_flop_per_dollar=10 ** 18,\n",
    "                                   max_flop_per_dollar=10 ** 24,\n",
    "                                   flop_halving_rate=[2, 2.5, 3][i],\n",
    "                                   year=(y - CURRENT_YEAR))\n",
    "\n",
    "        print('{}: {} max log FLOPs / ~{} petaFLOP/s-days)'.format(['25th', 'mean', '75th'][i],\n",
    "                                                                   np.round(np.log10(flop_at_max_), 1),\n",
    "                                                                   log_flop_to_petaflop_sdays(np.log10(flop_at_max_))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
