{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dc97373-f651-4bd0-a101-be321958b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import squigglepy as sq\n",
    "\n",
    "from squigglepy.numbers import K, M, B\n",
    "from squigglepy import bayes\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa2de6d-aecf-4028-a1cd-7db77ac8594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded default variables from cache!\n"
     ]
    }
   ],
   "source": [
    "with open('caches/variables.dill', 'rb') as f:\n",
    "    VARS = dill.load(f)\n",
    "print('loaded default variables from cache!') # Default variables are defined in \"(4) XRisk Model.ipynb\"\n",
    "# TODO: can do sensitivity analysis or VOI analysis over all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27eb4ca-9e6f-496b-a0f6-de3ef83802ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RUNS': 50000,\n",
       " 'CURRENT_YEAR': 2023,\n",
       " 'MAX_YEAR': 2123,\n",
       " 'p_make_agent_tai': 0.9,\n",
       " 'p_tai_aligned_by_default': 0.3,\n",
       " 'p_alignment_solved': <function __main__.p_alignment_solved(war, year, first_attempt=True, verbose=False)>,\n",
       " 'p_alignment_deployment_safety_and_coordination': <function __main__.p_alignment_deployment_safety_and_coordination(war, year, variables, first_attempt=True, verbose=False)>,\n",
       " 'p_subtle_alignment_solved': 0.85,\n",
       " 'p_subtle_alignment_solved_if_aligned_by_default': 0.4,\n",
       " 'p_tai_intentional_misuse': <function __main__.p_tai_intentional_misuse(war)>,\n",
       " 'p_full_tai_misalignment_averted': 0.15,\n",
       " 'p_tai_misalignment_averting_is_catastrophic': 0.4,\n",
       " 'p_full_tai_misalignment_averted_means_abandoned_tai': 0.7,\n",
       " 'p_tai_xrisk_is_extinction': 0.4,\n",
       " 'p_tai_singleton_is_catastrophic': 0.8,\n",
       " 'p_russia_uses_nuke': <function __main__.p_russia_uses_nuke(peace, year, variables)>,\n",
       " 'p_nk_uses_nuke': 0.001,\n",
       " 'p_china_invades_taiwan': <function __main__.p_china_invades_taiwan(peace, year, variables)>,\n",
       " 'p_china_uses_nuke': <function __main__.p_china_uses_nuke(peace, year, variables)>,\n",
       " 'p_other_uses_nuke': <function __main__.p_other_uses_nuke(peace)>,\n",
       " 'p_nuclear_accident': <function __main__.p_nuclear_accident(war, year)>,\n",
       " 'p_nuclear_accident_becomes_exchange': <function __main__.p_nuclear_accident_becomes_exchange(war)>,\n",
       " 'p_catastrophe_from_nuclear_exchange': <function __main__.p_catastrophe_from_nuclear_exchange(war)>,\n",
       " 'p_xrisk_from_nuclear_catastrophe': 0.05,\n",
       " 'p_nuclear_exchange_given_war': <function __main__.p_nuclear_exchange_given_war(first_year_of_war)>,\n",
       " 'p_great_power_war_us_russia_without_nuke_first': <function __main__.p_great_power_war_us_russia_without_nuke_first(peace, year, variables)>,\n",
       " 'p_great_power_war_us_china': <function __main__.p_great_power_war_us_china(peace, year, variables)>,\n",
       " 'p_great_power_war_other': <function __main__.p_great_power_war_other(peace, year, variables)>,\n",
       " 'war_length': <Distribution> lognorm(mean=2.3, sd=0.98),\n",
       " 'peace_length': <Distribution> lognorm(mean=3.45, sd=0.7),\n",
       " 'p_biowar_given_war': 0.00125,\n",
       " 'p_nonstate_bio': 0.0008333333333333334,\n",
       " 'p_natural_bio_is_catastrophe': 0.31622776601683794,\n",
       " 'p_engineered_bio_is_catastrophe': 0.31622776601683794,\n",
       " 'p_covid_spanish_flu_like_becomes_1pct_death': 0.31622776601683794,\n",
       " 'p_covid_lab_leak': 0.3,\n",
       " 'p_extinction_given_90_pct_death': 0.03,\n",
       " 'p_accidental_catastrophe_causes_90_pct_death': 0.1,\n",
       " 'p_intentional_catastrophe_causes_90_pct_death': 0.1,\n",
       " 'ratio_engineered_vs_natural_lab_leak': 0.8,\n",
       " 'p_natural_bio': <function __main__.p_natural_bio(year, variables)>,\n",
       " 'p_accidental_bio': <function __main__.p_accidental_bio(war, variables)>,\n",
       " 'p_xrisk_from_accidental_bio_given_catastrophe': <function __main__.p_xrisk_from_accidental_bio_given_catastrophe(year, variables)>,\n",
       " 'p_xrisk_from_engineered_bio_given_catastrophe': <function __main__.p_xrisk_from_engineered_bio_given_catastrophe(year, variables)>,\n",
       " 'p_nanotech_possible': <function __main__.p_nanotech_possible(year)>,\n",
       " 'p_nanotech_is_xrisk': 0.005000000000000001,\n",
       " 'p_supervolcano_catastrophe': 2e-06,\n",
       " 'p_supervolcano_extinction_given_catastrophe': 0.05,\n",
       " 'p_unknown_unknown_xrisk': <function __main__.p_unknown_unknown_xrisk(year)>,\n",
       " 'p_extinction_from_double_catastrophe': 0.1,\n",
       " 'extinction_from_double_catastrophe_range': 10,\n",
       " 'if_catastrophe_delay_tai_arrival_by_years': <Distribution> lognorm(mean=1.5, sd=0.49),\n",
       " 'if_us_china_war_delay_tai_arrival_by_years': <Distribution> lognorm(mean=1.5, sd=0.49),\n",
       " 'tai_years': array([2028, 2046, 2061, ..., 2031, 2124, 2039])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARS['tai_years'] = np.array(VARS['tai_years'])\n",
    "VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1e7250-1d6a-467a-b6c2-3a3f479b651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TAI scenarios module\n",
      "Loaded nuclear scenarios module\n",
      "Loaded great power war scenarios module\n",
      "Loaded bio scenarios module\n",
      "Loaded nano scenarios module\n",
      "Loaded supervolcano module\n",
      "Loaded unknown unknown scenarios module\n",
      "Loaded double dip catastrophe module\n",
      "Loaded TAI timelines module\n",
      "Loading from cache file (`caches/tai_years.sqcache`)...\n",
      "...Loaded\n",
      "Caching in-memory...\n",
      "...Cached!\n",
      "...Reducing\n",
      "...Reduced!\n",
      "...All done!\n",
      "loaded TAI variables from cache\n"
     ]
    }
   ],
   "source": [
    "years = range(VARS['CURRENT_YEAR'], VARS['MAX_YEAR'])\n",
    "\n",
    "exec(open('modules/tai_risk.py').read())\n",
    "print('Loaded TAI scenarios module')\n",
    "\n",
    "exec(open('modules/nuclear.py').read())\n",
    "print('Loaded nuclear scenarios module')\n",
    "\n",
    "exec(open('modules/great_power_war.py').read())\n",
    "print('Loaded great power war scenarios module')\n",
    "\n",
    "exec(open('modules/bio.py').read())\n",
    "print('Loaded bio scenarios module')\n",
    "\n",
    "exec(open('modules/nano.py').read())\n",
    "print('Loaded nano scenarios module')\n",
    "\n",
    "exec(open('modules/supervolcano.py').read())\n",
    "print('Loaded supervolcano module')\n",
    "\n",
    "exec(open('modules/unknown_unknown.py').read())\n",
    "print('Loaded unknown unknown scenarios module')\n",
    "\n",
    "exec(open('modules/double_dip_catastrophe.py').read())\n",
    "print('Loaded double dip catastrophe module')\n",
    "\n",
    "exec(open('modules/tai_timelines.py').read())\n",
    "print('Loaded TAI timelines module')\n",
    "\n",
    "tai_years = bayes.bayesnet(load_cache_file='caches/tai_years', verbose=True)\n",
    "print('loaded TAI variables from cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9287545-2852-4ab6-b2b5-5fc616877715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value at present: 320 billion QALY\n",
      "Total additional value over 100 years: 600 billion QALY\n",
      "Total value of future: 920 billion QALY\n"
     ]
    }
   ],
   "source": [
    "# TODO: Variation on these inputs?\n",
    "human_population = 8*B # TODO: Animals? Chance present is net negative?\n",
    "qaly_per_person = 40 # TODO: Improvements in health over time?\n",
    "VARS['total_present_value'] = human_population * qaly_per_person\n",
    "print('Total value at present: {} QALY'.format(numerize(VARS['total_present_value'])))\n",
    "\n",
    "births_per_year = 100*M # TODO: Digital minds? Population decline?\n",
    "qaly_per_birth = 60 # TODO: Improvements in health over time?\n",
    "VARS['total_additional_value_per_year'] = births_per_year * qaly_per_birth\n",
    "\n",
    "VARS['years_to_consider'] = 100  # TODO: Expand somehow to include more years?\n",
    "total_additional_value = VARS['total_additional_value_per_year'] * VARS['years_to_consider']\n",
    "print('Total additional value over 100 years: {} QALY'.format(numerize(total_additional_value)))\n",
    "\n",
    "total_value = VARS['total_present_value'] + total_additional_value\n",
    "print('Total value of future: {} QALY'.format(numerize(total_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6a84266-e875-4a76-9f5f-606def1249ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded world state valuation module\n"
     ]
    }
   ],
   "source": [
    "exec(open('modules/world_state_value.py').read())\n",
    "print('Loaded world state valuation module')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f78010-5d07-4d20-b02d-6bbc579afc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Loading from cache file (`caches/future_assessment_model_cache_short.sqcache`)...\n",
      "...Loaded\n",
      "Caching in-memory...\n",
      "...Cached!\n",
      "...Finding\n",
      "...Found!\n",
      "...All done!\n",
      "CPU times: user 32.6 s, sys: 9.23 s, total: 41.8 s\n",
      "Wall time: 49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'category': 'xrisk_subtly_unaligned_tai',\n",
       " 'tai': True,\n",
       " 'tai_year': 2033,\n",
       " 'tai_type': 'agent',\n",
       " 'nano': False,\n",
       " 'wars': [],\n",
       " 'war': False,\n",
       " 'war_start_year': None,\n",
       " 'war_end_year': None,\n",
       " 'russia_nuke_first': False,\n",
       " 'china_nuke_first': False,\n",
       " 'war_belligerents': None,\n",
       " 'peace_until': None,\n",
       " 'engineered_pathogen': False,\n",
       " 'natural_pathogen': False,\n",
       " 'lab_leak': False,\n",
       " 'state_bioweapon': False,\n",
       " 'nonstate_bioweapon': False,\n",
       " 'averted_misalignment': False,\n",
       " 'nuclear_weapon_used': False,\n",
       " 'catastrophe': [],\n",
       " 'recent_catastrophe_year': None,\n",
       " 'terminate': True,\n",
       " 'final_year': 2035,\n",
       " 'double_catastrophe_xrisk': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "exec(open('modules/define_event.py').read())\n",
    "print('Model loaded')\n",
    "\n",
    "# TODO: Reduce amount of information in cache file (only need final year) to improve load speed\n",
    "collectors = bayes.bayesnet(define_event,\n",
    "                            find=lambda e: e['collectors'][VARS['MAX_YEAR'] - 1],\n",
    "                            load_cache_file='caches/future_assessment_model_cache_short',\n",
    "                            reload_cache=False,\n",
    "                            raw=True,\n",
    "                            verbose=True,\n",
    "                            cores=1,\n",
    "                            n=VARS['RUNS'])\n",
    "collectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01be1348-d256-4676-a854-c8c68a5866cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 111705.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV of future: 608 billion QALY\n",
      "-\n",
      "{1: '10^11.5',\n",
      " 5: '10^11.6',\n",
      " 10: '10^11.6',\n",
      " 20: '10^11.6',\n",
      " 30: '10^11.6',\n",
      " 40: '10^11.6',\n",
      " 50: '10^11.7',\n",
      " 60: '10^11.8',\n",
      " 70: '10^12.0',\n",
      " 80: '10^12.0',\n",
      " 90: '10^12.0',\n",
      " 95: '10^12.0',\n",
      " 99: '10^12.0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "value_of_future = [value_of_world_state(world_state=c, variables=VARS) for c in tqdm(collectors)]\n",
    "\n",
    "print('EV of future: {} QALY'.format(numerize(np.mean(value_of_future))))\n",
    "print('-')\n",
    "pprint(sq.get_log_percentiles(value_of_future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "970d0d5c-caea-4048-b36a-1e8baece826b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running intervention model...\n",
      "Generating Bayes net with 5 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [07:58<00:00, 104.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling data...\n",
      "Waiting for other cores...\n",
      "Collecting data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:48<00:00, 21.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Collected!\n",
      "Caching in-memory...\n",
      "...Cached!\n",
      "...Finding\n",
      "...Found!\n",
      "...All done!\n",
      "Ready\n",
      "CPU times: user 6min 6s, sys: 1min 49s, total: 7min 56s\n",
      "Wall time: 9min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alt_variables = deepcopy(VARS)\n",
    "alt_variables['tai_years'] = [t + 5 for t in alt_variables['tai_years']] # Uniformly and universally delay TAI by 5 years with 100% success\n",
    "\n",
    "# TODO: Be able to declare changes in variables for only particular years\n",
    "\n",
    "print('Running intervention model...')\n",
    "alt_define_event_lambda = lambda: define_event(alt_variables, verbosity=0)\n",
    "alt_collectors = bayes.bayesnet(alt_define_event_lambda,\n",
    "                                find=lambda e: e['collectors'][VARS['MAX_YEAR'] - 1],\n",
    "                                raw=True,\n",
    "                                verbose=True,\n",
    "                                cores=5,\n",
    "                                n=VARS['RUNS'])\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c134a2-3676-42fc-9f20-c88e2f9f07ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating value...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [00:00<00:00, 332077.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Calculating value...')\n",
    "value_of_alt_future = [value_of_world_state(world_state=c, variables=alt_variables) for c in tqdm(alt_collectors)]\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fecab83-8618-49ff-9eda-3c7919dd728a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "EV of default future: 608 billion QALY\n",
      "EV of alt future: 628 billion QALY\n",
      "-\n",
      "Diff / Value of intervention: Alt future is 20 billion QALY relative to default\n",
      "-\n",
      "Distribution of default future\n",
      "{1: 344000000000.0,\n",
      " 5: 362000000000.0,\n",
      " 10: 368000000000.0,\n",
      " 20: 392000000000.0,\n",
      " 30: 416000000000.0,\n",
      " 40: 446000000000.0,\n",
      " 50: 494000000000.0,\n",
      " 60: 572000000000.0,\n",
      " 70: 920000000000.0,\n",
      " 80: 920000000000.0,\n",
      " 90: 920000000000.0,\n",
      " 95: 920000000000.0,\n",
      " 99: 920000000000.0}\n",
      "-\n",
      "Distribution of alt future\n",
      "{1: 374000000000.0,\n",
      " 5: 392000000000.0,\n",
      " 10: 404000000000.0,\n",
      " 20: 428000000000.0,\n",
      " 30: 446000000000.0,\n",
      " 40: 476000000000.0,\n",
      " 50: 524000000000.0,\n",
      " 60: 596000000000.0,\n",
      " 70: 920000000000.0,\n",
      " 80: 920000000000.0,\n",
      " 90: 920000000000.0,\n",
      " 95: 920000000000.0,\n",
      " 99: 920000000000.0}\n"
     ]
    }
   ],
   "source": [
    "print('-')\n",
    "print('EV of default future: {} QALY'.format(numerize(np.mean(value_of_future))))\n",
    "print('EV of alt future: {} QALY'.format(numerize(np.mean(value_of_alt_future))))\n",
    "print('-')\n",
    "print('Diff / Value of intervention: Alt future is {} QALY relative to default'.format(numerize(np.mean(value_of_alt_future) - np.mean(value_of_future))))\n",
    "print('-')\n",
    "print('Distribution of default future')\n",
    "pprint(sq.get_percentiles(value_of_future))\n",
    "print('-')\n",
    "print('Distribution of alt future')\n",
    "pprint(sq.get_percentiles(value_of_alt_future))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
