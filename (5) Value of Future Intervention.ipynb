{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc97373-f651-4bd0-a101-be321958b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dill\n",
    "\n",
    "import numpy as np\n",
    "import squigglepy as sq\n",
    "\n",
    "from squigglepy.numbers import K, M, B\n",
    "from squigglepy import bayes\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from datetime import datetime as dt\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa2de6d-aecf-4028-a1cd-7db77ac8594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache from: 2023-10-29 20:48:36.002006\n",
      "loaded default variables from cache!\n"
     ]
    }
   ],
   "source": [
    "with open('caches/variables.dill', 'rb') as f:\n",
    "    VARS = dill.load(f)\n",
    "print('Cache from: {}'.format(dt.fromtimestamp(os.path.getmtime('caches/variables.dill'))))\n",
    "print('loaded default variables from cache!') # Default variables are defined in \"(4) XRisk Model.ipynb\"\n",
    "# TODO: can do sensitivity analysis or VOI analysis over all the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27eb4ca-9e6f-496b-a0f6-de3ef83802ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VARS['tai_years'] = np.array(VARS['tai_years'])\n",
    "len(VARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd1e7250-1d6a-467a-b6c2-3a3f479b651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TAI scenarios module\n",
      "Loaded nuclear scenarios module\n",
      "Loaded great power war scenarios module\n",
      "Loaded bio scenarios module\n",
      "Loaded nano scenarios module\n",
      "Loaded supervolcano module\n",
      "Loaded unknown unknown scenarios module\n",
      "Loaded double dip catastrophe module\n",
      "Loaded TAI timelines module\n",
      "Loading from cache file (`caches/tai_years.sqcache`)...\n",
      "...Loaded\n",
      "Caching in-memory...\n",
      "...Cached!\n",
      "...Reducing\n",
      "...Reduced!\n",
      "...All done!\n",
      "loaded TAI variables from cache\n",
      "Cache from: 2023-10-29 20:45:28.031086\n"
     ]
    }
   ],
   "source": [
    "years = range(VARS['CURRENT_YEAR'], VARS['MAX_YEAR'])\n",
    "\n",
    "exec(open('modules/tai_risk.py').read())\n",
    "print('Loaded TAI scenarios module')\n",
    "\n",
    "exec(open('modules/nuclear.py').read())\n",
    "print('Loaded nuclear scenarios module')\n",
    "\n",
    "exec(open('modules/great_power_war.py').read())\n",
    "print('Loaded great power war scenarios module')\n",
    "\n",
    "exec(open('modules/bio.py').read())\n",
    "print('Loaded bio scenarios module')\n",
    "\n",
    "exec(open('modules/nano.py').read())\n",
    "print('Loaded nano scenarios module')\n",
    "\n",
    "exec(open('modules/supervolcano.py').read())\n",
    "print('Loaded supervolcano module')\n",
    "\n",
    "exec(open('modules/unknown_unknown.py').read())\n",
    "print('Loaded unknown unknown scenarios module')\n",
    "\n",
    "exec(open('modules/double_dip_catastrophe.py').read())\n",
    "print('Loaded double dip catastrophe module')\n",
    "\n",
    "exec(open('modules/tai_timelines.py').read())\n",
    "print('Loaded TAI timelines module')\n",
    "\n",
    "tai_years = bayes.bayesnet(load_cache_file='caches/tai_years', verbose=True)\n",
    "print('loaded TAI variables from cache')\n",
    "print('Cache from: {}'.format(dt.fromtimestamp(os.path.getmtime('caches/tai_years.sqcache'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9287545-2852-4ab6-b2b5-5fc616877715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total value at present: 320 billion QALY\n",
      "Total additional value over 100 years: 600 billion QALY\n",
      "Total value of future: 920 billion QALY\n"
     ]
    }
   ],
   "source": [
    "# TODO: Variation on these inputs?\n",
    "human_population = 8*B # TODO: Animals? Chance present is net negative?\n",
    "qaly_per_person = 40 # TODO: Improvements in health over time?\n",
    "VARS['total_present_value'] = human_population * qaly_per_person\n",
    "print('Total value at present: {} QALY'.format(numerize(VARS['total_present_value'])))\n",
    "\n",
    "births_per_year = 100*M # TODO: Digital minds? Population decline?\n",
    "qaly_per_birth = 60 # TODO: Improvements in health over time?\n",
    "VARS['total_additional_value_per_year'] = births_per_year * qaly_per_birth\n",
    "\n",
    "VARS['years_to_consider'] = 100  # TODO: Expand somehow to include more years?\n",
    "total_additional_value = VARS['total_additional_value_per_year'] * VARS['years_to_consider']\n",
    "print('Total additional value over 100 years: {} QALY'.format(numerize(total_additional_value)))\n",
    "\n",
    "total_value = VARS['total_present_value'] + total_additional_value\n",
    "print('Total value of future: {} QALY'.format(numerize(total_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6a84266-e875-4a76-9f5f-606def1249ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded world state valuation module\n"
     ]
    }
   ],
   "source": [
    "exec(open('modules/world_state_value.py').read())\n",
    "print('Loaded world state valuation module')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f78010-5d07-4d20-b02d-6bbc579afc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "Loading from cache file (`caches/future_assessment_model_cache.sqcache`)...\n",
      "...Loaded\n",
      "Caching in-memory...\n",
      "...Cached!\n",
      "...Finding\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'collectors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.11/site-packages/squigglepy/bayes.py:288\u001b[0m, in \u001b[0;36mbayesnet\u001b[0;34m(event_fn, n, find, conditional_on, reduce_fn, raw, memcache, memcache_load, memcache_save, reload_cache, dump_cache_file, load_cache_file, cache_file_primary, verbose, cores)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...Finding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 288\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...Found!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.11/site-packages/squigglepy/bayes.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...Finding\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 288\u001b[0m events \u001b[38;5;241m=\u001b[39m [\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m events]\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...Found!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m<timed exec>:6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'collectors'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "exec(open('modules/define_event.py').read())\n",
    "print('Model loaded')\n",
    "\n",
    "# TODO: Reduce amount of information in cache file (only need final year) to improve load speed\n",
    "collectors = bayes.bayesnet(define_event,\n",
    "                            find=lambda e: e['collectors'][VARS['MAX_YEAR'] - 1],\n",
    "                            load_cache_file='caches/future_assessment_model_cache',\n",
    "                            reload_cache=False,\n",
    "                            raw=True,\n",
    "                            verbose=True,\n",
    "                            cores=1,\n",
    "                            n=VARS['RUNS'])\n",
    "collectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01be1348-d256-4676-a854-c8c68a5866cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m value_of_future \u001b[38;5;241m=\u001b[39m [value_of_world_state(world_state\u001b[38;5;241m=\u001b[39mc, variables\u001b[38;5;241m=\u001b[39mVARS) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mcollectors\u001b[49m)]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEV of future: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m QALY\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(numerize(np\u001b[38;5;241m.\u001b[39mmean(value_of_future))))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collectors' is not defined"
     ]
    }
   ],
   "source": [
    "value_of_future = [value_of_world_state(world_state=c, variables=VARS) for c in tqdm(collectors)]\n",
    "\n",
    "print('EV of future: {} QALY'.format(numerize(np.mean(value_of_future))))\n",
    "print('-')\n",
    "pprint(sq.get_log_percentiles(value_of_future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d0d5c-caea-4048-b36a-1e8baece826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alt_variables = deepcopy(VARS)\n",
    "alt_variables['tai_years'] = [t + 5 for t in alt_variables['tai_years']] # Uniformly and universally delay TAI by 5 years with 100% success\n",
    "\n",
    "# TODO: Be able to declare changes in variables for only particular years\n",
    "\n",
    "print('Running intervention model...')\n",
    "alt_define_event_lambda = lambda: define_event(alt_variables, verbosity=0)\n",
    "alt_collectors = bayes.bayesnet(alt_define_event_lambda,\n",
    "                                find=lambda e: e['collectors'][VARS['MAX_YEAR'] - 1],\n",
    "                                raw=True,\n",
    "                                verbose=True,\n",
    "                                cores=5,\n",
    "                                n=VARS['RUNS'])\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c134a2-3676-42fc-9f20-c88e2f9f07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating value...')\n",
    "value_of_alt_future = [value_of_world_state(world_state=c, variables=alt_variables) for c in tqdm(alt_collectors)]\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fecab83-8618-49ff-9eda-3c7919dd728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-')\n",
    "print('EV of default future: {} QALY'.format(numerize(np.mean(value_of_future))))\n",
    "print('EV of alt future: {} QALY'.format(numerize(np.mean(value_of_alt_future))))\n",
    "print('-')\n",
    "print('Diff / Value of intervention: Alt future is {} QALY relative to default'.format(numerize(np.mean(value_of_alt_future) - np.mean(value_of_future))))\n",
    "print('-')\n",
    "print('Distribution of default future')\n",
    "pprint(sq.get_log_percentiles(value_of_future))\n",
    "print('-')\n",
    "print('Distribution of alt future')\n",
    "pprint(sq.get_log_percentiles(value_of_alt_future))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b96aa-361c-46c7-a6d5-237d9a7ef39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('File last ran: {}'.format(dt.now()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
