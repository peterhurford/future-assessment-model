{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1\n",
      "Loaded 2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import squigglepy as sq\n",
    "from squigglepy import bayes\n",
    "from squigglepy.numbers import K, M, B, T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "from scipy import stats\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "print('Loaded 1')\n",
    "\n",
    "\n",
    "exec(open('utils.py').read())\n",
    "print('Loaded 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded\n"
     ]
    }
   ],
   "source": [
    "# Global variables - probably don't want to change these but you could.\n",
    "RUNS = 100*K                                      # Number of runs to do (default 100*K)\n",
    "CURRENT_YEAR = 2023                               # What year to start the run on? (default: 2023)\n",
    "MAX_YEAR = 2123                                   # What year to end the run on? (default: 2123)\n",
    "\n",
    "\n",
    "years = range(CURRENT_YEAR, MAX_YEAR)\n",
    "print('Loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TAI Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded TAI scenarios module\n"
     ]
    }
   ],
   "source": [
    "# Conditoinal on making TAI, will it be agentic?\n",
    "p_make_agent_tai = 0.9\n",
    "\n",
    "# Conditional on making agentic TAI, will it be aligned by default?\n",
    "p_tai_aligned_by_default = 0.2\n",
    "\n",
    "# Conditional on making agentic TAI that is not aligned by default, will we solve the alignment problem?\n",
    "# Varies by year, whether this is the first attempt, and whether there is a great power war\n",
    "def p_alignment_solved(war, year, first_attempt=True, verbose=False):\n",
    "    if first_attempt:\n",
    "        p = min(0.1 + 1.3 * (year/45), 0.75)\n",
    "    else:\n",
    "        p = min(0.1 + 1.9 * (year/45), 0.85)\n",
    "    if war:\n",
    "        p = p * 0.7\n",
    "    if verbose == 2:\n",
    "        print('* alignment diagnostic - war: {} year: {} first attempt: {} -> p {})'.format(war, year, first_attempt, p))\n",
    "    return p\n",
    "# TODO: Convert to logistic curves\n",
    "\n",
    "# Conditional on solving the alignment problem, what is the chance we also solve the subtle misalignment problem?\n",
    "p_subtle_alignment_solved = 0.85\n",
    "\n",
    "# Conditional on alignment by default, what is the chance we also solve the subtle misalignment problem?\n",
    "p_subtle_alignment_solved_if_aligned_by_default = 0.4\n",
    "\n",
    "# Conditional on having agentic TAI, will it be intentionally misused to create a singleton?\n",
    "def p_tai_intentional_misuse(war):\n",
    "    return 0.3 if war else 0.05\n",
    "\n",
    "# If TAI is fully misaligned what is the chance we can successfully detect and avert this?\n",
    "p_full_tai_misalignment_averted = 0.15\n",
    "\n",
    "# If TAI is fully misaligned but successfully averted, what is the probability there will be a catasrophe (10%+ death)?\n",
    "p_tai_misalignment_averting_is_catastrophic = 0.4\n",
    "\n",
    "# If TAI is fully misaligned and we successfully avert it, what is the chance we give up on TAI?\n",
    "p_full_tai_misalignment_averted_means_abandoned_tai = 0.7\n",
    "\n",
    "# If TAI is fully misaligned, what is the chance it results in extinction versus a singleton?\n",
    "p_tai_xrisk_is_extinction = 0.4\n",
    "\n",
    "# If there is a fully misaligned TAI singleton, what is the chance it results in a non-extinction catastrophe (10%+ death)?\n",
    "p_tai_singleton_is_catastrophic = 0.8\n",
    "\n",
    "\n",
    "exec(open('modules/tai.py').read())\n",
    "print('Loaded TAI scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nuclear Scenarios Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded nuclear scenarios module\n"
     ]
    }
   ],
   "source": [
    "def p_russia_uses_nuke(peace, year):\n",
    "    peace = 10 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year == 2023:\n",
    "        return 0.03\n",
    "    else:\n",
    "        return 0.001 / peace\n",
    "\n",
    "    \n",
    "p_nk_uses_nuke = 0.001\n",
    "\n",
    "\n",
    "def p_china_invades_taiwan(peace, year):\n",
    "    peace = 10 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year == 2022:\n",
    "        return 0\n",
    "    elif year == 2023:\n",
    "        return 0.03\n",
    "    elif year == 2024:\n",
    "        return 0.145 # makes cumulative probability by EOY 2025 = 0.17 (0.03 + 0.145*(1-0.03) = 0.17)\n",
    "    elif year < 2030:\n",
    "        return 0.096 # makes cumulative probability by EOY 2029 = 0.5\n",
    "                     # 0.17 + (1-0.17)*X + (1-0.17)(1-X)*X + (1-0.17)(1-X)^2*X + (1-0.17)(1-X)^3*X + (1-0.17)(1-X)^4*X = 0.5\n",
    "    elif year < 2035:\n",
    "        return 0.097 # makes cumulative probability by EOY 2034 = 0.7\n",
    "                     # 0.5 + (1-0.5)*X + (1-0.5)(1-X)*X + (1-0.5)(1-X)^2*X + (1-0.5)(1-X)^3*X + (1-0.5)(1-X)^4*X = 0.7\n",
    "    else:\n",
    "        return 0.005 / peace\n",
    "\n",
    "\n",
    "def p_china_uses_nuke(peace, year):\n",
    "    return p_china_invades_taiwan(peace, year) * 0.01\n",
    "\n",
    "    \n",
    "def p_other_uses_nuke(peace):\n",
    "    peace = 10 if peace else 1\n",
    "    return 0.0002 / peace\n",
    "\n",
    "\n",
    "# What is the chance in a given year there will be a \"nuclear accident\"?\n",
    "def p_nuclear_accident(war, year):\n",
    "    p = 0.05 if war else 0.02\n",
    "    p = p * (0.998 ** year)\n",
    "    return p\n",
    "\n",
    "\n",
    "# Conditional on a nuclear accident, what is the chance it escalates into an \"exchange\"?\n",
    "def p_nuclear_accident_becomes_exchange(war):\n",
    "    return 0.2 if war else 0.05\n",
    "\n",
    "\n",
    "# Conditional on a nuclear exchange, what is the chance it escalates into a catastrophe (10%+ dead)?\n",
    "def p_catastrophe_from_nuclear_exchange(war):\n",
    "    p_exchange_becomes_all_out_war = 0.6 if war else 0.3\n",
    "    p_nuclear_winter_happens = 0.3\n",
    "    alternative_foods_or_other_save = 0.05\n",
    "    return (p_exchange_becomes_all_out_war *\n",
    "            (p_nuclear_winter_happens + (1 - p_nuclear_winter_happens) * 0.1) *\n",
    "            (1 - alternative_foods_or_other_save))\n",
    "    \n",
    "    \n",
    "# Conditional on a nuclear exchange catastrophe, what is the chance it becomes an xrisk?\n",
    "p_xrisk_from_nuclear_catastrophe = 0.05 # https://forum.effectivealtruism.org/posts/GsjmufaebreiaivF7/what-is-the-likelihood-that-civilizational-collapse-would\n",
    "\n",
    "\n",
    "# Conditional on a great power war, what is the chance it goes intentionally nuclear in any given year?\n",
    "def p_nuclear_exchange_given_war(first_year_of_war):\n",
    "    return 0.1 if first_year_of_war else 0.02\n",
    "\n",
    "\n",
    "exec(open('modules/nuclear.py').read())\n",
    "print('Loaded nuclear scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Power War Scenarios Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded great power war scenarios module\n"
     ]
    }
   ],
   "source": [
    "def p_great_power_war_us_russia_without_nuke_first(peace, year):\n",
    "    peace = 20 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year == 2022 or year == 2023:\n",
    "        return (0.02 / 2) / peace\n",
    "    else:\n",
    "        return 0.003 / peace\n",
    "\n",
    "    \n",
    "def p_great_power_war_us_china(peace, year):\n",
    "    peace = 20 if peace else 1\n",
    "    p_invade_taiwan = p_china_invades_taiwan(peace, year)\n",
    "    p_us_responds = 0.6\n",
    "    return p_invade_taiwan * p_us_responds\n",
    "\n",
    "    \n",
    "def p_great_power_war_other(peace, year):\n",
    "    peace = 5 if peace else 1\n",
    "    year = year + CURRENT_YEAR\n",
    "    if year > 2040:\n",
    "        return 0.005 / peace\n",
    "    else:\n",
    "        return 0.001 / peace\n",
    "\n",
    "\n",
    "# Conditional on a great power war starting, how long will it last?\n",
    "war_length = sq.lognorm(2, 50) # 90% CI\n",
    "\n",
    "# After a war ends, how long will there be a peace?\n",
    "peace_length = sq.lognorm(10, 100)\n",
    "\n",
    "\n",
    "exec(open('modules/great_power_war.py').read())\n",
    "print('Loaded great power war scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bio scenarios module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bio scenarios module\n"
     ]
    }
   ],
   "source": [
    "# Conditional on a great power war, what is the annual chance it intentionally results in a bioweapon?\n",
    "p_biowar_given_war = 1/800\n",
    "\n",
    "# What is the annual chance of a non-state actor creating an intentional biorisk that causes 1%+ death?\n",
    "p_nonstate_bio = 1/1200\n",
    "\n",
    "# What is the chance that if 1%+ die from natural bio, 10%+ will die from natural bio?\n",
    "p_natural_bio_is_catastrophe = 1 / (10 ** 0.5) # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "\n",
    "# What is the chance that if 1%+ die from engineered bio, 10%+ will die from engineered bio?\n",
    "p_engineered_bio_is_catastrophe = 1 / (10 ** 0.5) # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "\n",
    "p_covid_spanish_flu_like_becomes_1pct_death = 1 / (10 ** 0.5) # https://www.economist.com/graphic-detail/coronavirus-excess-deaths-estimates suggests COVID killed 0.2%... https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028 suggests 1% is 2x less likely than 0.2%\n",
    "p_covid_lab_leak = 0.3\n",
    "p_extinction_given_90_pct_death = 0.03 # per Luisa https://forum.effectivealtruism.org/posts/GsjmufaebreiaivF7/what-is-the-likelihood-that-civilizational-collapse-would\n",
    "p_accidental_catastrophe_causes_90_pct_death = (1 / (10 ** 0.5)) ** 2 # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "p_intentional_catastrophe_causes_90_pct_death = (1 / (10 ** 0.5)) ** 2 # https://www.liebertpub.com/doi/pdfplus/10.1089/hs.2017.0028\n",
    "\n",
    "# If a lab leak occurs, how likely is it that the leaked pandemic will be engineered vs. natural?\n",
    "ratio_engineered_vs_natural_lab_leak = 0.8\n",
    "\n",
    "# What is the chance of an natural biorisk/pandemic causing 1%+ population death?\n",
    "def p_natural_bio(year):\n",
    "    base_rate_from_covid_and_spanish_flu = 1/250\n",
    "    increase_from_globalization = 1.1\n",
    "    decreate_in_rate_per_year_from_improvements = 0.99 ** year\n",
    "    return ((base_rate_from_covid_and_spanish_flu * 0.5 +\n",
    "             base_rate_from_covid_and_spanish_flu * (1 - p_covid_lab_leak) * 0.5) *\n",
    "            increase_from_globalization *\n",
    "            p_covid_spanish_flu_like_becomes_1pct_death *\n",
    "            decreate_in_rate_per_year_from_improvements)\n",
    "    \n",
    "    \n",
    "# What is the chance of an accidental biorisk (e.g., lab leak) causing 1%+ population death?\n",
    "def p_accidental_bio(war):\n",
    "    base_rate_from_covid = 0.01 * p_covid_lab_leak\n",
    "    increase_factor_due_to_increasing_labs = 1.3\n",
    "    increase_factor_due_to_great_power_war = 2\n",
    "    p = (base_rate_from_covid *\n",
    "         p_covid_spanish_flu_like_becomes_1pct_death *\n",
    "         increase_factor_due_to_increasing_labs)\n",
    "    return p * increase_factor_due_to_great_power_war if war else p\n",
    "    \n",
    "\n",
    "# Conditional on a accidental biorisk (1% death), what is the chance it becomes a xrisk?\n",
    "def p_xrisk_from_accidental_bio_given_catastrophe(year):\n",
    "    return p_accidental_catastrophe_causes_90_pct_death * p_extinction_given_90_pct_death\n",
    "\n",
    "\n",
    "# Conditional on a bioweapon, what is the chance it becomes a xrisk?\n",
    "def p_xrisk_from_engineered_bio_given_catastrophe(year):\n",
    "    return p_intentional_catastrophe_causes_90_pct_death * p_extinction_given_90_pct_death\n",
    "\n",
    "\n",
    "exec(open('modules/bio.py').read())\n",
    "print('Loaded bio scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nanotech scenarios module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded nano scenarios module\n"
     ]
    }
   ],
   "source": [
    "# What is the chance in a given year that nanotech will be developed?\n",
    "def p_nanotech_possible(year):\n",
    "    return 0.0001 / (0.956 ** year) # TODO: This goes over 1\n",
    "\n",
    "\n",
    "# Conditional on developing nanotech, what is the chance nanotech results in an xrisk?\n",
    "p_nanotech_is_xrisk = 0.1 * 0.05\n",
    "\n",
    "\n",
    "exec(open('modules/nano.py').read())\n",
    "print('Loaded nano scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervolcano scenarios module (all other natural risks <0.01%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded supervolcano module\n"
     ]
    }
   ],
   "source": [
    "p_supervolcano_catastrophe = 1 / (500*K)  # https://www.openphilanthropy.org/research/large-volcanic-eruptions/ VEI >= 9 (geometric mean of 30K and 30M)\n",
    "\n",
    "p_supervolcano_extinction_given_catastrophe = 0.05\n",
    "\n",
    "\n",
    "exec(open('modules/supervolcano.py').read())\n",
    "print('Loaded supervolcano module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unknown unknown scenarios module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded unknown unknown scenarios module\n"
     ]
    }
   ],
   "source": [
    "# What is the chance in any given year that an unknown unknown xrisk occurs?\n",
    "def p_unknown_unknown_xrisk(year):\n",
    "    return (1 / (100*K)) / (0.99 ** year) # TODO: This goes over 1\n",
    "\n",
    "\n",
    "p_extinction_from_double_catastrophe = 0.1\n",
    "extinction_from_double_catastrophe_range = 10\n",
    "    \n",
    "    \n",
    "exec(open('modules/unknown_unknown.py').read())\n",
    "print('Loaded unknown unknown scenarios module')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Timeline variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2025.0,\n",
       " 5: 2028.0,\n",
       " 10: 2030.0,\n",
       " 20: 2036.0,\n",
       " 30: 2042.0,\n",
       " 40: 2049.0,\n",
       " 50: 2058.0,\n",
       " 60: 2069.0,\n",
       " 70: 2083.0,\n",
       " 80: 2124.0,\n",
       " 90: 2124.0,\n",
       " 95: 2124.0,\n",
       " 99: 2124.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tai_years = bayes.bayesnet(load_cache_file='caches/tai_years')\n",
    "tai_years = [y['tai_year'] for y in tai_years]\n",
    "\n",
    "# TODO: War spending\n",
    "# TODO: TAI China delay\n",
    "# TODO: TAI Catastrophe delay\n",
    "\n",
    "sq.get_percentiles(tai_years)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall module structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "exec(open('modules/define_event.py').read())\n",
    "print('Model loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############\n",
      "## RUN 1 ##\n",
      "############\n",
      "2028: WAR!!! (US vs. China)\n",
      "--- /!\\ TAI CREATED in 2032\n",
      "2033: ...Misaligned TAI happened, it was averted with catastrophe, and we abandon TAI\n",
      "2042: War ends :)\n",
      "...Total loop complete in 225.6ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 2 ##\n",
      "############\n",
      "2033: WAR!!! (US vs. China)\n",
      "--- /!\\ TAI CREATED in 2089\n",
      "2090: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 42.7ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 3 ##\n",
      "############\n",
      "2023: Russia uses a nuke first strike (outside of great power war)!\n",
      "2024: WAR!!! (US vs. Russia)\n",
      "2056: War ends :)\n",
      "...Total loop complete in 88.64ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 4 ##\n",
      "############\n",
      "2025: Russia uses a nuke first strike (outside of great power war)!\n",
      "2026: WAR!!! (US vs. Russia)\n",
      "2028: War ends :)\n",
      "2030: WAR!!! (US vs. China)\n",
      "2040: War ends :)\n",
      "2074: ...catastrophe from natural pathogen\n",
      "...Total loop complete in 44.27ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 5 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2051\n",
      "2052: ...Achieved aligned TAI (aligned by default), happy future! :D\n",
      "...Total loop complete in 38.29ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 6 ##\n",
      "############\n",
      "2028: WAR!!! (US vs. China)\n",
      "2042: War ends :)\n",
      "2057: WAR!!! (Other)\n",
      "2063: War ends :)\n",
      "--- /!\\ TAI CREATED in 2068\n",
      "2069: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 38.77ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 7 ##\n",
      "############\n",
      "2030: WAR!!! (US vs. China)\n",
      "2035: War ends :)\n",
      "...Total loop complete in 42.24ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 8 ##\n",
      "############\n",
      "2032: WAR!!! (US vs. China)\n",
      "--- /!\\ TAI CREATED in 2056\n",
      "2057: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 77.85ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 9 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2035\n",
      "2036: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 32.63ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 10 ##\n",
      "############\n",
      "2025: WAR!!! (US vs. China)\n",
      "2028: War ends :)\n",
      "--- /!\\ TAI CREATED in 2029\n",
      "2030: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 34.45ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 11 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2030\n",
      "2031: ...XRISK from fully unaligned TAI (singleton) :(\n",
      "...Singleton is catastrophic\n",
      "...Total loop complete in 32.93ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 12 ##\n",
      "############\n",
      "2031: WAR!!! (US vs. China)\n",
      "--- /!\\ TAI CREATED in 2031\n",
      "2032: ...XRISK from intentional misuse of TAI (singleton) :(\n",
      "...Singleton is catastrophic\n",
      "...Total loop complete in 33.21ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 13 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2029\n",
      "2030: ...XRISK from fully unaligned TAI (extinction) :(\n",
      "...Total loop complete in 76.83ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 14 ##\n",
      "############\n",
      "2023: Russia uses a nuke first strike (outside of great power war)!\n",
      "2024: WAR!!! (US vs. Russia)\n",
      "--- /!\\ TAI CREATED in 2049\n",
      "2050: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 33.65ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 15 ##\n",
      "############\n",
      "2027: WAR!!! (US vs. China)\n",
      "2035: War ends :)\n",
      "2065: WAR!!! (Other)\n",
      "2067: War ends :)\n",
      "--- /!\\ TAI CREATED in 2110\n",
      "2111: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 38.8ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 16 ##\n",
      "############\n",
      "--- /!\\ TAI CREATED in 2029\n",
      "2030: ...XRISK from fully unaligned TAI (singleton) :(\n",
      "...Singleton is catastrophic\n",
      "...Total loop complete in 34.6ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 17 ##\n",
      "############\n",
      "2023: WAR!!! (US vs. Russia)\n",
      "2027: War ends :)\n",
      "--- /!\\ TAI CREATED in 2075\n",
      "2076: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 35.28ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 18 ##\n",
      "############\n",
      "2025: WAR!!! (US vs. China)\n",
      "2056: War ends :)\n",
      "--- /!\\ TAI CREATED in 2109\n",
      "2110: ...XRISK from fully unaligned TAI (singleton) :(\n",
      "...Singleton is catastrophic\n",
      "...Total loop complete in 40.12ms\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 19 ##\n",
      "############\n",
      "2025: WAR!!! (US vs. China)\n",
      "--- /!\\ TAI CREATED in 2027\n",
      "2028: ...Tool TAI made\n",
      "2037: War ends :)\n",
      "...Total loop complete in 84.47ms\n",
      "...Boring future\n",
      "-\n",
      "-\n",
      "############\n",
      "## RUN 20 ##\n",
      "############\n",
      "2023: WAR!!! (US vs. China)\n",
      "2032: War ends :)\n",
      "--- /!\\ TAI CREATED in 2082\n",
      "2083: ...Achieved aligned TAI (aligned via work, 2nd+ attempt), happy future! :D\n",
      "...Total loop complete in 36.47ms\n",
      "-\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print('############')\n",
    "    print('## RUN {} ##'.format(i + 1))\n",
    "    print('############')\n",
    "    define_event(verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading cache...\n",
      "Generating Bayes net with 5 cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████████████████████████████████████████████████████████████▏                                                                                     | 46385/100000 [23:44<34:45, 25.71it/s]Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/queues.py\", line 368, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/connection.py\", line 224, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/connection.py\", line 422, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/connection.py\", line 387, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/pathos/helpers/mp_helper.py\", line 15, in <lambda>\n",
      "    func = lambda args: f(*args)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in multicore_event_fn\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in <listcomp>\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "Process ForkPoolWorker-3:\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 170, in run_event_fn\n",
      "    return event_fn()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<string>\", line 48, in define_event\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "Process ForkPoolWorker-1:\n",
      "  File \"<string>\", line 42, in nuclear_scenarios_module\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/pathos/helpers/mp_helper.py\", line 15, in <lambda>\n",
      "    func = lambda args: f(*args)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/utils.py\", line 201, in event\n",
      "    return event_occurs(p)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in multicore_event_fn\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/utils.py\", line 156, in event_occurs\n",
      "    from .rng import _squigglepy_internal_rng\n",
      "  File \"<frozen importlib._bootstrap>\", line 398, in parent\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in <listcomp>\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 170, in run_event_fn\n",
      "    return event_fn()\n",
      "  File \"<string>\", line 31, in define_event\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 750, in sample\n",
      "    samples = discrete_sample(dist.items,\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 474, in discrete_sample\n",
      "    values = [const(v) for v in values]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 474, in <listcomp>\n",
      "    values = [const(v) for v in values]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 510, in const\n",
      "    return ConstantDistribution(x)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 482, in __init__\n",
      "    super().__init__()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/multiprocess/pool.py\", line 48, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/pathos/helpers/mp_helper.py\", line 15, in <lambda>\n",
      "    func = lambda args: f(*args)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 45, in __init__\n",
      "    super().__init__()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/pathos/helpers/mp_helper.py\", line 15, in <lambda>\n",
      "    func = lambda args: f(*args)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in multicore_event_fn\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 27, in __init__\n",
      "    self.lclip = None\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in <listcomp>\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in multicore_event_fn\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 170, in run_event_fn\n",
      "    return event_fn()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 188, in <listcomp>\n",
      "    batch = [run_event_fn(pbar=pbar, total_cores=total_cores) for _ in r_]\n",
      "  File \"<string>\", line 31, in define_event\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py\", line 170, in run_event_fn\n",
      "    return event_fn()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 750, in sample\n",
      "    samples = discrete_sample(dist.items,\n",
      "  File \"<string>\", line 31, in define_event\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 474, in discrete_sample\n",
      "    values = [const(v) for v in values]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 750, in sample\n",
      "    samples = discrete_sample(dist.items,\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 474, in <listcomp>\n",
      "    values = [const(v) for v in values]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 474, in discrete_sample\n",
      "    values = [const(v) for v in values]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 510, in const\n",
      "    return ConstantDistribution(x)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py\", line 474, in <listcomp>\n",
      "    values = [const(v) for v in values]\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 482, in __init__\n",
      "    super().__init__()\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 510, in const\n",
      "    return ConstantDistribution(x)\n",
      "  File \"/Users/peterhurford/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py\", line 44, in __init__\n",
      "    def __init__(self):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py:199\u001b[0m, in \u001b[0;36mbayesnet\u001b[0;34m(event_fn, n, find, conditional_on, reduce_fn, raw, memcache, reload_cache, dump_cache_file, load_cache_file, cache_file_primary, verbose, cores)\u001b[0m\n\u001b[1;32m    196\u001b[0m         outfile\u001b[38;5;241m.\u001b[39mwrite(encoder\u001b[38;5;241m.\u001b[39mencode(batch))\n\u001b[1;32m    198\u001b[0m pool_results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mamap(multicore_event_fn, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(cores \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[0;32m--> 199\u001b[0m \u001b[43mmulticore_event_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWaiting for other cores...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py:188\u001b[0m, in \u001b[0;36mbayesnet.<locals>.multicore_event_fn\u001b[0;34m(core, total_cores, verbose)\u001b[0m\n\u001b[1;32m    186\u001b[0m r_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(cuts[core])\n\u001b[1;32m    187\u001b[0m pbar \u001b[38;5;241m=\u001b[39m _init_tqdm(verbose\u001b[38;5;241m=\u001b[39mverbose, total\u001b[38;5;241m=\u001b[39mn)\n\u001b[0;32m--> 188\u001b[0m batch \u001b[38;5;241m=\u001b[39m [run_event_fn(pbar\u001b[38;5;241m=\u001b[39mpbar, total_cores\u001b[38;5;241m=\u001b[39mtotal_cores) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m r_]\n\u001b[1;32m    189\u001b[0m _flush_tqdm(pbar)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py:188\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m r_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(cuts[core])\n\u001b[1;32m    187\u001b[0m pbar \u001b[38;5;241m=\u001b[39m _init_tqdm(verbose\u001b[38;5;241m=\u001b[39mverbose, total\u001b[38;5;241m=\u001b[39mn)\n\u001b[0;32m--> 188\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[43mrun_event_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_cores\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m r_]\n\u001b[1;32m    189\u001b[0m _flush_tqdm(pbar)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/bayes.py:170\u001b[0m, in \u001b[0;36mbayesnet.<locals>.run_event_fn\u001b[0;34m(pbar, total_cores)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_event_fn\u001b[39m(pbar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, total_cores\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    169\u001b[0m     _tick_tqdm(pbar, total_cores)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevent_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:31\u001b[0m, in \u001b[0;36mdefine_event\u001b[0;34m(verbosity)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py:750\u001b[0m, in \u001b[0;36msample\u001b[0;34m(dist, n, lclip, rclip, memcache, reload_cache, dump_cache_file, load_cache_file, cache_file_primary, verbose, cores, _multicore_tqdm_n, _multicore_tqdm_cores)\u001b[0m\n\u001b[1;32m    747\u001b[0m     samples \u001b[38;5;241m=\u001b[39m uniform_sample(dist\u001b[38;5;241m.\u001b[39mx, dist\u001b[38;5;241m.\u001b[39my, samples\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscrete\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 750\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mdiscrete_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m_multicore_tqdm_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_multicore_tqdm_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m                              \u001b[49m\u001b[43m_multicore_tqdm_cores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_multicore_tqdm_cores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dist\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    756\u001b[0m     samples \u001b[38;5;241m=\u001b[39m normal_sample(mean\u001b[38;5;241m=\u001b[39mdist\u001b[38;5;241m.\u001b[39mmean, sd\u001b[38;5;241m=\u001b[39mdist\u001b[38;5;241m.\u001b[39msd, samples\u001b[38;5;241m=\u001b[39mn)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py:474\u001b[0m, in \u001b[0;36mdiscrete_sample\u001b[0;34m(items, samples, verbose, _multicore_tqdm_n, _multicore_tqdm_cores)\u001b[0m\n\u001b[1;32m    472\u001b[0m weights, values \u001b[38;5;241m=\u001b[39m _process_weights_values(values\u001b[38;5;241m=\u001b[39mitems)\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m const\n\u001b[0;32m--> 474\u001b[0m values \u001b[38;5;241m=\u001b[39m [const(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mixture_sample(values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    476\u001b[0m                       weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    477\u001b[0m                       samples\u001b[38;5;241m=\u001b[39msamples,\n\u001b[1;32m    478\u001b[0m                       verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    479\u001b[0m                       _multicore_tqdm_n\u001b[38;5;241m=\u001b[39m_multicore_tqdm_n,\n\u001b[1;32m    480\u001b[0m                       _multicore_tqdm_cores\u001b[38;5;241m=\u001b[39m_multicore_tqdm_cores)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/samplers.py:474\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    472\u001b[0m weights, values \u001b[38;5;241m=\u001b[39m _process_weights_values(values\u001b[38;5;241m=\u001b[39mitems)\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m const\n\u001b[0;32m--> 474\u001b[0m values \u001b[38;5;241m=\u001b[39m [\u001b[43mconst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mixture_sample(values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    476\u001b[0m                       weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    477\u001b[0m                       samples\u001b[38;5;241m=\u001b[39msamples,\n\u001b[1;32m    478\u001b[0m                       verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    479\u001b[0m                       _multicore_tqdm_n\u001b[38;5;241m=\u001b[39m_multicore_tqdm_n,\n\u001b[1;32m    480\u001b[0m                       _multicore_tqdm_cores\u001b[38;5;241m=\u001b[39m_multicore_tqdm_cores)\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py:510\u001b[0m, in \u001b[0;36mconst\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconst\u001b[39m(x):\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03m    Initialize a constant distribution.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    <Distribution> const(1)\u001b[39;00m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConstantDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py:482\u001b[0m, in \u001b[0;36mConstantDistribution.__init__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py:45\u001b[0m, in \u001b[0;36mOperableDistribution.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/dev/lib/python3.9/site-packages/squigglepy/distributions.py:10\u001b[0m, in \u001b[0;36mBaseDistribution.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collectors = bayes.bayesnet(define_event,\n",
    "                            find=lambda e: e['collectors'],\n",
    "                            load_cache_file='future_assessment_model_cache',\n",
    "                            dump_cache_file='future_assessment_model_cache',\n",
    "                            reload_cache=True,\n",
    "                            raw=True,\n",
    "                            verbose=True,\n",
    "                            cores=5,\n",
    "                            n=RUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. World State At Year\n",
      "## 2030 ##\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'collectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y_c \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2030\u001b[39m, \u001b[38;5;241m2050\u001b[39m, \u001b[38;5;241m2070\u001b[39m, \u001b[38;5;241m2100\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m## \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ##\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_c)) \n\u001b[0;32m---> 17\u001b[0m     pprint(print_states([c[y_c][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcollectors\u001b[49m]))\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collectors' is not defined"
     ]
    }
   ],
   "source": [
    "def print_states(states):\n",
    "    c = Counter(states)\n",
    "    c = dict([(k, round(v / RUNS * 100, 3)) for k, v in c.items()])\n",
    "    for k in c.keys():\n",
    "        if k not in STATES:\n",
    "            raise ValueError('State {} not in `STATES`'.format(k))\n",
    "    for state in STATES:\n",
    "        if not c.get(state):\n",
    "            c[state] = 0.0\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    return c\n",
    "\n",
    "\n",
    "print('0. World State At Year')\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c)) \n",
    "    pprint(print_states([c[y_c]['category'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0B. Catastrophe States At Year')\n",
    "\n",
    "def print_catastrophe(catastrophes):\n",
    "    c = Counter([' '.join(sorted(c)) for c in catastrophes])\n",
    "    c = dict([(k, round(v / RUNS * 100, 2)) for k, v in c.items()])\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    c = [c_ for c_ in c if c_[1] >= 0.1]\n",
    "    return c\n",
    "\n",
    "for y_c in [2023, 2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_catastrophe([c[y_c]['catastrophe'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0C. *First* Catastrophe State At Year')\n",
    "\n",
    "def print_catastrophe_first(catastrophes):\n",
    "    c = Counter([c[0] if len(c) > 0 else '' for c in catastrophes])\n",
    "    c = dict([(k, round(v / RUNS * 100, 2)) for k, v in c.items()])\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    c = [c_ for c_ in c if c_[1] >= 0.1]\n",
    "    return c\n",
    "\n",
    "for y_c in [2023, 2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_catastrophe_first([c[y_c]['catastrophe'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0D. Double Catastrophe X-Risks')\n",
    "\n",
    "def print_double_catastrophes(catastrophes):\n",
    "    c = Counter(['' if c is None else c for c in catastrophes])\n",
    "    c = dict([(k, round(v / RUNS * 100, 3)) for k, v in c.items()])\n",
    "    c = sorted(c.items(), key=lambda x: x[1], reverse=True)\n",
    "    # c = [c_ for c_ in c if c_[1] >= 0.1]\n",
    "    return c\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_double_catastrophes([c[y_c]['double_catastrophe_xrisk'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0E. # of Catastrophes At Year')\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## # of catastrophes as of {} ##'.format(y_c))  \n",
    "    pprint(sq.get_percentiles([len(c[y_c]['catastrophe']) for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0F. War States At Year')\n",
    "\n",
    "def print_wars(wars):\n",
    "    bs = [[w['belligerents'] if w != [] else [] for w in ws] for ws in wars]\n",
    "    bs = Counter([' '.join(sorted(b)) for b in bs])    \n",
    "    bs = dict([(k, round(v / RUNS * 100, 3)) for k, v in bs.items()])\n",
    "    bs = sorted(bs.items(), key=lambda x: x[1], reverse=True)\n",
    "    return bs\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## {} ##'.format(y_c))  \n",
    "    pprint(print_wars([c[y_c]['wars'] for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0G. War Length States At Year')\n",
    "\n",
    "def print_wars(y, wars):\n",
    "    bs = [[(w['end_year'] - w['start_year'] if w['end_year'] < y else y - w['start_year']) if w != [] else 0 for w in ws] for ws in wars]\n",
    "    bs = [round(sum(b) / (y - CURRENT_YEAR) * 100, 1) for b in bs]\n",
    "    return bs\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## Percent of time in war as of {} ##'.format(y_c))  \n",
    "    pprint(sq.get_percentiles(print_wars(y_c, [c[y_c]['wars'] for c in collectors])))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('0H. # of Wars At Year')\n",
    "\n",
    "for y_c in [2030, 2050, 2070, 2100]:\n",
    "    print('## # of wars as of {} ##'.format(y_c))  \n",
    "    pprint(sq.get_percentiles([len(c[y_c]['wars']) for c in collectors]))\n",
    "    print('-')\n",
    "    print('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_p = np.array([p_alignment_solved(war=False, year=y - CURRENT_YEAR, first_attempt=True) for y in years])\n",
    "alignment_p2 = np.array([p_alignment_solved(war=False, year=y - CURRENT_YEAR, first_attempt=False) for y in years])\n",
    "alignment_pwar = np.array([p_alignment_solved(war=True, year=y - CURRENT_YEAR, first_attempt=True) for y in years])\n",
    "alignment_p2war = np.array([p_alignment_solved(war=True, year=y - CURRENT_YEAR, first_attempt=False) for y in years])\n",
    "plt.plot(years, alignment_p, label='first attempt, no war')\n",
    "plt.plot(years, alignment_p2, label='2+ attempt, no war')\n",
    "plt.plot(years, alignment_pwar, label='first attempt, war')\n",
    "plt.plot(years, alignment_p2war, label='2+ attempt, war')\n",
    "plt.legend()\n",
    "plt.ylabel('chance of solving alignment if TAI in year')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in years:\n",
    "    str_ = 'Year: {} - chance of solving TAI alignment with no war {}% (2nd attempt {}%)'\n",
    "    print(str_.format(y,\n",
    "                      round(alignment_p[y - CURRENT_YEAR] * 100, 0),\n",
    "                      round(alignment_p2[y - CURRENT_YEAR] * 100, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in years:\n",
    "    str_ = 'Year: {} - chance of solving TAI alignment with war {}% (2nd attempt {}%)'\n",
    "    print(str_.format(y,\n",
    "                      round(alignment_pwar[y - CURRENT_YEAR] * 100, 0),\n",
    "                      round(alignment_p2war[y - CURRENT_YEAR] * 100, 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('4B. AI X-Risk')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: e['collectors'][y_c]['category'] == category,\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    extinction = find(y_c, 'xrisk_full_unaligned_tai_extinction')\n",
    "    singleton = find(y_c, 'xrisk_full_unaligned_tai_singleton')\n",
    "    subtle_misalignment = find(y_c, 'xrisk_subtly_unaligned_tai')\n",
    "    misuse = find(y_c, 'xrisk_tai_misuse')\n",
    "    out = '{} - {}% (Extinction: {}%, Bad TAI singleton: {}%, Subtly misaligned singleton: {}%, Misuse singleton: {}%)'\n",
    "    print(out.format(y_c,\n",
    "                     round((extinction + singleton + subtle_misalignment + misuse) * 100, 1),\n",
    "                     round(extinction * 100, 1),\n",
    "                     round(singleton * 100, 1),\n",
    "                     round(subtle_misalignment * 100, 1),\n",
    "                     round(misuse * 100, 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('4D. Aligned TAI')\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: e['collectors'][y_c]['category'] == 'aligned_tai',\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('4E. When TAI?')\n",
    "print('-')\n",
    "\n",
    "yrs = bayes.bayesnet(define_event,\n",
    "                     find=lambda e: e['final_state']['tai_year'],\n",
    "                     raw=True,\n",
    "                     n=RUNS)\n",
    "pprint(sq.get_percentiles([2223 if yr is None else yr for yr in yrs]))\n",
    "print('-')\n",
    "\n",
    "def bin_tai_yrs(low=None, hi=None):\n",
    "    low = CURRENT_YEAR if low is None else low\n",
    "    if hi is None:\n",
    "        r = bayes.bayesnet(define_event,\n",
    "                           find=lambda e: e['final_state']['tai_year'] is None or e['final_state']['tai_year'] >= low,\n",
    "                           n=RUNS)\n",
    "    else:\n",
    "        r = bayes.bayesnet(define_event,\n",
    "                           find=lambda e: (e['final_state']['tai_year'] is not None and\n",
    "                                          (e['final_state']['tai_year'] >= low and e['final_state']['tai_year'] <= hi)),\n",
    "                           n=RUNS)\n",
    "    return round(r * 100, 1)\n",
    "\n",
    "print('<2024: {}%'.format(bin_tai_yrs(hi=2024)))\n",
    "print('2025-2029: {}%'.format(bin_tai_yrs(2025, 2029)))\n",
    "print('2030-2039: {}%'.format(bin_tai_yrs(2030, 2039)))\n",
    "print('2040-2049: {}%'.format(bin_tai_yrs(2040, 2049)))\n",
    "print('2050-2059: {}%'.format(bin_tai_yrs(2050, 2059)))\n",
    "print('2060-2069: {}%'.format(bin_tai_yrs(2060, 2069)))\n",
    "print('2070-2079: {}%'.format(bin_tai_yrs(2070, 2079)))\n",
    "print('2080-2089: {}%'.format(bin_tai_yrs(2080, 2089)))\n",
    "print('2090-2099: {}%'.format(bin_tai_yrs(2090, 2099)))\n",
    "print('2100-2109: {}%'.format(bin_tai_yrs(2100, 2109)))\n",
    "print('2110-2119: {}%'.format(bin_tai_yrs(2110, 2119)))\n",
    "print('>2020: {}%'.format(bin_tai_yrs(low=2020)))\n",
    "print('-')\n",
    "\n",
    "print('By EOY: {}%'.format(bin_tai_yrs(hi=2023)))\n",
    "print('By EOY 2024: {}%'.format(bin_tai_yrs(hi=2024)))\n",
    "print('By EOY 2025: {}%'.format(bin_tai_yrs(hi=2025)))\n",
    "print('By EOY 2027: {}% (within 5 yrs)'.format(bin_tai_yrs(hi=2027)))\n",
    "print('By EOY 2030: {}% (Ajeya 2022: 15%)'.format(bin_tai_yrs(hi=2030)))\n",
    "print('By EOY 2032: {}% (within 10yrs)'.format(bin_tai_yrs(hi=2032)))\n",
    "print('By EOY 2036: {}% (Holden benchmark - 10%-50%, Holden: 10%; Ajeya 2022: 35%)'.format(bin_tai_yrs(hi=2036)))\n",
    "print('By EOY 2040: {}% (Ajeya 2022: 50%)'.format(bin_tai_yrs(hi=2040)))\n",
    "print('By EOY 2042: {}% (FTX: 20%, 10%-45%)'.format(bin_tai_yrs(hi=2042)))\n",
    "print('By EOY 2047: {}% (within 25yrs)'.format(bin_tai_yrs(hi=2047)))\n",
    "print('By EOY 2050: {}% (Ajeya 2020: 50%, Ajeya 2022: 60%)'.format(bin_tai_yrs(hi=2050)))\n",
    "print('By EOY 2060: {}% (Holden benchmark - 25%-75%, Holden: 50%)'.format(bin_tai_yrs(hi=2060)))\n",
    "print('By EOY 2070: {}% (Carlsmith: 50%)'.format(bin_tai_yrs(hi=2070)))\n",
    "print('By EOY 2072: {}% (within 50yrs)'.format(bin_tai_yrs(hi=2072)))\n",
    "print('By EOY 2078: {}% (within my expected lifetime)'.format(bin_tai_yrs(hi=2078)))\n",
    "print('By EOY 2099: {}% (FTX: 60%, >30%)'.format(bin_tai_yrs(hi=2099)))\n",
    "print('By EOY 2100: {}% (Holden benchmark - 33%-90%, Holden: 66%)'.format(bin_tai_yrs(hi=2100)))\n",
    "print('By EOY 2122: {}% (within 100yrs)'.format(bin_tai_yrs(hi=2122)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('9. Total Catastrophic Risk* (10%+ death)')\n",
    "\n",
    "for y_c in [2030, 2050, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: e['collectors'][y_c]['catastrophe'] != [],\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10. Total Extinction Risk*')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: e['collectors'][y_c]['category'] == category,\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2030, 2050, 2100]:\n",
    "    ai = find(y_c, 'xrisk_full_unaligned_tai_extinction')\n",
    "    nukes_war = find(y_c, 'xrisk_nukes_war')\n",
    "    nukes_accident = find(y_c, 'xrisk_nukes_accident')\n",
    "    unknown = find(y_c, 'xrisk_unknown_unknown')\n",
    "    bio_war = find(y_c, 'xrisk_bio_war')\n",
    "    bio_accident = find(y_c, 'xrisk_bio_accident')\n",
    "    bio_nonstate = find(y_c, 'xrisk_bio_nonstate')\n",
    "    nanotech = find(y_c, 'xrisk_nanotech')\n",
    "    supervolcano = find(y_c, 'xrisk_supervolcano')\n",
    "    \n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: e['collectors'][y_c]['category'] in extinctions,\n",
    "                       n=RUNS)\n",
    "    \n",
    "    out = '{} - {}% (AI: {}%, Nukes: {}% (War: {}% Accident: {}%), Bio: {}% (War: {}%, Accident: {}%, Nonstate: {}%), Nano: {}%, Natural: {}%, Other: {}%)'\n",
    "    print(out.format(y_c,\n",
    "                     round(r * 100, 2),\n",
    "                     round(ai * 100, 2),\n",
    "                     round((nukes_war + nukes_accident) * 100, 3),\n",
    "                     round(nukes_war * 100, 3),\n",
    "                     round(nukes_accident * 100, 3),\n",
    "                     round((bio_war + bio_accident + bio_nonstate) * 100, 3),\n",
    "                     round(bio_war * 100, 3),\n",
    "                     round(bio_accident * 100, 3),\n",
    "                     round(bio_nonstate * 100, 3),\n",
    "                     round(nanotech * 100, 3),\n",
    "                     round(supervolcano * 100, 3),\n",
    "                     round(unknown * 100, 3)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('10B. Total X-Risk (including non-extinction x-risks and excluding successful tranisition-based extinctions)')\n",
    "\n",
    "def find(y_c, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: ('xrisk' in e['collectors'][y_c]['category']) and (category in e['collectors'][y_c]['category']),\n",
    "                          n=RUNS)\n",
    "\n",
    "for y_c in [2023, 2024, 2030, 2035, 2036, 2037, 2040, 2045, 2050, 2060, 2070, 2100]:\n",
    "    ai = find(y_c, 'tai')\n",
    "    nukes = find(y_c, 'nukes')\n",
    "    unknown = find(y_c, 'unknown')\n",
    "    nano = find(y_c, 'nanotech')\n",
    "    natural = find(y_c, 'supervolcano')\n",
    "    bio = find(y_c, 'bio')\n",
    "\n",
    "    out = '{} - {}% (AI: {}%, Nukes: {}%, Bio: {}%, Nano: {}%, Natural: {}%, Other: {}%)'\n",
    "    print(out.format(y_c,\n",
    "                     round((ai + nukes + bio + nano + unknown) * 100, 2),\n",
    "                     round(ai * 100, 2),\n",
    "                     round(nukes * 100, 3),\n",
    "                     round(bio * 100, 3),\n",
    "                     round(nano * 100, 3),\n",
    "                     round(natural * 100, 3),\n",
    "                     round(unknown * 100, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10C. Total X-Risk OR catastrophe')\n",
    "\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: 'xrisk' in e['collectors'][y_c]['category'] or e['collectors'][y_c]['catastrophe'] != [],\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10D. Total X-Risk AND catastrophe')\n",
    "\n",
    "for y_c in [2024, 2030, 2050, 2070, 2100]:\n",
    "    r = bayes.bayesnet(define_event,\n",
    "                       find=lambda e: 'xrisk' in e['collectors'][y_c]['category'] and e['collectors'][y_c]['catastrophe'] != [],\n",
    "                       n=RUNS)\n",
    "    print('{} - {}%'.format(y_c, round(r * 100, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://forum.effectivealtruism.org/posts/nYgw4FNpHf9bmJGEi/forecasting-thread-how-does-ai-risk-level-vary-based-on\n",
    "\n",
    "def generate_conditional(y_low, y_high):\n",
    "    def fn(e):\n",
    "        if e['final_state']['tai_year'] is None:\n",
    "            return False\n",
    "        elif e['final_state']['tai_year'] < y_low:\n",
    "            return False\n",
    "        elif e['final_state']['tai_year'] > y_high:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    return fn\n",
    "    \n",
    "\n",
    "def find(y_low, y_high, category):\n",
    "    return bayes.bayesnet(define_event,\n",
    "                          find=lambda e: e['collectors'][MAX_YEAR - 1 if y_high >= MAX_YEAR else y_high]['category'] == category,\n",
    "                          conditional_on=generate_conditional(y_low, y_high),\n",
    "                          n=RUNS)\n",
    "\n",
    "\n",
    "for y_c in [[2022, 2024], [2024, 2029], [2029, 2039], [2039, 2059], [2059, MAX_YEAR - 1], [2022, 2070]]:\n",
    "    print('AI X-Risk conditional on AGI beween beginning of {} and end of {}'.format(y_c[0] + 1, y_c[1]))\n",
    "    extinction = find(y_c[0], y_c[1], 'xrisk_full_unaligned_tai_extinction')\n",
    "    singleton = find(y_c[0], y_c[1], 'xrisk_full_unaligned_tai_singleton')\n",
    "    subtle_misalignment = find(y_c[0], y_c[1], 'xrisk_subtly_unaligned_tai')\n",
    "    misuse = find(y_c[0], y_c[1], 'xrisk_tai_misuse')\n",
    "    out = '{}% (Extinction: {}%, Bad TAI singleton: {}%, Subtly misaligned singleton: {}%, Misuse singleton: {}%)'\n",
    "    print(out.format(round((extinction + singleton + subtle_misalignment + misuse) * 100, 1),\n",
    "                     round(extinction * 100, 1),\n",
    "                     round(singleton * 100, 1),\n",
    "                     round(subtle_misalignment * 100, 1),\n",
    "                     round(misuse * 100, 1)))\n",
    "    print('-')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
